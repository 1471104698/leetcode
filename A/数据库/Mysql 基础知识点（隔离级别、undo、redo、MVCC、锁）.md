# Mysql 基础知识点（隔离级别、undo、redo、MVCC、锁）



## 1、数据库（事务）的四个特性（ACID 原则）

A：原子性，事务不能存在中间状态，要么全部成功，要么全部失败，成功就要应用于数据库，失败就不能对数据库有任何影响，基于 redo/undo 机制

C：一致性，你转给我 100，你那边就必须减100，我这边就必须加100，否则回滚，可以理解为数据一致性

I：隔离性，事务与事务之间是相互隔离的，即各自操作各自的数据，不能干扰，或者说 一个事务的数据修改不能反映到其他事务数据中，相当于事务之间使用的是数据的副本，互不影响

D：持久性：一个事务一旦被提交，在数据库中的数据改变就应该是永久有效的



原子性、隔离性、持久性 是为了保障一致性，即一致性是最终目的





## 2、体现隔离性的四个隔离级别

四个隔离级别：读未提交、读已提交、可重复读、串行

四个问题现象：ABA 问题、脏读、不可重复读、幻读（不可重复读 和 幻读有点容易混淆）



> ### 读未提交

一个事务执行过程中，可以读取到另外一个事务修改的未提交的数据



假设 x = 100

事务 A 和 事务 B 都在操作 x，事务 A将 x 改为 50，但是还没有提交

而事务 B 获取 x 值，这时读取到的是 x = 50

这时候如果 事务 B 执行 x - 50 这个操作的话，那么 x 变成 0

而如果 事务 A 没有提交，而是回滚，那么意味着 x = 50 这个值是不成立的，而事务 B 在不成立的值上做了修改，导致最终的结果也是不成立的，因为事务 A 回滚了，表示 x 应该还是 100，那么事务 B 执行的 x - 50 的话，结果应该是 50

这个 隔离性最差，基本事务之间就没有隔离



这个在自己事务中能够读取到别的事务修改的数据，就是脏读



> ### 读已提交

一个事务执行过程中，不可以读取另一个事务修改未提交的数据，但可以读取到已提交的数据



假设 x = 100

事务 A 和 事务 B 两个事务并发执行，事务 B 使用 select 查询 x = 100，事务 A 修改了 x = 50，然后提交，事务 B 使用 select 再次查询 x = 50，发现前后两次查询结果不一样，这就是不可重复读（按照字面意思就是不能够重复读取之前的值，即之前读的值会被修改）



假设 x > 50 的有 3 条数据

事务 A 和 事务 B 两个事务并发执行，事务 B 查询 x > 50，发现有 3 条数据，事务 A 插入了 x = 60 的一条数据，事务 B 再次查询 x > 50 ，发现有 4 条数据，前面查询的数据量不一样，这就是幻读



读已提交能够解决脏读的问题，即读取到的都是提交的，已经确定的值，但因此会产生 不可重复读 和 幻读

其中，不可重复读是针对 update 的，单单是修改值，幻读是针对 delete 和 insert 的，会改变数据量



> ### 可重复读

一个事务执行过程中，不能读取其他事务未提交以及已提交的数据，相当于事务之间操作的都是数据的副本



其中是通过 MVCC（多版本并发控制）来实现的，因为别的事务提交了数据，数据已经更新了，怎么保证自己能够读取到自己原来的值呢？就是指定版本



> ### 串行

这个隔离级别就严重了，可以解决上述问题的任何问题，因为每次只允许一个事务执行，即是串行的，没啥用吧，在如今这个要求效率的时代，基本不会去用这种拖慢下来的东西







## 3、redo log 和 undo log



### 1、redo log

---



> ### 它有什么用呢？

- 一是为了提高效率
- 二是为了保证数据持久化



设想一下，如果使用每次更新操作在事务提交后都要立马写入磁盘中进行持久化，即每个更新提交事务，去寻道查找对应的记录在哪里，然后再将内存中的数据写进入 --- 这个过程 I/O 成本很高，在高并发情况下 根本不允许这么做

因此，就出现了 redo log，它的出现使得 写入磁盘这个操作可以延迟，无需立马写入，在事务执行过程中当数据发生修改，那么就产生一条 redo log，这时候的 redo log 是在缓存中，只需要保证在事务提交前将 redo log 持久化即可



> ### 同样是磁盘文件，为什么写入 redo log 就可以，直接将数据写回磁盘就不可以？

因为 redo log 是以日志的形式写入的，可以直接在前面的内容后面追加，相当于是 log.append()，在原有的内容后面添加， 是顺序 IO，节省了很多的寻道时间

而将数据 直接写回 磁盘的话，那么就需要寻道，查找每条数据的位置，然后将数据写回去，是随机 IO，寻道时间长，效率低

因此，使用了 redo log，可以无需立马将数据写回去，可以在系统空闲的时候，使用后台线程，将数组写回磁盘中



> ### 假设这时候数据库宕机了，而数据还没有写回磁盘，那么数据会不见么？

不会，因为已经写到了 redo log，当数据库重启的时候，可以读取 redo log 内的数据，将数据写回磁盘



> ### 那这样的话，用户 A 更新数据，然而没有写回磁盘，用户进行查询，发现数据跟自己修改的不一样，这样的话不是就会出现不一致的问题么？

数据库内部维护了一个 缓存，主要就是缓存这些数据的，当数据查询或修改了，会在自己缓存中存储，当数据查询的时候，可以直接将缓存的数据发送给他



> ### redo log 的读写

redo log 文件的大小是固定的，从文件头开始写，写到末尾，然后又从头开始写

里面有两个指针，check point（检查点）表示下次数据写入磁盘的位置，write pos 表示下次数据写入 redo log 文件的位置

当 write pos == check point 时，表示文件已经满了，需要将数据写入到磁盘中，腾出空间

相当于一个是读指针，一个是写指针，当读指针和写指针重叠时，表示内存空间已满（类似数组实现队列一样）

![img](https://pic4.zhimg.com/80/v2-b2a4003fde5ed1a12cfb9522235319ff_720w.jpg)





### 2、undo log

---



Undo log中存储的是老版本数据，当一个事务需要读取记录行时，如果当前记录行的新版本数据对于该事务不可见，那么可以顺着undo log 链找到满足其可见性条件的记录行版本（MVCC 实现条件之一）



> ### undo log 分为两种

- insert undo log：事务对 insert 操作产生的 undo log，只有在事务回滚时才需要，当事务提交后可以立即丢弃

- update undo log：update 和 delete 都会产生的 undo log，InnoDB 默认将 delete 当作 update 的一种，所谓的 delete 只是修改了 删除标志位；该 undo log 不仅在回滚的时候需要，在 MVCC 中其他事务会需要，因此事务提交后不会立即删除，只有数据库现在持有的所有 ReadView  的事务 id 都跟 该 undo log 中记录的事务 id 搭不上边了，该 undo log 才会被删除



> ### 在一个事务过程中，有很多 undo log 产生，怎么写入磁盘中？

redo log 记录的是数据，可以把 undo log 数据， 然后后续同样通过 redo log 写回磁盘



> ### 记录行 update 的过程模拟

undo log 中有一个字段` db_trx_id` 记录修改当前数据的事务 id，以及一个` db_roll_ptr`，指向 undo log 版本链



假设有一条记录行如下，字段有 Name 和 Honor，值分别为"curry"和"mvp"，最新修改这条记录的事务ID为1。

![img](https://img-blog.csdnimg.cn/20200701205716343.png)

（1）现在事务A（事务ID为2）对该记录的Honor做出了修改，将Honor改为"fmvp"：

​                ①事务A先对该行加排它锁
​                ②然后把该行数据拷贝到undo log中，作为旧版本
​                ③拷贝完毕后，修改该行的Honor为"fmvp"，并且修改DB_TRX_ID为2（事务A的ID）, 回滚指针指向拷贝到undo log的旧版本。（然后还会将修改后的最新数据写入redo log）
​                ④事务提交，释放排他锁

![img](https://img-blog.csdnimg.cn/20200701210046670.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhdmVzX19f,size_16,color_FFFFFF,t_70)

（2） 接着事务B（事务ID为3）修改同一个记录行，将Name修改为"iguodala"：

​                ①事务B先对该行加排它锁
​                ②然后把该行数据拷贝到undo log中，作为旧版本
​                ③拷贝完毕后，修改该行Name为"iguodala"，并且修改DB_TRX_ID为3（事务B的ID）, 回滚指针指向拷贝到undo log最新的旧版本。
​                ④事务提交，释放排他锁

![img](https://img-blog.csdnimg.cn/2020070121022442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1dhdmVzX19f,size_16,color_FFFFFF,t_70)

从上面可以看出，不同事务或者相同事务的对同一记录行的修改，会使该记录行的undo log成为一条链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录。





> ### redo log 和 undo log 的过程模拟

```java
假设有A、B两个数据，值分别为1，2.
A.事务开始.
B.记录A=1到undo log.
C.修改A=3.
D.记录A=3到redo log.
E.记录B=2到undo log.
F.修改B=4.
G.记录B=4到redo log.
H.将undo log写入到 redo log 中
I.将redo log写入磁盘。
K.事务提交
```



## 4、MVCC

> ### MVCC 出现的原因

MVCC 是不加锁的，最开始的 mysql 使用原生锁，相当于 java  的 syn 锁，一次只能够一个事务，相当于上面的 串行

但是这样效率很低，而且很多情况下是读多写少，因此出现了读写锁，读锁和读锁之间共存，写锁和写锁 、写锁和读锁 之间互斥

这样提高了并发能力，但是发现还不够，还要提高并发能力，让读写什么的都可以同时进行。

因此出现了 MVCC，**MVCC 只能在 读已提交 和 可重复读 两种隔离级别下进行**

```java
因为 读未提交 基本就是没有隔离，不管了的，而 串行 就是那种加了重量级锁的，两种都是不同方面的极端
```



**引入了 MVCC 之后，只有 写和写 会阻塞，其他的都能够并行操作**



**MVCC 实现：隐藏字段 + ReadView（快照） + undo log**

InnoDB 在表中的每行数据后都会添加 3 个 隐藏字段：

- **DB_TRX_ID**：记录最近一次对 当前数据行 做修改的事务 id，对于 delete 操作，同样认为是update，不过修改的是删除标志位
- **DB_ROLL_PTR**：回滚指针，看上面的 undo log 图，类似链表形式，用于回滚
- **DB_ROW_ID**：当没有主键或者唯一非空索引的时候，使用的就是这个 id，**这个跟 MVCC 没什么关系**

**通过 undo log 可以找到之前的事务旧数据**

**通过 ReadView 可以确定对于当前事务而言哪些事务是可见的**



> ### ReadView

**RC 读 和 RR 读的区别就在于生成 ReadView 的策略不同**



ReadView 有 3 个重要字段 ：

- **low_limit_id**：当前 RV 创建时出现过的最大的事务 ID + 1，即下一个将被分配的事务 ID
- **up_limit_id**：当前 RV 创建时在活跃事务表 trx_ids 中最小的事务 id
- **trx_ids：**RV 创建时其他未提交的事务 id 集合列表，对持有 RV 的事物来说，它的 id 不会在 trx_ids 中



> ### 可见性算法

当 id = 11 的事务 select 某个数据行的时候，会创建一个 RV，而所有的事务 id 如下：

1	2	3	4	5	6	7	8	9	10	11	12	13	

其中有各个 id 对应的状态如下：

已提交事务 id：[1，2，3，4，7，9，12]

未提交事务 id：[5，6，8，10]（因为持有该 RV 的事务 id 不会在 trx_ids 中，因此忽略 11）

这样的话，low_limit_id = 14，up_limit_id = 5

此时 RV 上的数据就已经是固定了的，这就是快照，仅仅记录某个瞬间的数据，对于此刻的 id 11 事务来说，所有的事务就是这个状态

获取读取的数据行上的 trx_id，进行比较

- 1、如果 trx_id < up_limit_id，表示该数据是在创建 RV 前就已经被其他事务提交的了，那么对该事务来说是可见的，跳到步骤 5
- 2、如果 trx_id >= low_limit_id ，表示该数据是在 创建 RV 后才提交的，那么跳到步骤 4
- 3、如果 up_limit_id <= trx_id < low_limit_id ，那么表示创建 RV 的时候，这个数据可能是已经提交了的，或者提交这个数据的事务还在活跃中（即在 trx_ids 中），因此直接使用二分查找判断是否在 trx_ids 中
  - 如果不在，表示对该事务可见，跳到步骤 5
  - 如果在，表示当时那个事务当时还没有把它提交上去，因此对该事务不可见，跳到步骤 4

4、获取读取的数据行的` db_roll_ptr `指针，得到对应的 undo log 链的最新一个，获取对应的 trx_id，然后重新回到上面进行判断，直到跳到步骤 5 ，即找到一个可见的数据

5、找到可见值，那么结束了



> ### 当前读 和 快照读

快照读：普通的 select，每次调用 select 都会产生一个 RV 快照，这时候能够防止不可重复读和幻读，因为后续事务的数据新版本不会被读到

当前读：select...for share、select ... for update、 update、insert、delete 这种都是当前读，每次获取的是 数据行的最新数据，不会涉及到 RV 和 undo log

如果只靠 MVCC ，能够解决不可重复读 的问题，只能解决部分 幻读 的问题，而不能完全解决幻读

```
比如事务 A 开始，执行普通的 select 语句，这时候会创建一个快照，然后事务 B 执行 insert 操作
如果事务 A 再次执行 普通 select，那么就不会看到 事务 B insert 进去的数据，能够解决幻读
如果事务 A 再次执行的是 select...for update，那么会看到最新的数据，导致幻读
```

因此， 只靠 MVCC 无法解决 当前读 的幻读问题

因此， RR 级别下，会对当前读的 数据行 加上 行锁 和 间隙锁，即 使用 行锁 + 间隙锁 + MVCC 完全解决幻读问题



> ### RR 和 RC 生成 ReadView 的策略

RR 是在第一次执行普通 select 语句的时候创建一次 ReadView，后续的 select 之类的操作都是按照这个 RV，不会再继续创建，因此保证了可重复读，不会读取到新修改的数据



RV 是在每次 执行普通 select 的时候都创建一个 RV，这样的话，每次其他事务修改数据，当前事务进行 select，获取的都是新版本的数据，因为 RV 也是即时创建的，所以才出现 可重复读 和 幻读 的问题





## 5、Mysql 的锁



### 1、mysql 加锁原理



对于表锁，直接就是对表加锁

而对于行锁，**InnoDB 通过给索引的索引记录加锁的方式实现行级锁**

InnoDB 的索引树有两种：聚簇索引 和 非聚簇索引，而对于聚簇索引，只需要查询一次，对于非聚簇索引，一般需要查询两次

```java
update user set age = 10 where id = 49; //id 是聚簇索引，因此会在 id = 49 上加写锁

update user set age = 10 where name = 'Tom'; //name 是非聚簇索引，因此它会在查询到聚簇索引值，它的聚簇索引 id = 49，再到聚簇索引树上查询， 因此会在非聚簇索引树 name = 'Tom' 和 聚簇索引树 id = 49 上都加锁
```





### 2、mysql 锁分类



mysql 的所有锁按照粒度可以分为 表锁 和 行锁

- 表锁是锁住整个表的，并发度低
- 行锁是锁住数据行的，并发度高



> ### 行锁：共享锁 和 排他锁（读锁 和 写锁）

InnoDB 中有两种类型的行锁（注意，这里只是类型，而不是具体实现）

- **共享锁（S：share）**：同时也叫读锁，当某个事务对某行上读锁后，允许其他事务读取该数据行，即可以上读锁，但不能写，即不能上共享锁
- **排他锁（X）**：同时也叫写锁，但某个事务对某行上写锁后，不允许其他事务 读写 该数据行，即不能够上读锁或者写锁，可以说是重量级锁

| 锁类型       | 共享锁 S | 排他锁 X |
| ------------ | -------- | -------- |
| **共享锁 S** | [兼容]() | 冲突     |
| **排他锁 X** | 冲突     | 冲突     |

通过 select...for share 加读锁， select...for update 加写锁



**这些语句出现的意义是什么？为什么普通的读还要加锁，读完不就完了么？**

```java
insert、update 这些操作会加写锁，这样别人就不能动这些数据了

但是可能 一个事务 执行过程中 不一定存在是 insert、update，它仅仅只需要进行 读而已，但是事务执行过程中又不想要别人修改 数据，即每次当前读 都要保证数据不被修改，因此就使用 select...for share 和 select...for update 加锁，效果跟 insert 和 update 一样的
```



> ### 表锁：意向共享锁 和 意向排他锁

上面说了，mysql 中有两种锁：表锁和行锁



```java
当获取表的写锁时，意味着可以对表的任意数据进行修改

那么当事务 A 获取某行数据的写锁时，事务 B 想要再来获取表的写锁，那么一般情况下它会怎么做呢？

先判断该表是否已经存在表读锁 或者 表写锁，如果没有，那么就需要遍历所有的数据行，判断是否存在数据行给上了读锁或者行锁，如果存在，那么事务 B 就会被阻塞

很显然，这个效率低得一批，当一个表存在 1000W 数据行，那么一次需要判断 1000W 次，显然不可能
```



因此，就出现了 意向锁，意向锁是mysql 自动添加的

- 意向共享锁（IS）：事务在获取某行的读锁前，需要先获取该表的意向共享锁
- 意向排他锁（IX）：事务在获取某行的写锁前，需要先获取该表的意向排他锁



对于表读锁或者表写锁，事务只需要进行一次判断即可，而对于数据行中的读锁和写锁，需要遍历全部的数据行来判断，这样效率低，因此出现了意向锁，它也是表级的，事务只需要判断表上是否存在意向读锁/意向写锁，就可以直接判断是否存在数据行被加了 读锁/写锁，提高了判断的效率



每次执行当前读的时候，都会给对应的表加上意向锁

比如 select...for share 的时候 mysql 会自动给表加上 意向读锁

比如 select...for update、insert、update 的时候 mysql 会自动给表加上 意向写锁



| 锁类型        | 共享锁 S | 排他锁 X | 意向共享锁 IS | 意向排他锁 IX |
| ------------- | -------- | -------- | ------------- | ------------- |
| 共享锁 S      | [兼容]() | 冲突     | [兼容]()      | 冲突          |
| 排他锁 X      | 冲突     | 冲突     | 冲突          | 冲突          |
| 意向共享锁 IS | [兼容]() | 冲突     | [兼容]()      | [兼容]()      |
| 意向排他锁 IX | 冲突     | 冲突     | [兼容]()      | [兼容]()      |





### 3、行锁的具体实现



> ### 记录锁

记录锁就是对索引数据行加锁，只锁住满足条件的数据行



**1、通过主键操作**

```java
select * from t where id = 1 for update;
+----+------+------+------+
| id | c1   | c2   | c3   |
+----+------+------+------+
|  1 |    1 |    1 |    1 |
+----+------+------+------+
```

 使用`SHOW ENGINE INNODB STATUS`命令查看 InnoDB 监控中关于锁的事务数据，可以看到以下内容： 

```java
    2 lock struct(s), heap size 1136, 1 row lock(s//两个锁， 1 个是行锁
MySQL thread id 103, OS thread handle 140437513750272, query id 23734 localhost root
TABLE LOCK table `hrdb`.`t` trx id 43764 lock mode IX	//表 t 加上了 IX 锁
RECORD LOCKS space id 101 page no 4 n bits 72 index PRIMARY of table `hrdb`.`t` trx id 43764 lock_mode X locks rec but not gap	//主键索引上加了 X 锁
```

总共加了 2 个锁，表 t 加上了 IX 锁，对应的主键索引 上加上了一个 X 锁



**2、通过唯一索引操作**

```java
select * from t where c1 = 1 for update;
+----+------+------+------+
| id | c1   | c2   | c3   |
+----+------+------+------+
|  1 |    1 |    1 |    1 |
+----+------+------+------+
```

 使用`SHOW ENGINE INNODB STATUS`命令查看 InnoDB 监控中关于锁的事务数据，可以看到以下内容： 

```java
3 lock struct(s), heap size 1136, 2 row lock(s) //三个锁，2 个是行锁
MySQL thread id 103, OS thread handle 140437513750272, query id 23722 localhost root
TABLE LOCK table `hrdb`.`t` trx id 43761 lock mode IX	//表 t 加上了 IX 锁
RECORD LOCKS space id 101 page no 5 n bits 72 index idx_t_c1 of table `hrdb`.`t` trx id 43761 lock_mode X locks rec but not gap

RECORD LOCKS space id 101 page no 4 n bits 72 index PRIMARY of table `hrdb`.`t` trx id 43761 lock_mode X locks rec but not gap
```

总共加了 3 个锁，表 t 上加了 IX 锁，唯一索引 c1 上加了一个 X 锁，主键索引上加了一个 X 锁

即如果使用唯一索引查询出来的结果，该数据对应的主键索引也会进行加锁

即锁定 非聚簇索引 会同时锁定 聚簇索引



> ### 间隙锁

```sql
       Table: test
Create Table: CREATE TABLE `test` (
  `id` int(11) NOT NULL default '0',
  `v1` int(11) default NULL,
  `v2` int(11) default NULL,
  `v3` int(10) unsigned NOT NULL default '0',
  PRIMARY KEY  (`id`),
  UNIQUE KEY `v3` (`v3`),
  KEY `idx_v1` (`v1`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8


mysql> select * from test;
+----+------+------+----+
| id | v1   | v2   | v3 |
+----+------+------+----+
|  0 |    4 |   15 |  0 |
|  1 |    1 |    0 |  1 |
|  2 |    3 |    1 |  2 |
|  3 |    4 |    2 |  3 |
|  5 |    5 |    9 |  5 |
|  7 |    7 |    4 |  7 |
|  8 |    7 |    3 |  8 |
| 10 |    9 |    5 | 10 |
| 30 |    8 |   15 | 30 |
+----+------+------+----+
9 rows in set (0.00 sec)
```



两个事务执行的 sql 语句如下：

 ![img](https://pic4.zhimg.com/755752d226efac5c7ef1d599636ed4a2_b.png)



**上面阻塞的原理是什么？**

 这是在 RR 模式下的，因此当前读需要加 间隙锁

而 v1 是普通索引，所以可能会存在重复值

根据表中已经存在的记录，并且索引树是叶子节点存储 数据 data 和 聚簇索引值，那么在叶子除 v1 的值是有序且连续的

即 v1 索引树叶子节点的链表如下排列

v1	1	3	4	4	5	7	7	8	9

id	 1	2	0	3	5	7	8   30  10

v1 存在的间隙有  （-∞,1],(1,3],(3,4],(4,4],(4,5],(5,7],(7,7],(7,8],(8,9],(9,+∞) 

首先看 session1，它操作的是 v1 = 7 的数据行，它有两个数据行，因此对两个数据行都加间隙锁

间隙内的数值为  行(v1=5,id=5),行(v1=7,id=7),行(v1=7,id=8),行(v1=8,id=30) 

即锁上包括 v1 = 7 所有数据行左右两边的数据之间的间隔

这些间隙内的其他事务无法进行更新、插入、删除



再看 session2：

- 修改 (v1=9, id=10) 为 (v1=6, id=10)
  - 假设修改成功，那么 v1 索引树的叶子节点链表变成： (v1=5,id=5),**(v1=6,id=10)**,(v1=7,id=7),(v1=7,id=8),(v1=8,id=30) ，这个 (v1=6,id=10) 在锁定的间隙中，所以会阻塞
  - 假设执行的是 update test set v1 = 4 where v1 = 9，即 变成 (v1=4,id=10)，那么就不会阻塞，因为不在间隙中
- 修改 (v1=9,id=10) 为 (v1=8,id=10)
  - 假设修改成功，那么链表变成：(v1=5,id=5),(v1=7,id=7),(v1=7,id=8),**(v1=8,id=10)**,(v1=8,id=30) ，这个 (v1=8,id=10) 在间隙中，因此会阻塞
  - 假设将 v1 = 9 的 id 修改为 40，那么这样修改就不会在间隙中，就不会阻塞
- 修改 (v1=9,id=10) 为 (v1=5,id=10)
  - 假设修改成功，那么链表变成：(v1=5,id=5),**(v1=5,id=10)**,(v1=7,id=7),(v1=7,id=8),(v1=8,id=30) ，这个 (v1=5,id=10) 在间隙中，因此会阻塞
  - 假设将 v1 = 9 的 id 设置为 -1，那么就不会阻塞
- 修改 (v1=9,id=10) 为 (v1=9,id=10)
  - 会修改成功的原因是：(v1=5,id=5),(v1=7,id=7),(v1=7,id=8),(v1=8,id=30),**(v1=9,id=10)**，由于 (v1=9,id=10) 不在间隙锁中，所以会修改成功



> ### Next-key 锁

**Next-key 锁 = 记录锁 + 间隙锁**

由于记录锁只会锁某行记录，而间隙锁只会锁间隙，不会锁记录，因此将它合并起来

**RR 就是使用 MVCC + Next-key 锁 完全解决幻读问题的**





## 6、RC 和 RR 级别下各种操作种锁的应用

### 1、RC级别



> ### 聚簇索引

```sql
delete from t1 where id = 10;
```

id 是主键， 那么就是先对表加 IX 锁，再直接对 id 所在的叶子节点进行加 X 锁（记录锁）

 ![img](https://pic4.zhimg.com/80/v2-a34f111a461bac17c7cfdc62ba0647e2_720w.jpg) 



**因为聚簇索引对应的值是唯一的，因此不会再插入 id = 10 的数据，即不会造成幻读**



> ### 唯一索引

```sql
delete from t1 where id = 10;
```

id 是唯一索引，同时也是非聚簇索引，因此需要在 id 对应的非聚簇索引树 上对 id = 10 的节点 加 X锁（记录锁），并且再查找聚簇索引，找到对应的聚簇索引所在节点，对聚簇索引值所在节点加 X 锁（记录锁）

对聚簇索引加 X 锁，是因为这个数据行已经被事务进行操作了，防止别的事物通过 聚簇索引直接获取数据行进行修改

 ![img](https://pic1.zhimg.com/80/v2-2d1518813e1b1e6ffde3bc070e2e9c82_720w.jpg) 



**同聚簇索引一样，因为唯一索引对应的值是唯一的，因此不会再插入 id = 10 的数据，即不会造成幻读**



> ### 普通索引

```sql
delete from t1 where id = 10; 
```

id 是普通索引，那么表示它的值会存在重复，那么就意味着操作的不只一条数据行

由于是等值查询，因此对于 id 所在的索引树来说，它也是连续的，它找到对应的节点位置，并且连续读取满足条件的节点，全部 加 X 锁（记录锁），然后根据这些节点上的 聚簇索引值找到在 聚簇索引树上的节点，加 X 锁（记录锁）

 ![img](https://pic3.zhimg.com/80/v2-3027331e18395ec65709dcb2dacf4422_720w.jpg) 



**由于 RC 级别下只加记录锁，所以其他事物只是不能操作这些加锁的数据行，但却可以新添加数据行，比如可以添加一些 id = 10 的数据行，因此会导致幻读**



> ### 无索引

```sql
delete from t1 where id = 10; 
```

没有索引，那么必定全表扫描，**全表扫描的话是走 聚簇索引的索引树**

如果执行的是当前读，它会先对所有叶子节点，即所有数据行都加 X 锁，然后再遍历，将不满足条件的数据行的 X 锁进行释放，这样就剩下其他满足条件的数据行加 X 锁了

 ![img](https://pic2.zhimg.com/80/v2-931c0e3cddaf0fa9956478db1ea4a12e_720w.jpg) 



正是因为不走索引会遍历 聚簇索引树的所有叶子节点，虽然是链表形式可以直接顺序方法，但是当数据量过大时，效率就很低

并且其他涉及到对不满足条件的数据行 加锁和释放锁的操作，更加降低了效率



### 2、RR 级别



> ### 聚簇索引

操作跟 RC 级别一样，只需要对 聚簇索引树 上满足条件的那个叶子节点加 X 锁（记录锁）即可，因为值是唯一的，不会导致幻读



> ### 唯一索引

操作跟 RC 级别一样，只需要对 非聚簇索引树 和 聚簇索引树 上满足条件的那个叶子节点加 X 锁（记录锁）即可，因为值是唯一的，不会导致幻读



> ### 普通索引

```sql
delete from t1 where id = 10; 
```

id 是普通索引，因此会出现重复值，即会存在多条数据

首先跟 RC 级别一样，找到 非聚簇索引树上所有满足条件的节点加 X 锁，并且找到对应在 聚簇索引树上的节点加 X 锁

**但是由于 RR 级别需要解决幻读，而 如果仅仅只是对目前满足的数据行加 X 锁，那么这样就无法阻止后续的事务添加 id = 10 的新数据行，这样就又会导致幻读，因此，它会在 id 这个非聚簇索引树上的满足条件的数据行都加上上面提到的间隙锁，这样就能避免幻读**

**无需在 聚簇索引上添加间隙锁，因为当插入一条 id = 10 的新数据时，必定会需要插入到 id 这个非聚簇索引树，而这时被加了间隙锁，因此会插入失败**

 ![img](https://picb.zhimg.com/80/v2-85ef76008ef0f94964c3857a4b49e78b_720w.jpg) 



> ### 无索引

跟 RC 一样走聚簇索引的全表扫描，如果进行的是当前读，那么会锁上所有的叶子节点，并且给所有的数据行加上间隔锁，以此来避免幻读，后面再将不满足条件的叶子节点上的锁去掉

 ![img](https://pic1.zhimg.com/80/v2-71ce022c81c16ddf8ad3503d85dc61e2_720w.jpg) 





## 7、InnoDB 和 mysiam 引擎的区别

InnoDB 和 mysiam 都是 mysql 的存储引擎，一个 database 中的多张表可以设置不同的存储引擎

- InnoDB 支持事务，mysiam 不支持事务，InnoDB 每次都需要将 sql 语句封装进事务里来保证原子性，通过 undo log 和 redo log 保证回滚 和 数据延迟写回磁盘，保证数据库出现事故重启能够快速进行数据恢复
- InnoDB 支持外键，而 mysiam 不支持，带有外键的 InnoDB 表无法转换为 mysiam
- InnoDB 支持表锁和行锁，而 mysiam 只支持表锁，因此 InnDB 在当前读方面效率更高，因为并发度高
- InnoDB 和 mysiam 索引数据结构都是 B+ 树，但是 InnoDB 有 聚簇索引 和 非聚簇索引两种，而 mysiam 只有 非聚簇索引，即 InnoDB 的聚簇索引文件就相当于是数据文件，而 mysiam 的 索引文件 和 数据文件是分开的，所有的索引树的叶子节点不存储完整数据行，而是存储该数据行在数据文件中的物理地址
- InnoDB 调用 select count(*) from t 来统计表中数据行数的时候需要全表扫描，而 mysiam 内部维护了一个字段就是表中数据行，直接调用就可以获取表中数据行，这也侧面说明了 mysiam 主要是用来查询的，因为 insert delete 操作都需要修改这个字段