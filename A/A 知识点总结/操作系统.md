# 简单总结三





## 1、操作系统为什么要划分用户态和内核态

[进入内核态究竟是什么意思？](https://www.zhihu.com/question/306127044)

```
内核态 和 用户态 是 CPU 的两个状态，而不是操作系统的两个状态
CPU 指令分为特权指令 和 非特权指令，特权指令在内核态状态下执行，非特权指令在用户态状态下执行
CPU 这两种状态的区别在于它们能够访问的资源不同

操作系统将物理内存分为两部分，比如 4GB，那么低位的 1GB 是内核态空间，高位的 3GB 是用户态空间
这个所谓的内核态空间是指 CPU 处于内核态模式时才能访问的地址。

内核态和用户态的空间是隔绝的，它们之间的数据交流一般是通过 copy 的方式。

操作系统的最重要的就是稳定性，必须保证用户态程序无法直接访问、修改内核态的资源。如果用户态程序要访问内核态的资源，那么需要使用内核态对外提供的接口，称作系统调用，这个类似我们 Java 类对外开放函数，别的类只能调用这些函数来操作该类内部的资源，防止其他类随意破坏内部的变量数据。同时，操作系统没有 Java 反射这种强制访问类内部信息的特性，所以它能够完整的保证稳定性
    
    
用户态切换到内核态的三种方式：
1）系统调用（这种系统调用的指令就是特权指令）
2）中断：当某个事件完成后，通知 CPU 暂停它正在执行的指令，然后去进行后续的处理，比如 DMA 拷贝完成后通知 CPU 去处理（程序员抱着认可的态度）
3）异常：当前正在 CPU 执行出现错误，可以选择尝试进行修复、终止程序运行、显示错误信息（程序员不希望看到的）
```





## 2、一次完整的 网络 IO 过程

```java
总共涉及到三部分：网卡缓冲区、socket 缓冲区、用户态缓冲区
    （这里需要注意一下，socket 缓冲区是位于内核态的，是 socket 通信的缓冲区，也可以说是 TCP 的滑动窗口（接收缓冲区和发送缓冲区），而平时讲的内核缓冲区是比如磁盘拷贝数据到内核态 或者 进程间通信 时用的）
    
一个完整的 IO 就是从 网卡设备缓冲区的数据 传输到 用户态缓存 的过程（或者反过来）
网卡驱动 将硬件层面的网卡设备 和 内核 进行连接，从而实现通信
当网卡接收到数据时，驱动会进行通知，DMA 会将网卡设备的数据拷贝到内核态的 socket 缓冲区，这里不会使用到 CPU。
    
DMA：外设（网卡、磁盘）不通过 CPU 直接跟内存进行交换数据的技术，当拷贝完成后会通知 CPU。出现 DMA 的原因就是为了减少 CPU 的调用

即 IO 设备（网卡、磁盘）和 内核态之间的拷贝是 DMA 执行的，内核态和用户态之间的拷贝是 CPU 执行的


一次完整的网络 IO 过程：
1）用户态进程调用 read() 读取网络数据
2）DMA 将网卡缓冲区中的数据拷贝到内核态的 socket 接收缓冲区（如果是 TCP 那么是 TCP 接收缓冲区）
2）CPU 将内核态的 socket 缓冲区中的数据拷贝到用户态
```





## 3、OS 进程（线程） 和 Java 线程 的状态转换

```java
1、OS 进程（线程）的五种状态
1）初始化：进程刚创建，正在分配资源
2）运行状态：进程正在被 CPU 调度
3）就绪状态：进程等待被 CPU 调度
4）阻塞状态：进程遇到 IO 事件、信号量 P 操作等待获取资源等阻塞操作，等待阻塞事件完成后会进入到就绪状态
5）终止状态：进程正常执行完毕退出 或者 异常终止 或者 被 kill 指令强制终止

2、Java 线程的六种状态
1）NEW：线程刚创建，还没有调用 start()
2）RUNNABLE：线程调用了 start()，正在被 CPU 调度或者等待被 CPU 调度
3）WAITING：无限期的等待，比如 wait()、join()、park() 等函数
4）TIMED_WAITING：超时等待，比如 wait(1000)、sleep(1000)、join(1000)、parkNanos()，这种都是限时等待，超过时间后会自动唤醒，不过如果 wait(1000) 醒来后仍然会进入到 EntryList 队列中等待获取锁，其他的情况则是进入到 RUNNABLE 状态，等待 CPU 调度
5）BLOCKED：Java 线程只有在获取 sync 锁才会陷入阻塞状态（即使是 IO 事件也是处于 RUNNABLE）
6）TEMPRXXX：线程正常退出或者异常退出。
    

线程让出 CPU 的函数：
1）wait()
2）sleep()
3）join()
4）park()
5）yield()：注意 yield 的线程是可能再次抢到 CPU 的，基本不会使用该方法
```



## 4、进程间的通信方式

```
1、匿名管道
	以内存的形式存在
	Linux 命令中的 |，表示将前一个命令的输出用于后一个命令的输入。
	只能用于父子进程
	是内核空间的一段缓存，大小有限
	只能传输字节流数据
	用完即毁
    单向通信，同步阻塞 BIO
2、命名管道
	以文件形式存在
	通信是通过网络连接的方式
	用于不同主机或者同个主机的任意两个进程
	通信的数据也是存在于内核空间的一段缓存中，大小有限
	命名管道存在两种数据格式：字节流模式和消息模式。假设发送方写入 10B，如果是字节流模式，接收方可以一次读取 10B 或者 1B 的；如果是消息模式，那么接收方必须将 10B 全部读取，如果读取其中一部分会读取失败。
	命名管道可以设置同步阻塞和同步非阻塞、单向通信和双向通信，但是它是半双工的，同一时间只能有一个进程能够发送数据（跟 socket 的主要区别在于此，socket 是全双工的）
3、消息队列
	消息队列是内核空间的一段链表，数据是以数据块的形式（类似于 Node）
	每个数据块只能存储一种相同类型的数据，不同的数据块可以存储不同类型的数据
	数据块的大小是有限的
	消息队列就跟邮箱一样，它不依赖于任何一个进程，即使不存在进程通信，这个邮箱也是存在的，并且每个进程读写都是指定哪个邮箱，而不会指定哪个进程，比如 send(A, message) 表示向 邮箱 A 发送数据，recv(A, message) 表示从 邮箱 A 读取数据。
    消息队列用于异步通信
4、共享内存
	管道和消息队列 数据都是存储在内核缓存中的，那么每次读写都需要进行 CPU 上下文切换 和 用户空间和内核空间的拷贝，效率低。
	共享内存是进程各自拿出一部分虚拟页，映射到同一个用户空间的物理地址上（当然某些情况下是可以映射到内核空间的，比如 mmap()），这样它们可以将数据放到共享内存上，别的存在映射的进程可以直接从这个共享内存上获取数据，不需要经过内核空间。
	共享内存支持多个进程，当关闭时由最后一个进程进行关闭。
6、信号量
	共享内存多个进程的读写会存在数据混乱的问题，因此需要一种机制 -- 信号量 来限制进程的数据访问顺序。
	信号量定义了两个操作：P 和 V，分别表示获取资源 和 释放资源。
	当一个进程执行 P 操作获取资源，如果所剩资源为 0，那么该进程阻塞，直到别的进程释放资源。
	sync 锁 和 lock 就是在资源只有 1 的情况下的信号量
5、信号
	信号是异步通信。
	通过发送信号来告知进程执行某个事件，比如 
	kill -15 指令会发送信号告知进程终止执行，不过它是否终止由它自己判断；
	kill -9 指令则是让进程强制终止执行；
	当子进程执行完成退出时，会给父进程发送信号，让父进程来处理剩下的 PCB（如果父进程不处理，那么会导致子进程变成僵尸进程，占用 PID）
6、socket
	socket 用于两个不同主机之间的进程通信。它是对 TCP/IP 的一层封装，让应用层能够更加方便的进行数据传输。
	一次完整的网络 IO 如下：
		1）DMA 将网卡设备缓冲区的数据拷贝到内核空间的缓冲区
		2）CPU 将内核空间缓冲区的数据拷贝到用户空间的缓冲区
		3）CPU 将用户空间缓冲区的数据拷贝到内核空间的 socket 缓冲区
		4）DMA 将内核空间的 socket 缓冲区数据拷贝到网卡设备的缓冲区进行发送
	这里需要两次 CPU copy 和 四次 CPU 上下文切换（内核态和用户态的切换），因此出现了零拷贝技术
	
	1、mmap()，利用 mmap() 来代替 read()
		1）DMA 将网卡设备的数据拷贝到内核空间的缓冲区
		2）操作系统将内核空间的这部分空间跟用户空间建立映射，省去了一次 CPU copy
		3）CPU 将内核空间缓冲区中的数据拷贝到 socket 缓冲区
		4）DMA 将 socket 缓冲区中的数据拷贝到网卡设备的缓冲区
	这里需要一次 CPU copy 和 四次 CPU 上下文切换
	2、sendfile() 一个函数代替 read() 和 write()
		1）DMA 将网卡设备的数据拷贝到内核空间的缓冲区
		2）CPU 将内核空间的缓冲区直接拷贝到 socket 缓冲区
		3）DMA 将 socket 缓冲区的数据拷贝到网卡设备的缓冲区
	这里需要一次 CPU copy 和 两次 CPU 上下文切换
	3、sendfile() + DMA 辅助
	这里需要零次 CPU copy 和 两次 CPU 上下文切换
	
```

<img src="https://pic.leetcode-cn.com/1607513553-YBsiHg-image.png" style="zoom:60%;" />





## 5、死锁

```java
简单讲的话，造成死锁的 3 个条件为：
1）资源有限，已经被持有的资源不能被其他进程剥夺
2）一个持有资源的进程去请求别的进程持有的资源
3）持有资源的进程不会主动释放自己的资源

造成死锁的四个必要条件：
1）资源互斥：一个资源只能被一个进程获取，
2）不可剥夺：进程不能强行剥夺其他进程已经获取的资源
3）永久保持：进程在没有执行到释放资源的代码时不会主动释放自己的资源，就算阻塞了也不会释放
4）环路等待：各个进程在持有资源的情况下去请求其他进程持有的资源，形成一个环路，谁都无法释放资源

预防死锁就是打破死锁的四个必要条件之一，避免死锁就是使用银行家算法这种的避免进入资源分配的不安全序列

预防死锁：
1）进程在获取资源前如果自己持有资源并且已经不需要了，那么释放该资源再去获取其他资源（自己实现 LinkedBlockingQueue 就是由于没有去解决这个问题导致出现死锁）
2）超时等待资源：避免无限期的等待资源，可以设置一个超时时间
3）统一锁的获取顺序

避免死锁：
	银行家算法，当一个进程申请资源时，假设如果将资源分配给进程，那么剩下的资源是否足够分配给其他进程去完成任务，如果不能够的话，那么所有的进程最终都无法完成任务，那么就不会释放已经持有的资源，陷入死锁状态，那么这就是不安全的序列，不能够分配给该进程，如果不会陷入死锁，那么就是安全序列，可以分配给该进程。
	
已经发生死锁的解决方法：
①、关机重启
②、撤销进程：将进入死锁的进程一个个进行撤销，终止进程，剥夺它们获取的资源，直到死锁解除，一般是从优先级低的进程开始撤销
③、进程回退：将进程回退到没有死锁的情况，一般需要去定时记录进程的状态，开销大

检测死锁的发生：
这里是针对 Java 线程，通过 jps 查看正在执行的线程，然后通过 jstack 来查看每个进程的状态，如果长时间处于 BLOCKED，那么就是在 sync 锁处发生死锁，如果长时间处于 WAITING，那么可能是调用 lock() 发生死锁
```





## 6、进程的调度算法

[非常详细的进程调度算法（里面包含了其他操作系统知识）](https://www.yuque.com/u90713/itme1v/eao1gz?language=en-us)

```
1、先来先服务算法
2、短作业优先算法（非抢占）
3、最短完成时间算法（抢占）
4、高响应比算法
5、时间片轮转算法
6、多级反馈队列调度算法
7、CFS 算法
```

```java
1、先来先服务算法（非抢占）
	先来任务先进行调度
	问题在于一个 100s 的长任务先来，一个 1s 的短任务先来，那么这个 1s 的短任务需要等待 100s 的时间，导致平均等待时间增长
	
2、短作业优先算法（非抢占）
	无论谁先来后到，执行时间短的任务先执行完成。
	问题在于如果短任务过多，可能会导致长任务饥饿
	
3、最短完成时间优先（抢占式）
	是在短作业优先的基础上进行的修改
	当一个新的任务到来时，会将所有任务和新来的任务进行比较，哪个能够在最短的时间内完成，那么就调度哪个任务，所以原先执行的任务的时间片可能会被新的任务或其他任务抢占。
	比如一个 100s 的长任务只剩下 1s，来了一个 10s 的短任务，那么仍然会继续执行长任务
	
4、高响应比优先（非抢占）
	满足短任务优先但又不会导致长任务饥饿
	①、当等待时间相同（短任务和长任务同时等待），短任务优先
	②、当任务执行完成的时间相同时（两个相同的短任务），等待时间长的优先（相当于先来先服务）
	③、长作业的优先级会随着等待时间的增加而提高，因此在等待一段时间后能够得到调度，不会饥饿。
	
5、时间片轮转算法
	不考虑优先级，按照先来先服务调度的思想，每个进程分配一个时间片
	如果进程在一个时间片内能够完成任务，那么出队，不会强制等到时间片结束，继续调用别的进程
	如果进程在一个时间片内没有完成任务，那么入队到队尾，等待下一次调度
	
	问题在于时间片的大小难以控制，时间片太短会导致进程上下文的频繁切换，时间片太长会导致后面调度的进程等待太长时间，对于用户交互来说不友好

6、多级反馈队列调度算法
	设置 n 个队列，最上面的队列优先级最高的，下面的队列优先级逐步降低，但是越往下分配的队列中任务分配的时间片也越长。
	①、新来的任务进入到最上面的队列中
	②、CPU 最先调度上层队列的任务
	③、如果一个任务在分配的时间片中没有执行完成，那么降级到下一个队列中
	④、如果一个进程在调度过程中主动放弃 CPU 时间片，那么不进行降级处理
		④的意图很简单：如果一个进程是一个跟用户交互型的任务，存在大量的 IO 操作，那么它会在时间片用完前主动放弃 CPU，这样的话不希望对它进行降级，让它能够继续被调度。
		不过 ④ 会导致以下问题：如果队列中存在大量的交互型任务，那么会导致下层队列任务的饥饿，同时恶意程序可能会利用这个问题来霸占 CPU，因此出现了 ⑤ 和 重写的 ④
	⑤、经过一段时间 S 后，将所有队列中的任务都重新加入到最上层队列中重新调度（防止饥饿）
	重写④、一个进程在某个队列待的时间超过了设置的值，那么强行降级到下一个队列中（即不允许一个进程待太长时间）。

7、CFS 调度算法
	这个算法是 Linux 正在使用的算法，完全公平调度算法。
	它定义了一个新的模型，给每个进程分配一个 vruntime(虚拟运行时间)，当一个进程得到调度，那么它的 vruntime 会增加，即如果一个进程没有得到调度，那么它的 vruntime 会比其他的进程要小，那么 CPU 就会去调度它。CPU 每次调度的都是 vruntime 最小的一个。
	为了让优先级高的进程有更多的时间片，所以优先级高的进程的 vruntime 的增长速率比其他进程慢
	同时存在以下概念：
	1）调度周期：将所有的进程调度一遍所需要的时间
	2）进程权重：表示进程的优先级
    一个调度周期内进程所需要分配的时间片：调度周期 * 进程权重 / 所有进程权重之和
		比如调度周期为 30s，进程 A 的权重为 1，进程 B 的权重为 2，那么进程 A 分配的时间片为 10s，进程 B 分配的时间片为 20s
	vruntime = 进程实际的运行时间 * 1024 / 进程权重
	在理想情况下，假设所有的进程在一个调度周期内的时间片都已经执行完毕，那么进程实际的运行时间 = 一个调度周期内进程需要分配的时间片，以上两式组合，有
	vruntime = 调度周期 * 1024 / 所有进程权重之和。
	可以看到，vruntime 的增长跟单个进程权重无关，如果所有进程在一个调度周期内都分配到了应得的时间片，那么它们最终的 vruntime 是相同的。
	不过对于进程权重大的进程，它在一个调度周期能需要分配更多的时间片，所以它的进程实际运行时间会比别的进程多，在分配了相同时间片的情况下，优先级高的进程它的 vruntime 会比其他进程要小，所以 CPU 会去调度这个进程，但是如果都得到了应得的时间片，那么它们最终的 vruntime 都是相同的。
	CFS 的设计思想：个人感觉是在 时间片轮转算法 上进行改进，时间片轮转算法是在某种意义上的公平，比如分蛋糕，人有高矮胖瘦，食量也不一样，时间片轮转算法就是每个人都分得相同份量的蛋糕，但是对于实际上而言，瘦的和胖的它们的满足感和饱腹感是不一样的，瘦的可能满足，但胖的不一定会满足。而 CFS 则不是按照份量，而是想让所有人都能够达到相同程度的满足感和饱腹感来分配蛋糕的份量，所以对于胖的会分配得多，但是最终它们的满足感和饱腹感是一样的。
	Linux 实现 CFS 底层使用的是红黑树，按照进程的 vruntime 进行排序，每次 O(logn) 找到最左边的节点进行调度即可。
```



## 7、孤儿进程 和 僵尸进程

```java
1、孤儿进程：
在 Linux 系统中，存在 PID = 1 的进程， init 进程
一个进程的父进程比该进程先一步终止，那么该进程为孤儿进程，会交托给 init 进程管理

这种进程没什么问题


2、僵尸进程
进程运行终止后，会变成僵尸进程，留下 PCB 结构，内部存储着进程的 PID
在进程运行终止后，会发送信号让父进程收尸，不过父进程默认是忽略的，因此系统中可能会充斥着大量的僵尸进程

危害：
一个僵尸进程会占用一个 PID ，PID 用来唯一标识一个进程，比如我们指令都是能够直接操作 PID 来操作进程的，而 PID 的数据是有限的，如果僵尸进程太多占用太多的 PID 可能会导致无法创建新进程

解决：
1、父进程重写 signal()，让父进程接收到信号后调用 wait(int pid) 去处理；
2、父进程重写 signal(SIGCHLD, SIG_IGN)，通知内核自己不关心子进程的结束，让 init 进程去处理
3、杀死父进程，让子进程变成孤儿进程
4、两次 fork()，父进程 fork() 创建一个子进程，子进程再 fork() 创建一个子子进程，真正的运行在子子进程中，然后 kill 子进程，让子子进程变成孤儿进程，交给 init 进程 管理
```





## 8、虚拟内存 和 虚拟地址

[虚拟内存的作用详解](https://draveness.me/whys-the-design-os-virtual-memory/)

[关于进程的4GB虚拟地址空间概念的理解](https://blog.csdn.net/sjtu_huang/article/details/6037556?utm_source=blogxgwz3)

```java
1、为什么需要虚拟地址？
如果没有虚拟地址，那么进程就是直接访问到物理内存，那么会产生以下问题：
1）地址空间不隔离：没有虚拟内存，进程都是能够直接访问物理内存的，而且进程之间可以访问相同的物理内存，这就导致可能存在恶意软件恶意篡改别的进程的数据，同时也可能是由于代码问题导致的非恶意的越界访问修改
2）程序的运行地址不稳定：进程的运行地址是不稳定的，每次运行的时候，哪里有足够的内存空间就将该内存分配给该进程，而当强制要访问某个地址空间时，会由于地址空间不隔离而访问到别的进程的数据
3）产生内存碎片：早期的操作系统，换入换出物理内存都是必须整个进程，同时它们运行也必须在连续的物理内存上，这样的话，假设 A、B、C 分别需要占用 10M、25M、30M，物理内存为 50M，那么当运行了 A 和 B 的时候，它们分别占据了 35M 内存，剩下的 15M 内存无法容纳整个 C 进程，所以无法有效利用，产生内存碎片。

为了解决上面的问题，操作系统在进程和物理内存之间添加了一层抽象层：虚拟地址。
通过 MMU 实现虚拟地址和物理地址的映射，每个进程直接访问的是虚拟地址，然后 CPU 再访问虚拟地址映射的物理地址上的数据。
1）实现地址空间隔离：每个进程分配到的虚拟地址都是一样的，都是从 0 开始计算的，它们能够直接访问的就是自己分配到的虚拟地址，然后借助 MMU 访问虚拟地址映射的物理地址，因此，只要操作系统没有将不同进程的虚拟页映射到相同的物理地址上，那么就相当于地址空间隔离了，因为进程无论怎么访问都不可能访问到别的进程空间。
2）解决内存碎片：比如分页机制，将虚拟地址 和 物理内存 分为大小相同的页通过 MMU 进行映射，所以它们不需要连续的内存，只要对进程来说它的虚拟地址是连续的就行了，底层映射的物理内存页面不需要连续。

2、为什么需要虚拟内存？
32位的操作系统下每个进程都自认为能够占用 4GB 内存，主内存一直分配，而当没有内存可以分配时，那么这时候就需要将某个进程中的某个页面替换下来
操作系统根据 页面淘汰策略（OPT、FIFO、LRU、LFU）对进程的虚拟页进行淘汰，淘汰的页面对应的物理页数据会存储在虚拟内存中（Linux 中的 swap 空间），然后将该进程的虚拟页跟物理页断开映射关系，然后将新进程的虚拟页跟该物理页建立映射关系，将数据存储在物理页中。
当进程访问的虚拟页上没有映射物理地址时，会产生缺页异常，此时会从虚拟内存中将该页的数据加载到物理内存中，同时将虚拟页和物理页建立映射关系。
因此，进程的数据实际上存储在 虚拟内存（磁盘）+ 物理内存 两个地方
虚拟内存和虚拟地址的配合使用能够让进程感觉自己占有很大的内存空间。
```





## 9、页面置换算法

```java
1、OPT
	这种是理想的置换算法，得到后面访问页的顺序，淘汰掉永久不使用或者最久不会使用的页
	但是问题在于我们无法准确的得到页的访问顺序

2、FIFO
	先调用的先淘汰
	FIFO 的问题在于它会经常发生抖动，因为先调用的往往是需要频繁访问的，而 FIFO 会将需要频繁访问的页给淘汰掉，后面访问又需要置换回来，导致页面的命中率降低，频繁的换入换出
	同时 FIFO 会出现 Belady 现象，随着页面存储容量的增加，按概率来讲 FIFO 页面命中率逐渐降低

3、LRU
	最久未使用的先淘汰
	它淘汰的是最久未使用的页，这也相当于是从调用概率上来讲，留下的算是经常调用的页面，淘汰的是不经常使用的页面
	所以 LRU 不会发生 Belady。

4、LFU
	最近最少使用的先淘汰
	在 LRU 的基础上进行的升级，将最少使用次数的页面集合中淘汰掉最久未使用的页面。
```



## 10、操作系统虚拟内存换页的过程

```java
访问虚拟页 -> 虚拟页没有映射物理页 -> 产生缺页中断 -> 进入中断处理程序 -> 操作系统检查页面分配情况 -> 从虚拟内存磁盘中读取对应的数据页 -> 从物理内存中找到空闲的物理页（或者置换掉其他进程的物理页），将磁盘数据刷到物理页上 -> 建立映射关系 -> 恢复线程运行
```





## 11、内存管理

[MMU 和 页表](https://blog.csdn.net/qq_37718322/article/details/97815910)

```java
1、分段管理
将一个进程按照数据类型的不同分为多个不同的段，比如存储数据的集中为数据段，存储代码的集中为代码段
它会将每个段进行编号，比如 数据段的段号为 0，代码段的段号为 1
然后它会维护一张段表，每个段的编号作为索引，段表会记录该段在物理内存中的起始地址，以及该段界限（可以理解为大小）
比如 数据段在物理内存中的起始地址为 7000，段界限为 1000，那么它的末尾地址为 7000 + 1000 = 8000，那么它在物理内存的地址范围为 [7000, 8000]

地址转化过程：
1）分段机制下，虚拟地址分为两部分：段选择子和段内偏移量 d，通过段选择子可以得到段号
2）CPU 要访问某个数据的时候，CPU 根据虚拟地址的信息得到段号 和 段内偏移量 d，
3）如果 0 <= d <= 段界限，那么表示地址是有效的
4）根据段表查询出段号对应的物理起始地址，然后再加上段内偏移量，即可定位到要访问的数据。

分段的问题：存在外碎片和内碎片
1）外碎片：注意，段与段之间在物理内存中是不需要连续的，但是一个段的数据必须是连续的，这样的话如果一个段需要一段较大的物理内存，而剩余的连续内存不足以存储该段，实际上就会导致这些剩余的物理内存成为内存碎片。
2）内碎片：段只能作为一个整体换入换出，不能换掉其中的部分数据，注意的话，即使该段中有很多的数据是不会被使用的，也无法被换出，占据内存空间


2、分页机制
将一个进程的虚拟地址分为多个大小相同的空间，一般是 4KB，称作虚拟页，而同时再将物理地址也划分为多个大小相同的空间，称作物理块
由于页和块的大小是相同的，因此可以执行一一映射。
虚拟页和物理块之间的映射是通过页表来记录的。
页表上会记录对应页号映射的物理块的起始地址（具体看下面的图）
一个 CPU 内部会维护一个 MMU，MMU 上面有一个页面寄存器，记录了 CPU 当前调用的进程的页表地址。
进程访问的都是虚拟地址，所以 CPU 最先访问的是虚拟地址，然后通过内部的 MMU 获取页表，通过虚拟地址计算出页号，然后找到该页对应的物理块的起始地址，然后再通过偏移量去访问内存条中该物理块的偏移量的物理地址数据。

地址转化过程：
1）首先要访问的是虚拟地址 X，页的大小为 4KB
2）那么通过 X / 4KB 得到页号，对照页表可以得到物理块号
3）然后再通过 X % 4KB 得到物理块的偏移量，比如 X = 9000，那么页号为 9000 / 4000 = 2，偏移量为 9000 % 4000 = 1000
4）即该虚拟地址映射的数据为物理块号起始地址 + 1000 的位置

分页机制的特点：
将虚拟地址分为一个个的页，同时再将物理内存划分为相同大小的块，虚拟页和物理块能够实现映射，基本不会出现内存碎片，同时页不需要多大的连续内存空间


3、分段比较分页的特点：
1）分页机制单独一个页的数据对于用户来说是没有任何意义的，因为数据都分散的，而分段机制的每个段对用户来说是有意义的，因为是某种数据的集合。
2）分段可以更加简便的实现多个进程间的数据共享。要共享数据直接将数据段映射出去
3）段表和页表都是存储在内存中的，并且 CPU 执行的指令操作的地址都是虚拟地址，因此如果 CPU 要访问一个数据，那么它需要先访问内存获取段表/页表，再计算出物理地址，然后再访问内存获取真实数据，即分段和分页访问一次数据需要访问两次内存。


3、段页式管理
Linux 现在使用的就是段页式管理
段页式结合了分段 + 分页 两种机制，将进程按照数据类型分割为多个有意义的段，然后将每个段再划分为多个虚拟页
因此，这样就每个段又具有意义，同时通过分页又能够有效的利用物理地址防止内存碎片。

段页式管理下，虚拟地址分为三部分：段号、段内页号、页内偏移量
当 CPU 访问一个虚拟地址的时候，需要三次访问内存：
1）访问段表寄存器，获取段表
2）通过虚拟地址得到 段号 + 段内页号 + 页内偏移量，通过段表得到段号对应的页表的物理地址，通过该物理地址访问内存得到页表
3）通过页表 + 段内页号得到对应的页表项，得到物理块的起始地址，物理块起始地址 + 页内偏移量 访问内存获取数据。

段页式管理下，一个进程有一张段表 和 多张页表，CPU 中有段表寄存器，存储的是段表在内存中的起始地址，段表上的每个项记录的是该段对应的页表。
```

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTA3NTQzNi8yMDE5MDUvMTA3NTQzNi0yMDE5MDUyNDE3Mzk1MzE2MC04MjY0OTg1OTIucG5n?x-oss-process=image/format,png)

![img](https://img-blog.csdnimg.cn/2019073021055410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NzE4MzIy,size_16,color_FFFFFF,t_70)

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfVYxicDjAjl4nMxlmyJk7rkibwZfO6ibiaiaoRoiaCSu16NoWkpEVUVG0hHbBVJKdsveIL4J1446ZIc6vw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





## 12、进程和线程的区别

```java
1、进程是资源分配的基本单位，线程是 CPU 调度的基本单位，可以把进程当作一个平台，线程是该平台真正工作的员工，线程会共享进程中的资源（堆、方法区、打开的文件、虚拟地址页等），不过线程（员工）也有私有的资源（栈、程序计数器）
2、一个进程内部含有一个或多个线程，至少存在一个线程。
3、由于一个 CPU 只有一个 MMU，CPU 核心共用这个 MMU，所以一个 CPU 只能调度一个进程，多个 CPU 核心可以同时执行该进程中的多个线程（不过后续好像每个 CPU 核心都有一个 MMU，所以一个 CPU 核心可以调度一个进程）
4、进程上下文切换比线程上下文切换还要更加消耗资源，因为（同个）进程的线程上下文切换，它的虚拟地址页、CPU cache 等都是可以继续使用的，只需要切换线程私有的资源即可，而进程上下文切换或者不同进程的线程上下文切换，那么需要保存旧进程的虚拟地址页和其他资源，然后加载新进程的虚拟地址页和其他资源，同时 CPU cache 中的数据全部无效。
```





## 13、Linux 的线程是什么东西？

```java
Linux 本质上并没有线程的概念，即它没有为线程单独定义一个数据结构，它是把线程当作一个标准的进程来调用的，即 CPU 调度的仍然是进程，所谓的同个进程中的多个线程是能够共享这个大进程的某些资源的小进程，每个线程都有一个 task_struct 结构，称作 “轻量级进程”
	（task_struct：PCB 的一种实现）
相当于说我们创建一个进程，它是大进程，是资源分配的基本单位，单单只是用来存储资源的，而内部默认情况下有一个小进程，即我们自己说的线程，它具有一个 task_struct 结构，存储的是该小进程的信息，这个 task_struct 存储了该小进程的调用栈、优先级、进程的状态等，而它能够访问到外部大进程的资源。
如果存在多个小进程（多个线程），那么它们都有各自的私有资源，但能够共享外部的资源，即外部的大进程实际上不算作一个进程，单单只是一个资源分配的平台而已，真正 CPU 调度的是内部的这些小进程。


Linux 线程 和 fork() 子进程的区别：
Linux 线程是共享大进程的资源，是共享，它们操作的是同一份资源；fork() 出来的子进程则是拷贝父进程持有的资源，它操作的是父进程资源的副本。


Linux 的进程上下文切换和线程上下文切换：
1）进程上下文切换是切换外部大进程的资源，比如要调用大进程 2 中的某个线程，那么需要从大进程 1 切换到大进程 2，将大进程 1 的数据段、代码段、虚拟页之类的保存起来，然后将大进程 2 的数据段、代码段、虚拟页之类的进行刷新，然后再调用大进程 2 中的小进程（线程）。
	需要保存和刷新的资源比较大，同时 CPU cache 中是 大进程 1 的资源，对于大进程 2 来说是无效的，需要重新刷新
	一旦发生进程上下文切换，实际上必定也会跟随着线程上下文切换，因为进程上下文切换实际上是从大进程 1 的某个小进程切换到调用大进程 2 的某个小进程。
2）线程上下文切换是切换的内部的小进程，数据段、代码段、虚拟页都不需要进行刷新，只需要切换线程私有的 栈、线程ID（进程 PID）、进程的状态、PC 寄存器
```

<img src="https://pic.leetcode-cn.com/1609559719-sgtnAI-image.png" style="zoom:70%;" />





## 14、Linux 创建进程的大概过程

```java
首先，上面也说了，Linxu 的线程实际上是一个轻量级进程，使用的是进程的数据结构，CPU 调度的也是以这个轻量级进程为基本单位的，因为，我们一个 Java 进程部署在 Linux 上执行时，每个线程对应的是 Linux 的一个轻量级进程
我把这个这个 Java 进程称作大进程，把内部线程对应的线程称作小进程，平时讲的 PCB 结构实际上是小进程持有的，每个小进程都有一个 PID。
跟 Java 进程内部必定存在一个线程一样，一个 Linux 进程创建出来的时候必定存在一个大进程和一个小进程，CPU 调度的就是这个小进程

Linux 创建进程的过程：
1）先创建大进程，分配虚拟地址、堆等共享资源
2）再创建小进程，给它分配 PCB（内含内核栈和用户栈、进程的优先级、进程的状态等），这个小进程能够访问大进程的资源。
```

