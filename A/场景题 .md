# 场景题



## 1、普通大数据

> ### 10 亿个 IPv4地址，单机怎么找到出现次数top10的ip地址。如果这个文件全部能装入内存，最多会占多少内存

```
将 10亿 数据分成 1W 个数据块，每个文件找 TOP 10
然后将每个文件的 TOP 10 合并起来，再找 TOP 10

IP 地址 为 int 型，大小为 4B
10亿 个 IP 地址，那么需要 10亿 * 4B = 40亿B = 40 * 10^8B = 40 * 10^5KB = 40 * 10^2MB = 4GB
因此全部装入内存需要 4GB
```



>  ### 100万个ip地址，如何存这些ip地址，需要加入ip地址及判断ip地址是否存在，如何做

```
每个 ip 地址都是 32 位，那么直接转换为 int 型作为索引
然后使用一个 bitmap，在对应的索引位置处置 1 表示存在

加入 ip 地址就直接转换为 int 索引，在对应的 bitmap 处置 1
判断就直接判断对应的索引位置是否为 1
```



>  ### 有一个大文件有用户的登录信息，文件包含10亿条目，文件格式，uid，login_time，logout_time，编写一个函数，获得一天内登录的峰值人数

```
精确到秒的话，只需要开辟一个 24 * 60 * 60 的数组，记录对应的时间点的人数即可
```



>  ### 1TB 文件，里面每条记录都存在一个时间戳 和 数据，怎么找出在给定 时间范围内的所有数据

```
方法一：分为多个文件，对每个文件按照时间戳进行排序，然后二分查找获取每个文件中在 时间范围内的数据

方法二：O(n) 扫描一遍文件，获取时间戳中最小的时间 min 和最大的时间 max，跨度为 max - min，这样的话，假设跨度为 1000，那么按照 30 天之类的分为一个文件，比如 第 min 天到 第 min + 30 天的数据划分为一个文件
这样的话，当我们查找的时间跨度为 100 时，假设中间的 90 天是定在了 3 个文件中的，而有 5 天是在左相邻的一个文件中的，另外 5 天是在右相邻的文件中的，这样的话我们需要可以直接获取中间 3 个文件（90天）的所有数据，然后再对左右两边两个文件进行二分查找对应剩下的 10 天数据，高效
```







## 2、大字符串加减法

> ### 字符串加法：正整数

```
直接计算即可
```



>  ### 字符串加法：小数

```java
计算出 a 和 b 的两个的小数个数（indexOf(".")），当然需要先判断是否存在 "."
如果两个都是整数，那么直接运算
如果一个是整数或者两个都是小数，那么按照最长的小数长度对另一个进行补齐 0
比如 a = "1.2", b = "2.1234"
那么补齐后变成 a = "1.2000", b = "2.1234"
然后直接进行运算

    private void h(String a, String b){
        //进行小数点填充
        int point1 = a.indexOf(".");
        int point2 = b.indexOf(".");
        //小数长度
        int l1 = a.length() - point1 - 1;
        int l2 = b.length() - point2 - 1;
        //填充小数后面的 0
        if(point1 != -1 && point2 != -1){
            if(l1 > l2){
                b = addZero(l1 - l2, new StringBuilder(b));
            }else{
                a = addZero(l2 - l1, new StringBuilder(a));
            }
        }else if(point1 != -1){
            b = addZero(l1, new StringBuilder(b).append("."));
        }else if(point2 != -1){
            a = addZero(l2, new StringBuilder(a).append("."));
        }
        add(a, b);
    }
    private String addZero(int diff, StringBuilder sb){
        while(diff-- > 0){
            sb.append(0);
        }
        return sb.toString();
    }
    private void add(String a, String b){
        StringBuilder sb = new StringBuilder();
        int len1 = a.length();
        int len2 = b.length();

        int cin = 0;
        for(int i = len1 - 1, j = len2 - 1; i >= 0 || j >= 0; i--, j--){
            if(i >= 0 && a.charAt(i) == '.'){
                sb.append(".");
                continue;
            }
            int n1 = i >= 0 ? a.charAt(i) - '0' : 0;
            int n2 = j >= 0 ? b.charAt(j) - '0' : 0;
            int sum = n1 + n2 + cin;
            sb.append(sum % 10);
            cin = sum / 10;
        }
        if(cin == 1){
            sb.append(1);
        }
        System.out.println(sb.reverse().toString());
    }
```



> ### 字符串减法：

```java
先提取出符号位，然后判断都当作是正数的情况下哪个比较大，使用大的减去小的，这时候使用 int[] 来接受每一位的结果
然后从后往前判断 int[] 每一位的结果，如果 res[i + 1] < 0，那么向 res[i] 借位
即 res[i + 1] += 10, res[i]--

最终将返回的结果添加符号位
```





## 3、两个大文件找共同的 url

> ### 两个10G的文件，里面是一些url，内存只有1G，如何找到两个文件相同的url？

```
这种大数据问题，一般都是需要大化小的

遍历一遍 两个文件，将每个文件划分 1000 个文件，对里面的每个 url 进行 hash，比如 获取对应的 hashCode，然后 hashCode % 1000，放到对应的文件中，这样每个文件平均下来就是 1000MB

这样的话就有两份 1000 个文件，标号为 a0,,,a999 和 b0,,,b999

url 相同的字符串肯定 hash 到相同标号下的文件了，这样的话我们只需要先读取 a0，将里面的 url 使用 HashMap 存储，这样内存刚好差不多占用 1G，再一条条读取 b0，相同的就直接保存了
```





## 4、大数据排序

具体 看 <https://www.sohu.com/a/258751244_818692>



题目：假设存在 8G 数据，内存只有 2G，如何进行排序？



将 8G 数据分割为多个数据文件，使用 归并算法进行排序

由于内存只有 2G，所以每个文件最大只能是 2G，这样才能整个文件放入内存中进行排序

因此分割为 4 个文件

<img src="http://5b0988e595225.cdn.sohucs.com/images/20181011/462a9926df4c4e6ca44d4340bb243a0d.png" style="zoom:70%;" />

排序后每个文件都是有序的，那么对文件两两进行归并，两个合并为 1 个，这样最终就剩下 2 个4G 文件，然后对 4G 文件进行合并，最终剩下一个有序的 8G 文件

不过这里有个问题，一个文件大小为 2G，第一次归并的时候如果将两个文件都读取进内存，那么不就需要 4G 内存了吗，这样显然是不可行的。因此，**外排序的归并不是简单的全部读取进行内存的两两归并**

它是逐个从文件中读取，然后进行比较的

从文件1 和 文件2 中各读取一个数据，然后进行比较，小的数据 写回磁盘，再从这个小数据原本所在的文件中再读取一个数进行比较，这样一直比较，直到两个文件都读取完成，这样也就排序完成了

![img](http://5b0988e595225.cdn.sohucs.com/images/20181011/5db99651c0ac4e73aabf4013592a3917.png)



但是这样的存在一个缺点，8G 数据中的 每个数据都需要进行 3次 磁盘读取 + 3次 磁盘写入，性能差

```
1、 将8G 数据分割为 4 个文件，一次读取+写入
2、 任意两个 2G 文件进行归并变成 2 个 4G 文件，一次读取 + 写入
3、 2 个 4G 文件进行合并，变成 1 个 8G 文件，一次读取 + 写入
```



优化点：

我们可以使用多路归并，将 4 个 2G 文件一起进行归并，一次合并为 1个 8G 文件

这样就只需要 2次 磁盘读取 + 2次 磁盘写入，称为 4 路归并（n 路一起合并就称为 n 路归并）

假设有 12 个数据，内存只能装 3 个

<img src="http://5b0988e595225.cdn.sohucs.com/images/20181011/338fb200f69a46ff85a3ac78c9a4e2c7.png" style="zoom:70%;" />

那么 4 路归并如下：

![img](http://5b0988e595225.cdn.sohucs.com/images/20181011/bfd2ef5994d74dd793dbbf4b86dadc34.png)

那么这 4 个数据怎么获取其中的最小值呢？？？

难道每次都对 4 个数据 遍历一遍 或者 排序 吗？

我们需要明确一个问题，我们只需要获取其中的最小值而已，其他元素的关系我们毫不关心，因此只需要一个数据结构只维护最小值即可，这个数据结构就是 **最小堆，可以使用优先队列来实现**





## 5、大数据找中位数

具体看 <https://www.nowcoder.com/questionTerminal/359d6869d5ce4738bf9c9a42b67d9568>



假设 100亿 个数据存储在大文件中，要找其中的中位数，但是内存不足容纳整个文件。

有两种解决方法：

①、外排序，然后直接定位中位数

②、将每个数字以二进制的形式来表示，首先按照最高位来进行分割，最高位为 0 的放在 file_0 上，最高位为 1 的放在 file_1 上，这样等到全部分完后，假设 file_0 有 60亿 个数组，file_1 中有 40亿 个数字，那么中位数就在 file_0 排序后第 10亿 个数字

因为 file_1 全部都是负数，file_0 全部都是正数，中位数是在第 50亿 个，因此跳过负数的 40亿 个，就位于正数的第 10亿 个

然后继续对 file_0 使用相同的做法进行分割，这次参照次高位，第 31 位为 0 的，放在 file_0_0 上，第 31 位为 1 的，放在 file_0_1 上，全部分完后，假设 file_0_0 和 file_0_1 上各自存在 30亿 个数字，那么中位数就在 file_0_0 上的第 10亿 个数字

因为 file_0_0 上的数字比 file_0_1 上的数字小，所以按照顺序中位数是在 file_0_0 上

然后继续对 file_0_0 进行分割，这次参照第 30 位，，，以此类推，直到分割出来的文件大小足够存储在内存上时，直接使用内排序进行排序，然后获取中位数





## 6、秒杀超卖、少卖问题

具体看  https://blog.csdn.net/qq_42046105/article/details/102577610 



在不加锁的情况下，超卖问题如下：

 ![img](https://pic4.zhimg.com/v2-fbc25a9c9db03b94cd73480d89747d17_b.jpg)

超卖问题是由于 查询 和 下单 不是原子性的，而是分开的，这就导致了在同一时间 线程 A 和 线程 B 都查询出 12 台手机

但是在 线程 A 下单后，只剩下 2 台手机，而线程 B 的下单操作是在前面查询的结果上操作的，这就导致了库存变成 -8 

一般情况下，当库存不足够的时候，是不能生成订单的，即如果生成了订单，那么就必须保证库存足够，不然用户下单了，结果支付的时候显示库存不足，这不是开玩笑么。。。



**超卖解决方法：**队列请求串行化、分布式锁

队列串行化不太行，同一时间只能处理一个请求，毫无效率可言

因此常用的是分布式锁



> ### 分布式锁解决超卖问题

使用 redis 分布式锁，每个商品对应一个 分布式 key，一次只能有一个线程请求分布式锁成功，其他线程还是需要等待

假设一次完整的请求响应需要 20ms，1s = 1000ms，因此 1s 只能处理 50 个请求

 ![640?wx_fmt=png](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLaHXy6Z3IGYdxcE6cficS3ejcWLpsUKcTH9ql2Tws4LywTmcKtQz9oJPUFBqRwUzJSibskBOKRfpwpA/640?wx_fmt=png)

 

这种做法显然跟 队列请求串行化 没有任何区别，毫无效率可言，对于秒杀这种情况，1s 可能 几千、几万的并发量，这种效率显然是无法接受的，因此需要对 分布式锁 进行优化



既然单一的分布式锁并发度低，那么我们可以类似 ConcurrentHashMap 这样的做法，它有一个很重要的特性：分段锁；这个段可以是 JDK 7 的 Segment，也可以是 JDK 8 的一个槽位

假设某个商品的库存为 1000，那么在 redjis 中开 20 个槽，每个槽库存为 50，每个槽对应一个分布式锁 key，然后用户的请求可以根据 id hash 到对应的槽位上，获取对应的分布式锁



如果一个用户请求 hash 到某个槽位上，获取分布式锁后，发现该槽位的库存为 0 了，这时候就有两种处理选择了：

- 选择一：直接将这个请求打回，不执行；因为在秒杀场景下并发量很高，一般是供不应求，其他槽位上的库存自然会有别的请求去获取
- 选择二：释放分布式锁，然后可以选择重新进行一次 hash 或者 直接按照顺序定位下一个槽位上，获取分布式锁，如果有库存，那么执行操作，如果没有库存，那么继续定位到其他的槽位
  - 这个做法类似 JDK 8 中 ConcurrentHashMap 的 size()，使用辅助数组 CounterCell 来解决竞争问题，一旦某个位置上的 CounterCell 存在竞争，那么 hash 到其他位置上的 CounterCell，直到 CAS 成功为止



注意，当 redis 库存发生改变后，需要同步到 DB 中，这时候可以选择 异步写入 DB，这段时间会数据不一致，不过只要请求一直打到 redis 上即可



> ### 少卖问题

如果用户 hash 到的槽位上库存足够，那么下单后减库存，如果用户没有支付的话，那么这个减的库存别的用户无法获取，但实际上它还在，如果库存没有加回来，那么减去的库存就无法卖出

即如果用户恶意下单，那么就会出现少卖问题

因此我们需要设置在用户下单后同时减库存，减库存 和 生成订单应该是异步的，比如先减库存然后 异步生成订单，因为订单涉及到 DB 写入，所以速度较慢，可以异步写入，这里减库存可以保证不超卖，同时异步生成订单可以保证处理速度

订单需要设置有效时间，比如 15min，如果这段时间用户没有支付，那么订单失效，并且将减的库存加回去让别的用户下单，保证不少卖。





## 7、设计 复制粘贴

[电脑复制粘贴背后发生了什么？ - SuperSodaSea的回答 - 知乎](https://www.zhihu.com/question/66284095/answer/240367965)

[我们在电脑按下ctrl+c，剪切板储存了哪些信息？ - ShellBin的回答 - 知乎](https://www.zhihu.com/question/398335345/answer/1258940042)

windows 存在一个 剪贴板，用于进程间的复制粘贴

所谓的剪贴板，实际上是 windows 中 RAM（内存）中的一个 缓冲区 buffer，它相当于是**共享内存**，对于所有的进程都可见，这样 进程 A 复制的数据才能对 进程B 可见，从而粘贴到 进程 B 上



剪贴板 复制粘贴 的 api 执行顺序如下：

```C
Bool OpenClipboard(HWND hWndNewOwner);    
//指定关联到打开的剪切板的窗口句柄，传入NULL表示关联到当前任务。
//每次只允许一个进程打开并访问，使用后需要关闭，不然其他进程不能继续使用。

Bool EmptyClipboard(void);                
//写入新内容前必须先清空，否则也是不能写入的。

HGLOBAL GlobalAlloc(UINT uFlags, SIZE\_T dwBytes);
//在堆内存申请内存空间，需要传入分配内存的属性和大小
//成功时指向该内存，失败返回 NULL

LPVOID GlobalLock(HGLOBAL hMem);
//锁定刚刚申请到的内存空间，锁定计数器+1，GlobalUnLock计数器-1为负一
//成功返回内存对象起始指针，失败返回NULL
					
HANDLE SetClipboardData(UINT uFormat, HANDLE hMem);//UINT uFormat：数据类型
//设置剪切板，执行成功返回句柄，否则 NULL

BOOL GlobalUnlock(HGLOBAL hMem);
//解锁内存计数器，此时GlobalUnLock计数器+1为零

Bool CloseClipboard(void);
//关闭剪切板，此时其他进程才能使用

HANDLE GetClipboardData(UINT uFormat);//UINT uFormat：数据类型
//获取剪切板数据
```



复制的数据类型有两种：

- 单纯的文本数据
- 文件

剪贴板不直接存放复制的数据，而是会存储指针、文件路径之类的



对于文本数据，假设 进程 A 要复制 "Hello" 这个字符串，那么步骤如下：

- 进程 A 调用 OpenClipboard() 打开剪贴板，类似于 对剪贴板加锁，为了数据安全，剪贴板一次只能有一个进程访问
- 进程 A 调用 EmptyClipboard() 情况剪贴板关联的数据，否则无法关联新的数据
- 进程 A 调用 GlobalAlloc()  申请分配内存，传入参数为所需的内存空间大小，方法返回申请到的内存地址指针
- 进程 A 调用 GlobalLock() 对刚刚申请到的 内存 进行加锁，并将文本数据写入到该内存中
- 进程 A 调用 SetClipboardData() 将 内存地址指针 写入到 剪贴板 中
- 进程 A 调用 GlobalUnlock() 解锁（其实我不太理解这里为什么要对申请到的内存加锁解锁，如果是为了防止别的进程访问，那么这里解锁后这个内存不也会被别的进程访问吗，，，有点问题）
- 进程 A 调用 CloseClipboard() 关闭 剪贴板，类似于 对剪贴板释放锁，这样别的进程才能够访问，从而获取到剪贴板的数据
- 进程 B 调用 GetClipboardData() 获取剪贴板关联的内容



对于文件的复制，那么剪贴板存储的是文件的路径，因此，如果文件删除了，那么剪贴板存储的文件路径相当于失效了

- 当进程 A 复制了 `a.txt` 文件，这样在剪贴板中记录的是 `a.txt` 的文件路径
- 我们反手把这个文件删除了
- 进程 B 要粘贴这个文件，发现剪贴板中路径指向的位置不存在该文件，那么就 **提示文件不存在，请找到正确的位置**



这里大概说明一下 windows 回收站的实现：回收站是 C 盘中的一个特殊文件夹，删除的文件会先移动到这个文件夹中，在这里的文件同时会记录原先的文件路径 和 删除时间等信息，方便还原和查看