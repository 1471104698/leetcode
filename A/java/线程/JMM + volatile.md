# JMM + volatile





## 1、JMM



> ### 背景介绍

早期的 CPU 的 速度 和 内存是差不多的， CPU 处理完 能很快写入内存

但是如今，CPU 的指令执行速度快得一批，内存的速度跟不上了，比如 1s CPU 需要写入 100 个数据，而 内存 1s 只能写入 1 个数据，这样的话，如果 CPU 就相当于降低速度去写数据，效率降低

为了解决这个问题，在 CPU 和 内存 中间引入了 cache，即高速缓存，它的速度跟 CPU 差不多，CPU 只需要将数据复制到 cache 中，然后去干自己的事，让 cache 慢慢将数据写入到内存中

需要注意的是：现在每台计算机不再是单核 CPU ，而是多核 CPU，每个 CPU 多对应一个自己的 cache

这样的话，就涉及到 **缓存一致性**

 ![img](https://pic2.zhimg.com/80/v2-3caf591483d67ccfd6ca01ef054a146f_720w.jpg) 

> ### JMM 是什么？

JMM 又叫 Java 内存模型，它跟 `jvm` 不一样啊。别搞错了啊。。。

它规定了 多线程对于 共享变量 的访问规则，以及将 共享变量 存储到内存，从内存中读取 共享变量 的底层细节



它会规定了 每个线程都有自己的工作内存，这个工作内存就跟上面的 CPU 对应的 cache 一样

每个线程对变量的操作都是在工作内存中，并且操作的是 内存中变量的副本，它不能直接操作内存中的变量，因为是共享的

操作完成，再将工作内存中的值写入到内存中

 ![img](https://picb.zhimg.com/80/v2-f0364f6f863d5730e2b962ac6b3387e2_720w.jpg) 





## 2、volatile



我们上面说了，JMM 规定了每个线程都有各自的工作内存，并且操作的都是在工作内存中的变量副本

正是因为这种模型，所以才存在数据可见性的问题

> ### 数据可见性问题

上面说了，线程操作的都是自己工作内存中的变量副本，而各个线程的工作内存又都是独立的，无法互相访问

并且它们从主存获取副本后，操作过程中基本不会再去访问主存

这样的话，当 线程 A 修改变量 x 后，写入到内存中，但是 线程 B 由于没有访问内存，它仍然使用的是在 自己工作内存中的旧值，这就导致了数据不可见



> ### 可见性问题的解决方案



> 加锁

当线程 获取  synchronized  锁后，会清空自己的工作内存，然后从主存中读取新的变量到工作内存中

然后再执行完代码后，将工作内存中的值重新写回主存，然后再释放锁

而获取不到锁的线程会阻塞，不会提前去读取主存，等到获取锁后再读取主存

这样的话就能保证数据是最新的

**这个是  synchronized 的可见性的原理**



> volatile 修饰共享变量

当线程操作完某个变量 x 后，将 变量 x 从工作内存中写回 主存，当它发现这个变量是 volatile 修饰时，那么就会让其他线程的工作内存中的 缓存行失效（**注意，不只是 volatile 变量失效，而是缓存行里的所有数据**）

通过总线嗅探，CPU 会通过嗅探在总线上传播的数据，如果发现线程的缓存过期了，那么就重新到主存中读取，就会去访问主存，获取最新值

(**并且还需要指令重排序，后面会讲**)





> ### 指令重排序

volatile 保证了修饰变量的可见性，并且它还能 **禁止 指令重排序**



JVM 会将代码编译成一条条的指令，指令重排序就是 修改指令的执行顺序 来提高性能

下面是一段 C 语言代码：

```C
int a, b;
void foo(void)
{
	a = b + 11;
	b = 0;
}

```

通过工具查看编译结果：

```C
0000000000000750 <foo>:
 750:   90000080        adrp    x0, 10000 <__FRAME_END__+0xf6b8>
 754:   90000081        adrp    x1, 10000 <__FRAME_END__+0xf6b8>
 758:   f947dc00        ldr     x0, [x0, #4024] // 取b内存地址
 75c:   f947e821        ldr     x1, [x1, #4048] // 取a内存地址
 760:   b9400002        ldr     w2, [x0]        // 寄存器w2 = b(内存地址)
 764:   b900001f        str     wzr, [x0]       // b(内存地址) = 0
 768:   11002c40        add     w0, w2, #0xb    // 寄存器w0 = b + 11 
 76c:   b9000020        str     w0, [x1]        // w0寄存器的值存入a(内存)
 770:   d65f03c0        ret
 774:   d503201f        nop

```

**编译得到的汇编代码和我们原本的C语言代码不顺序并不一致**，相当于是下面的 C 语言代码：

```java
int a, b;
void foo(void)
{
    b = 0;
    a = b + 11;
}

```



在单线程时代这个没有什么问题，但是在多线程时代，某个代码指令顺序的发生改变可能会影响到别的线程导致错误

比如下面的 java 代码

```java
class A{
    boolean flag = false;
    public void h1(int op){
    	//进行一系列操作
    	//...	
   		
   		flag = true;
    }
    public void h2(){
        while(!flag){
            //wait;
        }
        //进行操作
    }
}
```

线程 A 调用 h1()，线程 B 调用 h2()，本意是通过 flag 来限制 线程 B 等待 线程 A 执行完后再进行执行的

但是如果由于编译器发生指令重排序（因为对于 h1() 方法来说， flag 的先执行与否都没有太大影响，因此可能发生指令重排），导致 flag 提前为 true，那么就相当于是给 线程 B 提前放行了，因此会导致错误



因此通过添加 volatile 保证不会发生指令重排

如下代码：

```java
class A{
    // 此变量必须定义为volatile
    volatile boolean flag = false;
    int a = 0;
    int b = 0;
	// 线程A中执行
    public void h1(){
        a = 2;
        b = 3;
        flag = true;
    }
    
    // 在线程B中执行
    public void h2(){
        while (!flag) {    
            wait();
        }
        System.out.println(a);
        System.out.println(b);
    }
}

```

这样的话，编译器就不会将 flag 和 上面的其他执行指令进行重排序，原理是由于 flag = true 是 volatile 写

而 volatile 在 volatile 写前后各加一道内存屏障，保证不会跟其他代码进行重排序

![img](https://picb.zhimg.com/80/v2-1c459334f09b418add91ac2831f4113f_720w.jpg)

可以转换为上面的例子看：

```C
class A{
    // 此变量必须定义为volatile
    volatile boolean flag = false;
    int a = 0;
    int b = 0;
    public void h1(int op){
    	a = 2;
        b = 3;
        
   		barrier(); // 插入编译器内存屏障，禁止指令重排序
   		flag = true;
        barrier(); // 插入编译器内存屏障，禁止指令重排序
    }
    public void h2(){
        while(!flag){
            //wait;
        }
        System.out.println(a);
        System.out.println(b);
    }
}
```



> ### volatile 保证可见性原理



在 JDK 1.5 的时候，对 volatile 变量是禁用缓存的，即线程无法缓存 volatile 变量，每次使用只能去主存里读，这样就保证了 volatile 变量一定都是最新值，但是这样明显效率很低



那么之后的 volatile 是如何保证可见性的呢？

**通过 hb 规则**

hb  规则 有很多条，其中有一条是：**一个线程的 volatile 的写必须先于 另一个线程 对这个 volatile 变量 的读**

这个意思不能单纯的认为 对 volatile 变量的写 发生在 对 volatile 变量的读之前，因为这样其实还是没有真正理解它的意思

用通俗点的话来讲，就是 **对 volatile 变量的写 以及 之前的所有写操作 都要 对后面 对 volatile 变量的读 可见**



**这是什么意思呢？**

如下面的案例

```java
class A{
    // 此变量必须定义为volatile
    volatile boolean flag = false;
    int a = 0;
    int b = 0;
	// 线程A中执行
    public void h1(){
        a = 2;
        b = 3;
        flag = true;
    }
    
    // 在线程B中执行
    public void h2(){
        while (!flag) {    
            wait();
        }
        System.out.println(a);
        System.out.println(b);
    }
}

```

上面 flag 是一个 volatile，那么线程 A 对 flag 写完后，需要将前面的所有写操作都刷新回内存，

即 将 a = 2 和 b = 3 以及 flag = true 刷新回内存

对于线程 B 来讲，因为 线程 B 是在一直读取 flag 的，那最开始是在缓存中读的，而由于 线程 A 修改了 flag，导致它缓存失效，所以它会去主存 读取最新的值 a 和 b 和 flag，这样就获取到新值

正是因为 线程 B 是使用 while 循环不停的在读，即存在 线程 A 写回主存后 进行读的时机，如果线程 B 在线程 A 写回主存后没有进行 对 flag 进行使用 或者 读操作，那么就无法感知到 a 和 b 的值的变化



而 hb 规则解决可见性的原理就是 

- volatile 写 会将之前的写操作立马写回主存，同时会让其他线程的缓存失效，等到读取 voaltile 变量时会重新去主存读取新值
- 禁止重排序，否则上面的 flag 跟 a = 2 和 b = 3 重排序了，那么就有问题了



> ### happens-before 规则

- 程序顺序规则：代码在单线程中的执行是有序的；所谓的有序是指虽然编译器会进行重排序，但是对程序的执行结果不会造成影响，比如 a = 2 和 b = 3 的任意重排序，这个对于当前线程调用没有任何影响；但是在多线程情况下会出现问题，比如上面的 flag = true 和 a = 2 发生重排序
- 监视器锁规则：对于 syn 锁，一个线程释放锁后对于后面获取锁的线程的所有写操作是可见的（上面说的 syn 可见性的原理）
- volatile 规则：上面说了
- 传递性：A hb B, B hb C，那么 A hb C



## 3、volatile、synchronized 和 lock 的区别和使用场景



### 1、单例模式中 volatile 和 synchronized  共同作用



在 8 种单例模式写法中，有这么一种写法：

```java
class Singleton{
    //volatile 修饰，保证可见性和禁止指令重排
    private volatile static Singleton instance = null;
    
    //构造方法私有化
    private Singleton(){}
    
    public static Singleton getInstance(){
		//双重检查
        if(instance == null){
            //锁住 Class 对象，类锁（同时还有对象锁，注意，对象有多个，Class 类只有一个）
            synchronized(Singleton.class){
                if(instance == null){
                    //赋值方法非原子性
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```



> ### **上面 volatile 有什么作用？**

很容易看出的是保证可见性，但是这个 禁止指令重排有什么作用呢？

我们需要先知道，上面那个赋值语句的执行 跟 i++ 一样不是原子性的，它分为如下操作：

- 分配内存空间
- 调用构造方法，创建实例对象
- 将对象所在地址返回给引用

如果发生指令重排的话，那么将 2 3 步调换，先分配内存空间，然后再直接将地址返回给引用，最后再创建实例对象

假设在将地址返回给引用，这时候 instance 引用指向了一个地址，不再为空

地址上的实例对象还没有创建的时候，这里也不说什么多线程和单线程，假设是单线程，那么到这一步前 CPU 调用其他的线程，发现 instance 不为空，那么直接拿去用了， 那么就自然存在空指针异常了，多线程同样问题

**注意：其他线程在判断的时候是在第一个判断 if(instance == null) 的时候发现不为空的，还没有到 synchronized，这时候跟 synchronized 保证的原子性无关**



> #### **上面 synchronized 有什么作用？**

保证赋值语句的原子性，上面也说了赋值语句 本身是非原子性的

因此需要赋值语句来保证原子性，这个不用讲



简单讲，volatile 主要是禁止指令重排序，防止 其他线程在第一个 if 判断处获取一个空对象

synchronized 是保证赋值语句的原子性，不会多个线程创建多个对象，这就不是真正意义上的单例





### 1、三者的特点以及使用场景



> ### volatile

- 保证可见性
- 禁止指令重排
- 不能保证原子性，并且只能修饰 共享变量

在只需要保证可见性 或者 禁止指令重排的时候可以使用，比如 CAS 中的 state 和 单例模式 进行 赋值语句指令重排



> ### synchronized

- 修饰方法和代码块

- 代码简洁
- 能够保证可见性（**线程获取锁前会清空工作内存，读取主存新值**）
- 原子性
- 可重入，并且有 偏向锁、轻量级锁、重量级锁 三种，会根据竞争情况进行锁升级

如果仅仅需要同步线程，而不需要什么其他操作，使用 synchronized  就行了



> ### lock

- 具有灵活性，**灵活性在于可以手动上锁和释放锁，并且可以指定等待锁的时间，不会死等**，线程池中 Worker 类 就继承了 AQS，赋予了 tryAcquire() 锁的语义，当调用 shutdown() 的时候线程池可以调用 teyLock() 判断线程是否空闲
- 能够保证可见性（**由于 state 是 volatile 的，所以释放锁，即修改 state 的时候，会将前面的操作一并刷新入内存，这样其他线程看得到了**）
- 可实现重入
- 可以配套使用 `lock.newCondition()` 来指定不同类型的锁对象，可以方便唤醒某种类型的线程，用于生产者消费者模式，

lock 的灵活性使得可以避免无限期的阻塞，以及可以用来线程池判断线程的状态

但是由于需要手动释放锁，所以如果忘了在 finally 中调用 unlock()，那么问题就大了



