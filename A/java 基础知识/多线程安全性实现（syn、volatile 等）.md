# 多线程安全性实现（syn、volatile 等）

## 1、synchronized 

关于 synchronized  的几个问题

- synchronized 原理
- synchronized 锁升级过程
- synchronized 是重量级锁，那有哪些轻量级锁



> ### synchronized 原理



**synchronized 最开始保证 线程安全 / 原子性 是因为它是一把重量级锁，会阻塞其他的线程**

**保证可见性就是因为线程在获取锁时会将工作内存清空，然后从内存中读取新的数据，释放锁前会将工作内存中的数据写回主存**



**synchronized 重量级锁的实现实际上是靠 Java 对象头**

Java 对象都是 存储在堆中的，而对象实例不仅仅只有用户写的代码，JVM 会自动添加一些额外的信息，来帮助一些事情，这些信息就构成了对象头

对象头包括：Mark Word、Klass Word、数组长度

- Mark Word 64 位，内部分割为多个部分，用来标记锁的状态、是否可 GC 回收、以及 `hashCode`
- Klass Word 标记了该对象在方法区中的 元数据，通过该指针确定是哪个类的实例
- 数组长度 是只有该对象为数组时才有的

 ![img](https://img-blog.csdnimg.cn/20190115141050902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NDRE5fQ1A=,size_16,color_FFFFFF,t_70) 

 

而 synchronized 就是用到了 对象头中的 Mark Word  信息

最开始的 synchronized  是重量级锁，在 Mark Word 中只有 无锁 和 有锁（重量级锁） 两种状态

锁 的底层是 JVM 基于 monitor 对象来实现的，当某个代码块添加了 synchronized  关键字，那么在编译的时候，就是在代码块前面添加一条 `monitorenter` 指令表示加锁，在方法结束处 和 异常处 添加一条 `monitorexit` 指令表示释放锁

它内部还有一个计数器，当持有锁的线程再次需要获得锁的时候，可以直接获取，然后计数器 +1，当计数器为 0 的时候，那么释放锁（原理跟上面的 ReentrantLock 的可重入实现差不多）



> ### 锁升级过程

后续版本的 JDK 对 synchronized  进行了优化，使得 synchronized  的性能跟 ReentrantLock 差不多，差别主要是 ReentrantLock 用户能够自行释放锁

原本的 synchronized  只有两个状态：无锁，重量级锁；

后续再添加了两种状态，变成了 四种状态：**无锁、偏向锁、轻量级锁、重量级锁**

**偏向锁、轻量级锁 都是 乐观锁， 重量级锁 是 悲观锁**



偏向锁是 认为大多数的锁都不会存在竞争，一般都是由一个线程持有

轻量级锁是 认为两个线程使用锁的时间是错开的，即基本不会同时使用，最多也就通过 CAS 等待一会而已

重量级锁是 锁竞争激烈的情况下，为了不让 其他线程 CAS 浪费 CPU 空转，直接阻塞线程，同时它重量级的原因就是，阻塞了线程后需要去唤醒线程，然后再去切换线程，线程切换是用户态和内核态的切换，时间花费大

```java
这里说下什么是用户态，什么是内核态

用户态：把每个线程/进程当作一个用户，它们有自己独立的内存空间，即各个 进程/线程 的可访问空间是相互独立的，  CPU 只能受限的访问内存 

内核态：顾名思义，内核，是所有进程/线程 共享的，内核态是  CPU可以访问内存所有数据 

当某个线程 被 CPU 调度的时候，就是将线程从 用户态转换为内核态，即将数据复制到内核态当中，而执行完毕的线程又需要将数据从内核态复制到用户态当中

因此，频繁的线程上下文切换 会频繁的进行 用户态 和 内核态 之间的复制，时间花费太大
```



- 对象初始化的时候，没有被其他线程占有，那么这时**这个对象是 可偏向 状态**，也就是它只认为只有一个线程会来访问它，当**第一个线程来访问它的时候，它会通过 CAS 将自己的线程 ID 设置为该线程**，**该对象 从 可偏向状态 转换为 偏向 状态**，以后，改线程再来访问该对象时，只需要对比 ID 即可，如果一样则可以直接获取，无需 CAS
- 可能过了很久很久，当第二个线程来访问对象时，发现 该对象 是 偏向状态，表示在以前有线程访问这个对象了，导致它变成了 偏向状态，那么检查下该对象的 线程 ID 对应的线程 是否还存活（因为即使线程消亡了，对象的偏向状态也不会主动改变，需要别的线程来这样帮它改变），如果存活，那么检查下该线程是否仍然持有这个偏向锁，如果持有，那么该锁会升级为轻量级锁，此时锁仍由原来的线程持有，而第二个线程会 CAS 自旋，等待获取锁；；； 如果没有存活 或者 不持有，那么不会升级为轻量级锁，表示该对象可以重新偏向，将锁的 线程 ID 设置为 自己
- 当升级为轻量级锁后，如果 CAS 一段时间 第一个线程还没有释放锁，或者 有第三个线程来访问 了，那么就会升级为重量级锁，阻塞线程，避免不持有锁的其他线程 无意义的 CAS 自旋，浪费 CPU





## 2、JMM



> ### 背景介绍

早期的 CPU 的 速度 和 内存是差不多的， CPU 处理完 能很快写入内存

但是如今，CPU 的指令执行速度快得一批，内存的速度跟不上了，比如 1s CPU 需要写入 100 个数据，而 内存 1s 只能写入 1 个数据，这样的话，如果 CPU 就相当于降低速度去写数据，效率降低

为了解决这个问题，在 CPU 和 内存 中间引入了 cache，即高速缓存，它的速度跟 CPU 差不多，CPU 只需要将数据复制到 cache 中，然后去干自己的事，让 cache 慢慢将数据写入到内存中

需要注意的是：现在每台计算机不再是单核 CPU ，而是多核 CPU，每个 CPU 多对应一个自己的 cache

这样的话，就涉及到 **缓存一致性**

 ![img](https://pic2.zhimg.com/80/v2-3caf591483d67ccfd6ca01ef054a146f_720w.jpg) 

> ### JMM 是什么？

JMM 又叫 Java 内存模型，它跟 `jvm` 不一样啊。别搞错了啊。。。

它规定了 多线程对于 共享变量 的访问规则，以及将 共享变量 存储到内存，从内存中读取 共享变量 的底层细节



它会规定了 每个线程都有自己的工作内存，这个工作内存就跟上面的 CPU 对应的 cache 一样

每个线程对变量的操作都是在工作内存中，并且操作的是 内存中变量的副本，它不能直接操作内存中的变量，因为是共享的

操作完成，再将工作内存中的值写入到内存中

 ![img](https://picb.zhimg.com/80/v2-f0364f6f863d5730e2b962ac6b3387e2_720w.jpg) 





## 3、volatile



我们上面说了，JMM 规定了每个线程都有各自的工作内存，并且操作的都是在工作内存中的变量副本

正是因为这种模型，所以才存在数据可见性的问题

> ### 数据可见性问题

上面说了，线程操作的都是自己工作内存中的变量副本，而各个线程的工作内存又都是独立的，无法互相访问

并且它们从主存获取副本后，操作过程中基本不会再去访问主存

这样的话，当 线程 A 修改变量 x 后，写入到内存中，但是 线程 B 由于没有访问内存，它仍然使用的是在 自己工作内存中的旧值，这就导致了数据不可见



> ### 可见性问题的解决方案



**1、加锁**

因为当某个线程 获取  synchronized  锁后，会清空自己的工作内存，然后从主存中读取新的变量到工作内存中

然后再执行完代码后，将工作内存中的值重新写回主存，然后再释放锁

而获取不到锁的线程会阻塞，不会提前去读取主存，等到获取锁后再读取主存

这样的话就能保证数据是最新的

这个相当于是  synchronized 的底层原理



**2、volatile修饰共享变量**

当线程操作完某个变量 x 后，将 变量 x 从工作内存中写回 主存，当它发现这个变量是 volatile 修饰时，那么就会让其他线程的工作内存中的 缓存行失效（**注意，不只是 volatile 变量失效，而是缓存行里的所有数据**）

上面我们说了，线程在从主存中读取完内存后，基本不会再去访问主存，但是有一种情况除外，当它们发现自己工作内存的缓存失效，就会去访问主存，获取最新值

这就是 volatile 起到的作用



需要说明的是，之前一直以为失效的是 volatile 修饰的变量，没想到是缓存行失效，缓存行是很多数据，基本我们就认为是所有缓存都失效了（虽然没那么多，不过为了了解方便）



**那么是怎么发现数据失效的？**

通过总线嗅探，CPU 会通过嗅探在总线上传播的数据，发现过期了，那么就重新到主存中读取



volatile 保证了修饰变量的可见性，并且它还能 **禁止 指令重排序**

> ### 指令重排序

JVM 会将代码编译成一条条的指令，指令重排序就是 修改指令的执行顺序 来提高性能



**volatile 是怎么 禁止 指令重排序的呢？**

通过 happens-before 原则



> ### happens-before 规则

happens-before：翻译过来就是  发生在。。。之前

happens-before 规则 有很多条，其中有一条是：**一个线程对一个 volatile 的写必须先于其他线程对一个 volatile  的读**



在 JDK 1.5 的时候，对 volatile 变量是禁用缓存的，即线程无法缓存 volatile 变量，每次使用只能去主存里读，这样就保证了 volatile 变量一定都是最新值，但是这样明显效率很低

之后的 volatile 是通过禁止 volatile 变量与 普通变量的重排序，然后制定对应的规则来保证可见性

如下面的案例

```java
int a; //线程间共享变量
int b;
// 此变量必须定义为volatile
volatile boolean flag = false;

// 假设以下代码在线程A中执行
// 模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用configOptions = new HashMap();
a = 2;
b = 3;
flag = true;

// 假设以下代码在线程B中执行
// 等待 flag 为true，代表线程 A 已经把配置信息初始化完成
while (!flag) {    
    wait();
}
print(a);
print(b);
```

上面有两个线程，线程 A 中 flag 是 volatile 变量，因此会禁止 a = 2, b = 3 这两行代码 和 flag = true 这行代码重排序

即 flag = true 的执行必定是在 这两行代码之前，而 a = 2, b = 3 之间可以进行重排序

当 flag 执行完毕后，会将它前面代码的执行结果一并写入主存中，这样 线程 B 读取 flag 变量会清空自己的工作内存，然后去读取内存新值，这样 线程 A 修改的 a 和 b 的新值就能够被 线程 B 看见了

volatile 产生的作用就是

- 通过禁止 volatile 变量 和 普通变量的重排序，防止了 flag = true 在 a = 2，b = 3 代码之前执行
- 上述的禁止重排序就是因为 volatile 写入内存会将之前代码的执行结果一并写入主存，这样读取 volatile 变量的其他线程就能够看到之前修改的新值了，所以禁止重排序是为了修改的新值能够跟着 volatile 一起写入内存，一起被 其他线程 可见

这里需要说一点的是，上面线程 B 是在等待线程 A，但是如果对于高并发情况下，不会有这种 while(flag) 的情况，因此 volatile 是为了方便写完之后的其他线程能够直接读到新值，以及 已经读旧值的线程缓存过期，在需要使用的时候重新去主存读取新值



## 4、volatile、synchronized 和 lock 的区别和使用场景



> ### 单例模式中 volatile 和 synchronized  共同作用



在 8 种单例模式写法中，有这么一种写法：

```java
class Singleton{
    //volatile 修饰，保证可见性和禁止指令重排
    private volatile static Singleton instance = null;
    
    //构造方法私有化
    private Singleton(){}
    
    public static Singleton getInstance(){
		//双重检查
        if(instance == null){
            //锁住 Class 对象，类锁（同时还有对象锁，注意，对象有多个，Class 类只有一个）
            synchronized(Singleton.class){
                if(instance == null){
                    //赋值方法非原子性
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```



**上面 volatile 有什么作用？**

很容易看出的是保证可见性，但是这个 禁止指令重排有什么作用呢？

我们需要先知道，上面那个赋值语句的执行 跟 i++ 一样不是原子性的，它分为如下操作：

- 分配内存空间
- 调用构造方法，创建实例对象
- 将对象所在地址返回给引用

如果发生指令重排的话，那么将 2 3 步调换，先分配内存空间，然后再直接将地址返回给引用，最后再创建实例对象

假设在将地址返回给引用，这时候 instance 引用指向了一个地址，不再为空

地址上的实例对象还没有创建的时候，这里也不说什么多线程和单线程，假设是单线程，那么到这一步前 CPU 调用其他的线程，发现 instance 不为空，那么直接拿去用了， 那么就自然存在空指针异常了，多线程同样问题

**注意：其他线程在判断的时候是在第一个判断 if(instance == null) 的时候发现不为空的，还没有到 synchronized，这时候跟 synchronized 保证的原子性无关**



**上面 synchronized 有什么作用？**

保证赋值语句的原子性，上面也说了赋值语句 本身是非原子性的

因此需要赋值语句来保证原子性，这个不用讲



简单讲，volatile 主要是禁止指令重排序，防止 其他线程在第一个 if 判断处获取一个空对象

synchronized 是保证赋值语句的原子性，不会多个线程创建多个对象，这就不是真正意义上的单例





> ### 三者的区别

我们上面都说了关于 volatile、synchronized 和 lock 的情况

volatile 保证可见性、禁止指令重排，但不能保证原子性，并且只能修饰 共享变量，在只需要保证可见性 或者 禁止指令重排的时候可以使用，比如 CAS 中的 state 和 单例模式 进行 赋值语句指令重排



synchronized 保证可见性（**线程获取锁前会清空工作内存，读取主存新值**） 和 原子性，可重入，并且有 偏向锁、轻量级锁、重量级锁 三种，会根据竞争情况进行锁升级，如果仅仅需要同步线程，而不需要什么其他操作，使用 synchronized  就行了

阻塞和唤醒方法为：wait() 和 notify()



lock 具有灵活性，同时也能够保证可见性（**由于 state 是 volatile 的，所以释放锁，即修改 state 的时候，会将前面的操作一并刷新入内存，这样其他线程看得到了**）具体实现如 ReentrantLock，可重入，并且对应的可以配套使用 `lock.newCondition()` 来指定不同类型的锁对象，可以方便唤醒某种类型的线程，用于生产者消费者模式，而且**灵活性在于可以手动上锁和释放锁，并且可以指定等待锁的时间，不会死等**，里面的 tryLock() 方法在线程池中也用于判断线程是否是空闲状态

阻塞和唤醒方法为：await() 和 signal()





## 5、线程等待的四种方式（多个线程等待，统一放行）

- 使用 CountDownLatch
- 使用 CyclicBarrier
- 使用 thread.join() 等待线程死亡
- 使用 线程池的 submit 提交任务后获取 Future 调用 get()

各自的使用场景：

- CountDownLatch 适合指定特定个数的线程执行完毕后主线程才能执行的场景（追求任意，不针对哪个线程）
  -  new CountDownLatch(5)：指定等待 5 个线程执行完
  - 在子线程尾部结束前调用  countDown() 减值，在主线程中调用 await() 进行阻塞，当减到 0 的时候，那么 await() 停止阻塞，主线程开始执行，
- CyclicBarrier 指定特定数量的线程在其指定的某个点暂停，然后统一执行（追求任意，不针对哪个线程）
  - new CyclicBarrier(5)：指定在某个暂停点等待 5 个线程
  - 各个子线程在某个位置调用 await() 陷入阻塞，当调用 await() 的线程数量到达 5 时，那么停止阻塞，开始执行，类似赛跑，跑道有 5 个位置，那么任意来齐 5 个人后，统一开始赛跑
- join() 适合少量线程的情况，因为需要调用特定线程的 join()（线程的数量确定，针对某个特定线程）
  - 线程 A 调用 线程 B 的 join()，那么线程 A 会陷入阻塞，直到线程 B 执行完毕
- 线程池的 submit + future.get() 跟 join() 差不多，同样是针对某个线程的，由于使用的是线程池，因此使用的情况是线程的数量是不确定的时候（线程的数量不确定，针对某个特定线程）
  - 提交任务时使用 submit，返回一个 Future，调用 get() 等待线程完成任务返回结果



> ### 能使用 sleep() 或者 while() 么

如果是仅仅的进行线程等待，那么可以，但是这里要求的是统一放行，**要从 能否实现 和 效率 的方面看**

如果使用的是 sleep() ，它需要指定睡眠的时间，各个线程的执行任务的时间都是不确定的，可能一个执行 100ms，一个执行 500ms，所以无法确定睡眠时间，即无法做到统一放行

如果使用的是 while()，其实也是可以的，可以使用一个 volatile boolean 变量，各个线程 自旋读取这个变量，修改后就能统一放行，但是自旋的话会一直占用 CPU，会降低 CPU 的执行效率去做这种无意义的事，当然，可能会说使用 wait() 什么的进行阻塞，但是使用 wait() 就需要用到锁，而一次只能有一个线程获取锁，怎么做到统一放行。。。