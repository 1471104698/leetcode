# 简单总结

## 1、JVM 内存模型

```java
JVM：Java VM，即 Java 虚拟机，用来运行 class 文件，class 文件并不是直接跟操作系统打交道，而是在 操作系统 OS 和 class 文件之间架设了一层 JVM，通过 JVM 作为中间层，将 class 文件中方法的字节码指令通过内部的 Java 解释器翻译为跟 OS 相关的 CPU 指令

JRE：Java Runtime Environment，即 Java 运行环境，它包含了 JVM 和 基础类库，单单只能用来运行 class 文件，无法编写程序，因为它内部没有包含 编译器 和 调试器（debug）

JDK：Java Development Kit，即 Java 开发工具包，它包含了 
    JVM 和 基础类库（JRE）
    编译器、调试器、
    javac(将 java 文件 编译成 class 文件)、
    java（执行 class 文件）、
    javap（将 class 文件进行反编译，获取 class 文件内部信息）
        所以 JDK 可以编写程序，将代码转换为 class 文件，同时还可以运行程序。
```



```java
//1、程序计数器 PC：
是线程私有的，也是唯一一个不会发生 OOM 的区域，存储的是该线程下一条将要执行的字节码指令的位置（这里的位置不是内存地址，而是某个方法 code 属性字节码指令列表的 序号）
为什么需要 PC？
字节码指令需要经过 Java 解释器解释成 二进制指令， CPU 才能够执行
JVM 只有一个 Java 解释器，在单线程下，解释器可以按照顺序直接执行下去，这个 PC 没有什么作用
但是在多线程下，经常会发生线程上下文切换，Java 解释器不会去保存哪个线程执行到哪条字节码指令，所以 Java 解释器切换回来后，它本身是不知道当前执行到哪条字节码指令的，所以需要线程本身来记录
	注意：PC 记录只是记录字节码指令的偏移序号，但是没有记录的是哪个方法的字节码指令，所以这里应该还需要知道调用的是哪个方法，
	这里可以根据线程栈顶的栈帧来确定

//2、虚拟机栈 和 本地方法栈
它们都是线程私有的，虚拟机栈存储的是 Java 方法，本地方法栈存储的是 native 方法（非 Java 方法），HotSpot 将这两个栈合并为一个，因此实际上我们现在使用的 JVM 只有一个栈。
栈中存储的是栈帧，一个方法对应一个栈帧，栈顶的栈帧就是当前正在执行的方法
栈帧中包含：局部变量表、操作数栈、动态链接、方法返回地址
    1）局部变量表：存储方法中定义的局部变量，使用 slot 来表示，一个 slot 占用 32bit，一个变量占一个 slot，不满 32 bit 的变量也是一个 slot，如果是 long、double 这样的，那么就占两个连续的 slot
    2）操作数栈：存储当前字节码指令需要使用到的操作数，比如当前调用 a.h(1, 2)，那么会将 a 对象压入到操作数栈，再将调用的方法所需的参数压入到操作数栈，然后根据字节码指令执行方法。比如 return 时，会将需要返回的值压入到操作数栈，然后 return 操作数栈栈顶的数。
    3）动态链接：指向运行时常量池中 在类加载时期存储进去的常量池（constant pool）中该方法的引用， 在最上面我们讲了，PC 中只是存储了一个字节码偏移量，还需要知道方法的 code，因此这里的动态链接就是存储的常量池记录的方法 Method 对象，通过 Method 对象可以得到方法的 code，再根据 PC 内容确定字节码指令
    4）方法返回地址：这里的方法返回地址不是一个地址，它跟 PC 一样，不过是用在方法调用时，当方法 A 调用方法 B 时，由于使用的是同一个线程，而 PC 只有一个，所以此时的 PC 会去记录方法 B 的字节码指令位置，而 A 的就没了，所以需要记录方法 A 的字节码指令位置，这个方法返回地址记录的就是方法 A 调用方法 B 时，方法 A 的 PC 内容

本地方法栈中由于不是 Java 方法，所以只存在 --- 方法返回地址 ---

栈溢出 StackOverflowError：栈的空间是有限的，如果无限创建栈帧（递归）导致无法为新的栈帧分配空间，那么栈溢出
栈OOM：每创建一个线程都需要为它分配一个栈空间（1M 或者 10M），没有限制可以创建多少个线程，理论上是进程可以分配的最大空间，如果无法为新的线程分配空间，那么出现栈 OOM

//3、堆
堆是用来存储大部分对象，一个新对象的分配大部分都是在堆的伊甸区分配的。
堆分为新生代和老年代，新生代和老年代的比例为 1：2，新生代分为 1 个伊甸区和 2 个幸存区，新生代和两个幸存区的比例为 8：1：1
新生代使用的是复制算法，所以需要两个幸存者区，老年代使用的是标记-清除 和 标记-整理算法

如果在伊甸区无法为新的对象分配连续的内存，那么会出现 young GC，此时在 young GC 之前，会进行一次 空间分配担保 的计算：
	1）判断此次 young GC 在最坏的情况下，老年代是否能够容纳新生代的对象，
	2）如果不能，那么退一步，根据历次 young GC 晋升的新生代对象的大小判断老年代是否能够容纳，如果还是不能，那么直接触发 full GC。，full GC 会清理整个堆空间 。
young GC 会将新生代的对象转移到幸存区，将幸存区达到 GC age 阈值（阈值最大为 15，因为 mark 头部中记录 GC age 的为 4bit，最大为 1111，只能记录 15），或者满足动态计算晋升年龄阈值 的对象都转移到老年代。
注意， full GC 的触发看来是在 空间分配担保 策略实施后执行的，当然，还有一个大对象分配，如果老年代无法存储，那么也会触发 full GC；如果存在永久代，由于 永久代 和 老年代是绑定的，所以永久代满了也会触发老年代的 full GC
(这里讲一下，只有 CMS 才能单独处理 old 区，其他的 GC 回收器的 full GC 都必须新生代和老年代一起处理)
    
     Java 对象分配问题：
    	Java 对象不是都分配在堆上的，JDK 1.6 出现了 JIT 即时编译，JIT 有一个逃逸分析的技术。
     逃逸分析：
    	它会对方法中创建的对象进行分析，判断是否可能会被其他线程访问到，如果被外部指针引用，或者 return 了，那么就可能会被其他线程访问到，那么该对象存在逃逸
     栈上分配：
    	如果在方法中创建的对象不会逃逸，即它的生命周期仅仅局限于该方法（用完即毁），那么该对象可以在栈帧中进行分配，不需要分配到堆中（因为堆中的对象是所有线程共享的，而该对象只有调用该方法的当前线程才能访问到），从而减少对堆内存的占用，减少 GC。该对象在方法调用结束后随着栈帧的销毁而销毁。
     标量替换：
    	比如 A() 中创建了一个 User 对象，内部有两个 int 变量 x 和 y，而在方法中对该对象的访问仅仅是访问 x 和 y 变量，因此该 User 对象是能够打散的，不需要使用一段连续的内存来存储整个对象，直接在栈中不需要连续的内存空间存储两个 int 型变量来代替这个 User 对象。
    栈上分配不适合大对象和逃逸对象。
    有人说 HotSpot 没有真正的实现栈上分配，而是只有标量替换，如果只有标量替换的话那么就是只存在几个变量，这样的话如果对象存在方法调用那么就不能标量替换，只能在堆中进行分配，但是测试后发生创建的对象调用了方法后还是能够在栈上分配，而没有在堆中分配。（当然也有可能是把方法涉及到的变量全部创建出来，然后执行对应的字节码。）

 

//4、方法区
方法区存储的就是类的元数据
JDK 1.7 时还是永久代，JDK 1.8 变成了元空间
永久代跟 old 区是 GC 绑定的，所以其中一个出现问题都会触发 full GC（注意不是 old GC，old GC 只会出现在 CMS）；
元空间不在 JVM 内存中，它理论上可用空间等于物理内存
JDK 1.6 时，字符串常量池在方法区，JDK 1.7 时移动到堆中了
JDK 1.7 时，运行时常量池在方法区，JDK 1.8 时移动到堆中了
    （运行时常量池存储的就是 class 文件的常量池，跟方法的 code 属性相关的符号引用。JDK 1.7 的时候，class 常量池是存储在方法区的，JDK 1.8 是存储在堆中的，不过都是运行时常量池中，需要说明的一点是）
    方法区 OOM：通过 CGLIB 代理产生过多的 class 文件元数据堆满方法区。

//5、直接内存
直接内存不在 JVM 内存的范畴，这里只是扩展讲一下
    直接内存不受 JVM 的管理，它是堆外内存, 所谓的堆外内存是相对于 JVM 堆空间来说的，它仍然是属于用户态空间。
 	一般情况下完整的 IO 过程如下：
     Java 堆内存 -> 堆外内存 -> 内核态 socket 缓冲区 -> DMA -> 网卡1 -> 网卡2 -> DMA -> 内核态 socket 缓冲区 -> 堆外内存 -> Java 堆内存
    而使用堆外内存，由于不受到 JVM 管理，所以需要分配的时候不会导致 GC，同时能够减少 CPU 拷贝次数。
 
Java 直接内存的分配方式：
    1）ByteBuffer.DirectByteBuffer()：
        虽然直接内存不受 JVM 管理，但是 ByteBuffer 分配的直接内存实际上是间接受到 JVM 管理的，该对象在创建时会同时创建一个  Cleaner 对象，它继承了虚引用，在 GC 回收该 ByteBuffer 对象前，会将这个消息存储到对应的引用队列中，交给 ReferenceHandler 线程（JVM 启动时会启动该线程，优先级很高，通过 jstack 可以看到该线程）来处理，在该线程中，会调用 Cleaner 对象的 clean() 来释放堆外内存。
    2）unsafe：
        而如果是 unsafe 分配的直接内存，这就跟 C 分配内存一样，如果我们不手动释放，那么会导致内存泄漏
        
JVM 默认没有限制直接内存的大小，理论上等于一个进程所能够分配到物理内存。
使用一个死循环不断分配直接内存，使用 ByteBuffer 分配会频繁发生 GC，但电脑不会卡死；使用 unsafe 不会发生 GC，电脑卡死
这是因为 ByteBuffer 对象会 GC 回收，释放直接内存，而 unsafe 不会
当我们限制直接内存大小，那么都会发生 直接内存 OOM


//6、强软弱虚引用
1）强引用：默认的引用都是强引用
只要存在强引用，并且 GC roots 可达，那么就算 GC 后内存不足抛出 OOM 也不会回收这些对象。

2）软引用：使用 SoftReference 对象封装起来的对象，对该对象而言就是软引用，不过 SoftReference 对象本身是强引用
比如 SoftReference<User> soft = new SoftReference(new User()); 这个 User 对象就是被软引用所引用
通过 soft.get() 可以获取到 User 对象，如果 User 对象被回收了，那么 get() 返回 null.
如果 GC 后内存足够，那么不会回收软引用指向的对象，即不会回收 User 对象，如果内存不足，那么在抛出 OOM 前会回收 User 对象
不过 soft 对象本身是一个强引用

3）弱引用：使用 WeakReference 对象封装起来的对象
比如 WeakReference<User> weak = new WeakReference(new User()); 这个 User 对象就是被弱引用所引用
通过 weak.get() 可以获取到 User 对象，如果 User 对象被回收了，那么 get() 返回 null.
只要发生 GC 然后 User 对象被扫描到不存在强引用，只存在弱引用，那么会将 User 对象回收，即不管内存是否足够都会回收 User 对象

ThreadLocal 就是借助弱引用来解决部分内存泄漏问题

4）虚引用：使用 PhantomReference 对象封装起来的对象，它不用来缓存数据的，而是用来通知对象是否已经被 GC 回收了的，它需要跟 ReferenceQueue 引用队列绑定在一起使用，它的构造方法必须强制传入一个 ReferenceQueue
PhantomReference<User> pha = new PhantomReference(new User(), new ReferenceQueue<>()); 这个 User 对象就是被虚引用所引用
pha.get() 永远都是返回 null，因为它不是用来缓存对象的，当虚引用指向的对象被回收时，会将这个虚引用对象 pha 存储到与之绑定的引用队列中，然后我们可以从引用队列中获取这个虚引用对象来进行一些收尾工作

NIO 中的 ByteBuffer 分配的直接内存（堆外内存）就是通过虚引用来让 JVM 间接管理直接内存的释放的
在创建 DirectByteBuffer 对象，分配内存的时候，会同时创建一个 Cleaner 对象，该对象继承了 PhantomReference，当 DirectByteBuffer 对象被回收时，ReferenceHandler 线程会直接调用这个 Cleaner 对象的 clean() 来释放直接内存
（当然，这里没有涉及到引用队列，由于是 JDK 自己设计的 Cleaner，所以它可以不需要放入到引用队列中再处理，可以直接调用 clean() 进行处理，而如果是我们程序员来设计 Cleaner，那么 JVM 就会将这个 Cleaner 放入到引用队列中，然后在引用队列中调用 Cleaner 对象的 clean() 来释放直接内存）
        
        
```

*![image.png](https://pic.leetcode-cn.com/1608361799-uKIEHa-image.png)*



## 2、JVM GC

```java
GC 回收对象的判断：
1）引用计数法：一个对象被其他 x 个对象引用，那么它的引用计数为 x，当为 0 的时候可回收，缺点是无法解决循环引用的问题
2）可达性分析：从 GC roots 出发，递归标记存活对象

GC roots 包含 
1）栈帧中的局部变量
2）全局变量
3）本地方法中的变量
4）Class 对象中的静态变量
（反正只要是最开始可以确定存活的对象就都是 GC roots）

GC 算法：复制算法、标记清除算法、标记整理算法（标记的应该是可回收对象）
新生代使用的是复制算法，老年代一般情况下使用的是标记-清除算法，特殊情况下使用的是标记-整理算法

关于 GC 算法标记的对象：有说标记存活对象的，有说标记回收对象的，但是按照可达性分析来说，标记的应该是存活对象，对于可回收对象，它的 mark 的锁标志位会被设置为 11（具体怎么在 GC 过程中将标志位设置为 11 的，这个是底层细节，不得而知）

三色标记法：
GC 算法扫描过程中，使用的三色标记法
白色：未扫描或者可回收对象
灰色：扫描一半的对象
黑色：扫描完成的对象
最开始所有的对象都是白色对象，按照 GC roots 链递归扫描，最终在 GC roots 链上所有存活对象都是黑色的，没有被扫描到的对象，即可回收对象都是白色的，因此直接回收白色对象即可

GC 回收器：串行回收器、并行回收器、CMS、G1

CMS：
CMS 的出现是为了减少 串行和并行回收器的 STW 时间的
CMS 是只作用于 old 区的垃圾回收器，它只会回收 old 区，只有 CMS 才存在 old GC，其他都是 young GC 和 full GC
CMS 回收过程：
    1）初始标记：会进行 STW 暂停所有用户线程（进入安全点/安全区域），初步扫描所有 GC roots，标记存活对象，这里需要扫描新生代和老年代，为了确定新生代哪些对象存活从而确定老年代的存活情况，这里会使用 卡表 card table（卡表后面讲）
    2）并发标记：跟用户线程一起执行，递归扫描初始标记时标记的对象，使用的是三色标记法，同时它这里会使用增量更新的方式（具体是什么后面讲）
    3）预清理：STW，这里可以执行一次 young GC，回收新生代的部分对象，减少下面需要执行的重新标记扫描 GC roots，从而减少 STW 时间
    3）重新标记：STW，由于并发标记是跟用户线程一起执行的，用户线程可能会修改一些引用，所以这里需要重新扫描所有的 GC roots，但它会跳过黑色节点，只会扫描那些白色或者灰色节点，意味着大部分都可以跳过扫描
    4）并发清理：跟用户线程一起执行，回收可回收的老年代对象
    5）并发重置：重置 CMS 内部数据，为下一次 GC 做准备（具体重置哪些数据不太清楚）

G1：
G1 是为了在更少的 STW 时间内回收更多的对象。
它将整个堆空间划分为一个个大小相同的区域，称作 Region，这些 Region 不再固定属于新生代或者老年代，即跟 CMS 不一样，不需要规定新生代范围和老年代范围。同时，它还增加了一个专门用来存储 大对象的区域，即所有的类型为 E、S、O、H
    每个 Region 的类型不是固定的，现在是 S 区的 Region 之后可能是 O 区，反正是哪个区需要使用多一点的空间，就将多一点的 Region 分配给它，动态的，非常人性化。不过同一个 Region 只能存储一个类型的区的对象，不能 S 区 和 O 区对象混合存储。
G1 回收过程：
    1）初始标记：跟 CMS 差不多，不过这个阶段一般同时也会执行 young GC，可以说占用的是 young GC 的时间（不过个人感觉怪怪的，因为 mixed GC 本来就是会回收 young 的）
    2）并发标记：跟 CMS 差不多，区别在于它不会使用增量更新，而是使用快照的方式记录被删除的引用
    3）重新标记：根据并发标记的快照恢复引用
    4）筛选回收：根据每个 Region 中的存活对象等信息，统计所有 Region 的回收价值，根据回收价值进行排序，然后按照用户希望的停顿时间，回收所有的新生代 Region 和 部分老年代 Region，它会将需要回收的 Region 中的存活对象复制到 空的 Region 中，然后回收掉整个 Region
    
    CMS 有 young GC、old GC（只回收老年代）、full GC（回收新生代 + 老年代）
    G1 有 young GC、mixed GC（回收新生代 Region + 部分老年代 Region）、full GC

浮动垃圾问题：
在 GC 过程中，如果用户将引用修改，将黑色节点从 GC roots 链上断开，变成了可回收对象，但是由于它已经扫描过了，所以它在此次 GC 中无法被回收，只能留到下一次 GC 回收，这些对象称作浮动垃圾（CMS 和 G1 都无法处理）

对象消失问题:
在 GC 过程中，用户修改引用，将一个 GC roots 链上的白色对象从 GC roots 链上断开，然后让它跟别的黑色节点进行连接，这样的话，由于黑色节点已经扫描过了，所以它不会再去扫描，导致在回收的时候对象是白色的，被回收


对象消失问题的解决方法 --- 增量更新 和 快照：
    1）CMS 在并发标记时，使用的是增量更新，当用户线程修改引用，在黑色节点上插入一个白色节点时，那么这个黑色节点就需要修改为灰色，重新进行扫描，这样可以避免对象消失
    2）G1 在并发标记时，使用的是快照，它只关注引用的删除，它会将删除的引用关系存储到一个队列中，然后在重新标记阶段它不会去扫描所有的 GC roots，而是从这个队列中的引用关系出发进行扫描，避免对象消失
G1 使用了快照，它只关注引用的删除，所以在重新标记阶段不会扫描所有的 GC roots，所以比 CMS 要更快，但是一些被删除的引用的对象应该是需要会回收的，但是它被重新扫描后会被标记为黑色节点，因此导致 G1 会比 CMS 出现更多的浮动垃圾

并发标记过程中用户创建新对象的问题：
	1）CMS 使用增量更新，所以新创建的白色对象无论是跟 GC roots 上的白色、灰色、黑色哪一个节点进行连接，都可以扫描到，不会导致新的对象被回收的问题
	2）G1 它只关注删除的引用，而新对象它的引用关系它并不会去记录，所以如果新对象跟黑色节点建立连接，G1 是不知情的，那么它应该会被回收，但是肯定不可能让它回收，G1 底层使用了两个 map 来记录新对象的引用，具体看 [G1 中用户创建新对象的解决方法](https://www.cnblogs.com/thisiswhy/p/12388638.html)			，我也不太清楚，反正是有进行处理就对了

CMS 的并发失败问题：
在 CMS 进行 old GC 的时候，用户线程如果需要分配内存，而内存不足，那么就会导致并发失败，从而升级为 full GC，由于 CMS 只能进行 old GC，所以它会退化为 串行回收器，效率降低
解决方法：预留内存，不要在快满的时候才触发 GC

卡表 和 Remember Set（RSet）：
    1）卡表 card table：为了避免在 young GC 时扫描整个老年代，将老年代分为大小相同的多个区域，默认是 512B，每个区域称作卡页，而卡表上则是记录了每个卡页对 新生代的引用情况，卡表上的每个卡表项映射一个卡页（类似分页机制的页表），当对应卡页上的老年代对象存在对新生代对象的引用时，那么卡表项值为 1，表示对应的卡页为脏页。
    在 young GC 时想知道新生代哪些是被老年代对象引用的，直接扫描卡表，然后找到卡表项为 1 的，扫描这些卡表项对应的卡页中的老年代即可。这样可以避免扫描那些卡表项为 0 的区域，从而避免扫描整个老年代。由于老年代对新生代对象的引用是很少的，所以相当于只需要扫描老年代的一点区域而已。

    2）Remember Set：由于 G1 将整个堆空间划分为 Region，淡化了分区的概念，在 GC 的时候需要知道 Region 中的对象哪些是被其他 Region 引用的，因此 CMS 中一个简单的卡表在这里并不适用，所以出现了 RSet，它是对卡表的扩展， 原本是一个老年代对应一个卡表，现在是每个 Region 对应一个卡表，记录着其他 Region 对当前 Region 的引用情况，这种一个 Region 对应一个卡表的 方案称作 RSet。在回收一个 Region 的时候不需要扫描所有的 Region，只需要扫描 RSet 上哪些 Region 存在对该 Region 的引用，然后去扫描这些 Region 即可。
    它将每个 Region 划分为大小相同的多个区域，大小为 512B（跟 CMS 的老年代划分一样，就是类似将每个 Region 当作老年代那样），然后给每个 Region 都分配一个卡表，这个卡表实际上就是一个 HashTable<key, byte[]> 的类型，key 存储的是其他的 Region 的地址，byte[] 是 key 对应的 Region 的卡页，byte[0] 表示是第一个卡页，byte[1] 表示是第二个卡页。
    它用来记录当前 Region 中被其他 Region 的哪些 card 给引用了，这样在回收该 Region 的时候，只需要扫描它的 RSet，然后只需要扫描那些引用了它的其他 Region 的 card，确定当前 Region 的存活对象即可
    需要注意的是，它只是记录了其他 Region 的哪些 card 引用了当前 Region，而没有具体到引用了当前 Region 的哪个 card。如果要记录的话，那么就需要三层架构了，而不是单单 HashTable 两层架构
```

卡表 ：

<img src="https://user-gold-cdn.xitu.io/2020/7/3/1731052eb999f1a7?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" style="zoom:40%;" />

RSet：

<img src="https://pic.leetcode-cn.com/1604937577-UMiHDP-image.png" style="zoom:50%;" />





## 3、JVM 方法重载和方法重写

```java
方法重载：同一个方法名，不同的方法参数（方法名相同，方法参数、个数不同），方法具有唯一性
方法重写：同一个方法名 和 相同的方法参数，只能出现在父子类之间，方法不具有唯一性

方法重载：
    在编译期间编译器就可以确定的了，比如 A 类有 h(), h(int i), h(String str), h(int i, String str) 四个同名方法
    当我们执行：
        A a = new A();
        a.h(1);
    编译器在编译期间就可以根据方法名 + 参数个数 + 参数类型确定调用的是 h(int i)

方法重写：
    方法重写发生在父子类之间，能够被子类重写的方法，叫做虚方法，除 private、final、static、构造方法外，剩下的都是虚方法
    编译器在编译期间只能根据引用指针的类型确定方法重载，但无法确定真正调用的是哪个对象的方法，
    因为在编译期间编译器无法确定引用指针引用的是哪个对象
    比如 
        class B{
            public void h(){
                System.out.println("B");
            }
            public void h(int i){
                System.out.println("B i");
            }
        }
        class A extends B{
            @Override
            public void h(){
                System.out.println("A");
            }
        }
    当我们执行 
        B b = new A();
        b.h();
    编译器只能确定调用的是 B 的 h()，而不是 B 的 h(int i)
    但是它此时是不会去获取 b 指向的对象类型的，即不知道调用的是 A 的 h() 还是 B 的 h()，因为编译器不确定
    有的人可能会说为什么不确定？引用的对象类型不是在 = 后面了吗？
    这是因为可能有时候存在如下情况：
    ①、
        B b = new B();
        b = new A();
        b = new B();
        b = new A();
    ②、
        int i = new Scanner(System.in).nextInt();
        B b;
        if(i < 0){
            b = new B();
        }else{
            b = new A();
        }
        b.h();
    对于第一种情况，编译器是可以根据上下文确定的，不过有点麻烦，对于第二种情况，编译器是无法进行确定，具有不确定性
    所以编译器干脆就不去确定了，调用的是哪个对象的方法就留到运行期间的解析阶段，根据操作数栈的栈中对象来得知真正的对象类型
```



## 4、JVM 类加载机制

```java
类加载阶段分为：加载-验证-准备-解析-初始化
其中 JVM 规定了 解析阶段不一定必须在 类加载的时候执行，可以留到运行期执行，也就是说在方法第一次调用的时候进行解析

1、加载：JVM 使用的是 OOP-Klass 体系
	将 class 文件中的信息转换为方法区的数据结构，一个 class 文件表示一个类，在方法区创建的就是 Klass 对象。
	Klass 会记录类的元数据，比如 父类、接口、方法 和 字段。
		方法对应的结构体为 Method，内部包含了方法名、访问修饰符、方法参数、方法的 Code 属性，如果是虚方法，那么会包含在 vtable 中的索引位置
		字段对应的结构体为 Field，内部包含了字段名、访问修饰符、字段偏移量[offset_start, offset_end]，
        这个偏移量是表示相对于 OOP 对象体来说的，这里可以看出每个类的每个字段它的偏移位置都是固定了的，
        因此可以直接通过偏移量来定位到字段，获取字段值，这也是 CAS 中使用 unsafe 的实现前提
	同时这个阶段还会在堆中创建 Class 对象，Klass 对象和 Class 对象是双向指向的，
        这也就是我们常说的是 Class 对象是反射的入口，正是因为可以通过 Class 对象访问类的元数据

2、验证：当加载完成了，再来验证字节码是否存在错误，比如 类是否继承了 final 类之类的
		因为如果是正常的通过编译器编译，那么肯定是没有问题的，但是 class 文件的获取不一定是通过编译器编译，可能是从网上下载的，这样的话 class 文件可能存在非法信息
		
3、准备：处理静态变量，为静态变量赋初始值
       	这里实际上就是分配内存空间，同时由于分配的内存空间上可能是其他进程使用过的，数据没有清零，所以这里会进行清零，将所有 bit 都置为 0（操作系统好像不会回收内存的时候就清零，而是在需要使用的时候再清零）
            (注意，这里的静态变量只是变量，而不是 = 右边的值，所有的对象都是存储在堆中的，所以 GC roots 才包括 static)
		比如 int 类型的初始值为 0，是因为分配内存后上面的值都是 0，
		而引用类型则是 null，同样的分配的内存上面不存在任何有效的地址，是空指针
		对于 final static，这种不会赋初值，而是直接将程序员定义的值赋值给它
		在 JDK 7 的时候，static 变量从方法区移到了 Class 对象中，因此这里是在 Class 对象中分配内存

4、解析
所谓的解析，就是将方法的 Code 属性中的 putstatic #15、invokevirtual #11 等字节码指令 和 运行时常量池中 constant pool 中的 Methodref 和 Fieldref 等代表符号引用的结构体替换为真正的指向方法区 Klass 对象中的 Method 和 Filed 结构体

如何解析？
    Constant pool:
       #1 = Methodref          #7.#37         // java/lang/Object."<init>":()V
       #2 = Fieldref           #3.#38         // cur/A.a:I
       #3 = Class              #39            // cur/A
       #4 = Methodref          #3.#37         // cur/A."<init>":()V
       #5 = Methodref          #3.#40         // cur/A.h:()V
       #6 = Fieldref           #3.#41         // cur/A.b:I
       
  public static void main(java.lang.String[]) throws java.lang.InterruptedException;
    descriptor: ([Ljava/lang/String;)V
    flags: ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=2, args_size=1
         0: new           #3                  // class cur/A
         3: dup
         4: invokespecial #4                  // Method "<init>":()V
         7: astore_1
         8: aload_1
         9: invokevirtual #5                  // Method h:()V
        12: return

首先我们可以看出在 main() 的 Code 属性的字节码指令中，存在 invokevirtual #5 这种，invokevirtual 表示调用都是虚方法，#5 表示它调用的方法的信息在常量池 #5 的位置，算是一个符号引用，因为没有真正的具体信息。
我们看上面 Constant pool 中 #5 对应的是一个 Methodref 结构体，它包含了 方法所属的类、访问修饰符、方法名、方法参数个数
	Methodref 结构体如下：
    CONSTANT_Methodref_info {
    	//字节码指令后面跟着的 #5， 这个 5 就是这个 tag
        u1 tag;						
        //指向常量池的其他数据结构，表示方法所属的类，比如上面的 #3 Class 和 #5 后面的 #3.#40，表示之间的关联
        u2 class_index;             
        //指向常量池的其他数据结构，存储方法的方法名 和 方法描述符，方法描述符存储着方法的 参数个数 以及 方法的访问修饰符 
        u2 name_and_type_index;     
    }

    在运行时期，当 JVM 解释器执行到 invokevirtual #5 时，发现还没有解析，仍然是符号引用，所以无法获取 #5 对应的 Code 属性，所以会先进行解析。
    根据 #5 找到 Methodref 结构体，然后获取方法的信息，由于这里是 invokevirtual，表示是一个虚方法，所以需要知道真正的调用对象，那么会从操作数栈中获取到调用的对象（在执行 invokevirtual 指令前，肯定会先执行其他的字节码指令，将方法调用对象 和 方法所需的参数压入到操作数栈中），然后根据这个对象从 OOP 对象头中的 Klass 指针进入到方法区，然后根据方法信息扫描虚方法表，定位到调用方法的 Method 对象，最终返回，将 Constant pool 中的 Methodref 对象替换为该 Method 对象指针，将 invokevirtual 替换为 invokevirtual_quick 表示已经解析过了，下次调用该方法的字节码指令无需再次解析，将 #5 替换为 Method 所在的 vtable 的下标 和 方法参数个数，完成解析。
    最后开一个栈帧，将栈帧中的动态链接指向常量池中的 Mehtod 对象，然后根据 Method 对象获取内部的 Code 属性，调用字节码指令，执行该方法。


所谓的运行时常量池存在字面量是什么意思？
我们都知道，运行时常量池存储的是 常量池（里面一堆符号引用 Methodref、Fieldref），那么字面量是什么？
字面量就是我们直接定义的:
	String a = "abc";
	long l = 2L;
以上这种就是字面量，它同样是以符号引用存储在常量池中的，比如
    Constant pool:
       #1 = Methodref          #8.#31         // java/lang/Object."<init>":()V
       #2 = Long               2l		
       #4 = Fieldref           #7.#32         // cur/A.l:J
       #5 = String             #33            // abc
       。。。
       #33 = Utf8               abc
	上面的 #2 Long 就是 l 的符号引用， #5 String 就是 a 的符号引用，它的数据结构不是 Fieldref，而是 Long 和 String
	不过 #5 String 相当于只是一个 index 索引，指向的 #33 Utf8 才是真正的字符串内容，在解析阶段会通过 ldc 指令解析为堆中的对象。


 
5、初始化：执行静态代码块，同时为 static 变量赋值，这里的值是程序员定义的值

类加载阶段完成
```



## 5、redis 底层数据结构

<img src="https://picb.zhimg.com/80/v2-92afb6f1dd844e640fe40c242dede27d_720w.jpg" style="zoom:60%;" />

```
redis 自定义的核心数据结构：redisObject，内部主要字段有 type 和 encoding、ptr
type 表示当前 redisObject 对象的基本数据结构，encoding 表示该基本数据结构的编码格式，ptr 指向真实数据

redis 总共有 5 种基本数据结构：string、list、hash、set、zset
    1) string 的编码格式有 int、embstr、raw（其中 embstr、raw 通过 SDS 实现）
    2) list 的编码格式有 ziplist、linkedlist、quicklist
    3) hash 的编码格式有 ziplist、dict
    4) set 的编码格式有 intset、dict
    5) zset 的编码格式有 ziplist、skiplist + dict
我们可以当 redis 内部维护了一个很大的 dict，而所有的 key 都是 redisObject 类型的，它们就存储在这个 dict 中


//比较难记的底层数据结构：SDS、ziplist、dict

1、SDS：
SDS 叫做简单动态字符串（Simple Dynamic String），的数据结构如下：
    class SDS{
        //buf 中已用长度	
        int len;
        //buf 中剩余可用长度
        int free;
        //字节数组
        char[] buf;
    }
C 的字符串只是一个简单的 char[] 数组，而 SDS 是对 char[] 进行封装
SDS 相比 C 来说有 4 个不错的优点
对于 C 的字符串来说：
    1）获取字符串的长度 strlen() 需要 O(n)，即扫描一遍字符串
    2）C 每次分配都是刚好需要的字节空间，因此每次 append 追加字符串都需要重新分配内存
    3）C 字符串是二进制不安全的，因为 C 中字符串结尾是 '\0'，而如果存储的字符串是 "abc\0 def"，
    	这样字符串变成 "abc\0 def\0"，那么在读取到 '\0' 后会停止读取，导致只读取了 'abc'
    4）C 是用户直接操作指针的，由于没有记录字符串长度，因此直接操作容易导致缓冲区溢出而修改了其他内存的数据
在 redis 中，计算字符串长度 strlen() 和 append 是很常见的，所以 C 的字符串效率太低，SDS 能够完全解决这两个问题：
    1）SDS 中存在 len 字段用来记录字符串长度，O(1) 即可获取
    2）SDS 使用预分配 + 惰性删除的原则
    	每次分配都会多分配一倍的内存，在 append 时就可以直接使用预分配的内存
    	删减字符串时也不会立马将剩余的空间释放掉，会记录在 free 字段中
    3）SDS 是二进制安全的，因为它读取字符串不是按照 '\0' 来读取的，而是按照字段 len 来读取的，
    	这样就不会存在数据读取不完全的问题，可以用来保存图片、音频等
    4）SDS 自带安全的 API，会检查操作的索引，避免缓冲区溢出
embstr 和 raw 底层都是使用 SDS 来实现的，只不过 embstr 是在字符串长度 <= 39 的时候使用，raw 是在 > 39 的时候使用
embstr 是在使用短字符串时的优化，将 redisObject 和 SDS 在一次内存分配中同时创建，即 redisObject 和 SDS 是一段连续的内存； raw 是两次分配，先分配 redisObject，再分配 SDS，然后让 ptr 指针指向 SDS，它们的内存地址之间不连续
由于是 embstr 地址空间连续，所以是一次分配和一次释放，效率相比 raw 来说更高。
但相对的，由于地址空间连续，所以 char[] 不能太长，不然占用一大段连续的地址空间

2、ziplist：
ziplist 压缩链表，分配的是一段连续的内存空间
这里需要讲以下的是，ziplist 实际上只是一段连续的内存空间数据，它不存在什么多余的数据结构，下面的讲的数据结构是设计者为了方便理解而抽象出来的，实际上 ziplist 并不采用这种结构。
ziplist 的结构： <zlbytes>、<zltail>、<zllen>、<entry>、<zlend>
    1）zlbytes：整个 ziplist 占用的字节数
    2）zltail：列表末尾的偏移量，方便实现 O（1）在尾部插入
    3）zllen：entry 节点的个数，初始为 0
    4）entry：存储数据的数据结构，含有多个，比如 [entry1][entry2][entry3]...[zlend]
    5）zlend：标识压缩链表的末尾，固定值为 255，由于没有 entry 以 255 开头，所以碰到 255 就表示到达列表末尾
    			因为 entry 的开头为 prevlen，它最大表示到 254（11111110）
    			专门剩下这个 255（11111111）用来作为结尾表示

entry 结构：<prevlen> <encoding> <entry-data>
    1）prevlen：前一个节点的长度，当前一个节点的字节数 < 254，使用 1B 来表示（注意是 < 254）
                如果 >= 254，那么使用 5B 表示，第一个字节为 254，用来标识这个情况，后面的 4B 是实际长度
    2）encoding：表示 entry-data 的长度，比如 00xxxxxx，其中后 6bit 表示后面字符串的字节数
    3）entry-date：真正的数据
    
ziplist 的使用场景：
    ziplist 用于 list、hash、zset，其中对于 hash 和 zset
    它们插入的数据有都两个字段，hash 是 key-value，zset 是 member-score，
    在 ziplist 中都是使用相邻的两个 entry 来存储的
ziplist 由于需要连续的内存空间，跟 SDS 一样，所以它不适合在数据量较大的情况下使用


3、linkedlist：
这个没什么好讲的，就跟我们 Java 的 LinkedList 一样，使用链表的形式，增删效率高，查询效率较低，相比 ziplist 来说由于前后指针的存在以及没有 ziplist 那种数据压缩，所以占用内存更多，但是它需要的内存空间不需要连续

    
4、quicklist：
list 的最初的版本选定的是 
1）数据量小的时候选用 ziplist，一段连续的内存空间，不需要指针，节省内存
2）数据量大的时候使用 linkedlist，由于 ziplist 需要一段连续的内存，如果数据量太大，那么将会占用一大段连续内存，同时在修改的时候还需要进行数据后移，效率较低，因此转换为 linkedlist 双向链表，它不要连续内存，但是需要使用节点来保存前后指针，数据量大的时候耗费内存。
因此出现了 quicklist，它将 ziplist 和 linkedlist 的优点结合在一起，它使用的是 linkedlist 的双向链表结构，但是每个节点存储了一段连续的 ziplist，上面存在多个 Entry。相当于如果存在 6 个数据，每个链表节点存储一段包含 2 个数据的 ziplist，这样就只需要 3 个链表节点，只要权衡 ziplist 的大小，即能节省内存，又不需要太大的连续内存，同时又能够增加修改效率。


5、inset：
inset 的数据结构如下：
    typedef struct intset {
        uint32_t encoding;	// 编码方式
        uint32_t length;	// 数组中元素个数
        int8_t contents[];	// 保存元素的数组
    } intset;
实际上它跟 SDS 一样，都是对数组的封装，不过 intset 是对 int[] 的封装
虽然 intset 只有 set 使用的，而 set 是无序的，但是 intset 为了在查询时使用二分查找加快查询效率，它会保证数据的有序
因此当插入一个新的数据时，二分查找插入的位置，然后将后面的元素后移，再插入


6、dict：
redis 的 dict 作用就是 HashTable，使用的是数组 + 链表的形式。
但是不同的是， dict 是对 HashTable 的封装，内部维护了两个 HashTable，分别为 ht[0] 和 ht[1]，而真正使用的数据只有一个 ht[0]，而 ht[1] 是在 扩容/收缩 用来帮助进行数据迁移的

dict 的数据迁移不是一次性全部完成的，而是使用 渐进性 rehash 的方式。
它会借助执行用户命令来完成，当执行完一条用户指令时，不会立马返回，而是会借此将 ht[0] 上的一个或者多个 slot 迁移到 ht[1] 上，利用这种方式将数据迁移的时间进行分摊。当数据迁移完成后，会将 ht[0] 和 ht[1] 进行互换，然后将 ht[1] 清空
不过这种 渐进式 rehash 的方式会对 scan 指令造成查询出来的 key 重复和数据丢失问题
		（具体看 scan 如何通过修改 游标 v 的访问顺序来解决 dict 渐进式 rehash 导致的解决数据丢失 以及减少 key 重复）

7、skiplist：
在 zset 中，当数据量小的时候使用的是 ziplist，而在 ziplist 中同样需要保证顺序，因此每当插入一个数据都需要涉及到 entry 的后移，当数据量较大的时，一是需要较大的连续内存空间，二是每次插入和修改都可能会涉及到大量的 entry 的移动，因此需要升级为 skiplist，skiplist 首先是对 score 进行排序，当 score 相同时，会对 member 进行排序。
不过 zset 不单单是使用 skiplist 来实现，而是使用 skiplist + dict 来实现：skiplist 用来范围查询，而 dict 用来 O(1) 单值查询，并且 skiplist 和 dict 使用的是相同的节点，节省了内存空间。

skiplist 的增删改查都具有 O(logn) 的效率，对于修改，由于修改后的节点由于排序问题可能需要移动，所以它都是先将节点删除，然后再进行插入。
```





## 6、redis key 过期处理策略 / 内存淘汰策略 / 缓存三大问题 / 缓存一致性

```java
redis 对 key 的管理有两个部分：expires 字典 和 键空间
    1）expires 字典：存储所有设置了 expires 的 key 和对应的过期时间
    2）键空间：存储所有的 key，expires 字典是键空间的一部分
    
1、key 过期处理策略：
对 key 来说，如果设置了过期时间，那么它总会到失效的时候，这时候根据对 CPU 和 内存 的不同影响，存在3种 key 过期处理策略：
    1）一旦某个 key 过期了，那么通知 CPU 进行处理。
    2）一旦某个 key 过期了，那么在访问时发现过期了再进行处理
    3）定时扫描 expires（yi ke si bai er） 字典中一些 key，然后清理掉过期的 key
第一个方法，对内存友好，但是对 CPU 不友好，redis 讲究的是效率，如果 CPU 都去处理这些 key，那么效率显然会降低
第二个方法，对 CPU 友好，对内存不友好
第三个方法，是在 CPU 和 内存上进行权衡，这里肯定是不能扫描所有的 key 的，因为如果 key 有10W，那么定时扫描 10W 肯定不科学
redis 使用的是 第二个方法 + 第三个方法，即定时扫描 expires 字典的一些 key 进行处理，同时在访问的时候如果发现过期那么再处理，可以看出 redis 相当于是使用了 空间换时间（时间换空间和空间换时间这两种做法渗透了各个地方）的做法

2、内存淘汰策略：
redis 的内存空间是有限的，如果一直存储，那么总会挤满整个内存空间，单靠 key 过期处理策略是不行的
redis 指定了 8 种内存淘汰策略，当插入一个 key 而无法分配内存时会进行触发：
1）报错
2）删除 expires 字典 中最接近过期的 key
3）随机删除 键空间 的某个 key
4）随机删除 expires 字典 的某个 key
5）删除 键空间 最久没有使用的 key（LRU）
6）删除 expires 字典 最久没有使用的 key（LRU）
7）删除 expires 字典 中最近最少使用的 key（LFU）
8）删除 键空间 中最近最少使用的 key（LFU）
其中 7 和 8 是 redis 4.0 新加入的

3、redis LRU 实现：
redis 在内存淘汰策略中使用的 LRU 不是常规的 LRU
常规的 LRU 是直接将队列尾部（最久未使用）的元素给淘汰掉，但是 redis 使用的是 近似 LRU，使用的是 LRU 的设计思想，不过它本身不会去维护一个队列
近似 LRU 的设计如下：
redis 维护一个 24bit 的全局时钟，可以理解为系统的时间戳，定时更新这个时钟。
当插入一个新的 key 时，就将当前全局时钟的值绑定到该 key 上。等到需要淘汰的时候，那么根据淘汰策略从 键空间/expires 字典 中随机抽取 N 个 key，按照它们的时间戳进行排序比较，然后淘汰就最久的 key
（redis 使用近似 LRU 的原因可以理解为避免维护一个所有 key 的队列，节省内存）

4、redis LFU 实现：
由于 LRU 的计算并不准确，所以在 redis 4.0 出现了 LFU
LRU 的不准确体现：存在两个 key A 和 B，它们的使用情况如下：
    A~~A~~A~~A~~A~~A~~A~~A~~A~~A|
							    
    B~~~~~B~~~~~B~~~~~B~~~~~~~~~~~~~B|
按照这种上面这种情况，按照 LRU 淘汰的会是 A，但实际上 A 的使用频率比 B 要高得多，因此应该淘汰的应该是 B
因此出现了 LFU，LFU 会将上面的 24bit 进行分割，16bit 作为时钟，8bit 作为访问次数，这样的话可以根据访问次数 + LRU 进行淘汰

5、缓存雪崩：
当 redis 的 key 的过期时间设置在一个统一的时间，而在过期时间的那段时间存在一个高并发的访问情况，这样的话会导致所有的请求都打到数据库上，造成数据库崩溃（比如高并发请求同时打到数据库，而数据库是磁盘 IO，效率较低，排在后面的请求会由于超时而无法进行处理）
解决方法：
    1）给 key 的过期时间添加一个随机值，让它们的过期时间从一个点分摊为多个点，同时在更新的时候双重检查加锁更新（加的锁视情况而定，如果是单机并且 key 只是由当前模块访问，那么只需要加 sync 锁，如果是集群环境，那么需要加分布式锁）
    2）允许短暂的数据不一致性问题，缓存不直接设置过期时间，而是为每个 key 绑定一个用来记录过期时间的 expire:key，在获取的时候判断 expire:key 是否已经超时，如果超时，那么将更新缓存的任务提交到线程池异步更新，没有超时的话那么继续使用。
        需要注意的是，由于可能多个线程同时到达，所以在任务中需要先获取锁，再访问数据库获取新数据进行更新，这里同样可以使用双重检查。
        该方案的问题在于需要多余的内存空间来存储 expire:key

6、缓存穿透：
用户经常访问一些不存在的数据，即能够绕过缓存去访问数据库，使得请求都打在数据库上，导致数据库宕机。
这种情况出现问题一般是黑客蓄意使用一些不存在的参数访问进行攻击，使得请求都打在数据库上。
解决方法：
    1）对于第一次查询不存在参数，缓存空对象（缺点是当存在大量的不存在访问时，会缓存大量的空对象，占用 redis 内存）
    2）使用布隆过滤器，它是借助 redis 的 bitmap 来实现的，对一个 key 进行多个散列算法的计算，然后将得到的值分布在 bitmap 上，它只能判断哪些值一定不存在，以及哪些值可能存在，并且不能够删除，因为同个 bit 位置的 1 可能是多个 key 叠加起来的，如果删除了可能会导致其他 key 的误判
    3）不要信任用户的任何请求，对用户请求的参数进行过滤，比如有的 id = -1 或者 分页参数为 Integer.MAX_VALUE 这种明显搞事情的请求参数，那么可以进行过滤掉,可以限制分页情况下一次只能获取多少数据
    4）限制每个 ip 一定时间内的请求数（不过这个方法没什么大作用，因为如果是黑客攻击，肯定是不断变换 ip 进行攻击）

7、缓存击穿：
针对 热点 key 的问题，当一个 热点 key 设置了过期时间，而在过期了的那段时间里，大量并发请求同时访问这个 key，绕过缓存打到数据库上，导致数据库宕机。
解决方法：
    1）缓存不设置过期时间，异步更新（在更新过程中存在数据不一致问题）
    2）设置过期时间，不过当第一个线程访问发现过期时，加锁访问数据库（如果存在多个服务器，那么需要使用分布式锁），其他线程阻塞在同步代码块处，当第一个线程读取完数据存储在缓存后，其他线程去访问缓存。这里跟 单例模式的懒汉式中的双重检查一样，使用双重检查。
    （这里的问题在于如果存在大量请求同时访问的时候，会有大量线程阻塞在同步代码块处，效率较低）


8、数据库 和 缓存 的一致性问题
所谓的数据库和缓存的一致性问题：不是说不能存在短时间的数据不一致，而是说避免由于操作问题而导致长时间的数据不一致。
我们对缓存的更新不是插入数据后就直接更新，因为有的缓存是冷数据，更新了也没多少访问，没必要去浪费时间更新，不如在访问的时候发现缓存失效了再进行更新。
    1）先更新数据库，再删除缓存
    如果数据库更新失败，那么不需要删除缓存，保证了数据一致性。
    如果数据库更新成功，缓存更新失败，那么会导致数据不一致，这时候需要捕获异常循环删除直到成功为止。

	2）先删除缓存，再更新数据库
    删除缓存失败，那么不会更新数据库，保证数据一致性（这里可以循环删除缓存成功为止）。
    删除缓存成功，更新数据库失败，由于缓存中没有数据，所以仍然保证了数据一致性。
	这个方案存在一个问题：就是在多线程情况下，线程 A 执行写操作，插入数据，先删除缓存，和删除成功后去更新数据库，在更新的过程中，来了线程 B，它执行读操作，查询缓存，发现缓存为空，那么查询数据库，先一步线程 A 执行完成，然后将旧数据存储在缓存中，导致后续其他线程访问的都是缓存中的旧数据，出现缓存一致性问题

    3）延时双删
    删除缓存，再更新数据库，然后预计其他线程在读取完数据库的旧数据再存储到缓存的时候，sleep 等待这一段时间，然后再删除掉缓存中的旧数据，避免 2） 中出现的问题。
	这个方案同时也存在一个问题：sleep 时间难以估计，有时候可能会由于一点时间的偏差导致数据不一致问题，如果太长了就又导致效率降低

	4）binlog 订阅异步更新
	数据库的 binlog 是 Server 层的，所有存储引擎都适用。binlog 是二进制文件，它只记录写操作的 sql 语句，用来数据库主从节点的数据同步。
	由于 binlog 本身保证了写操作 sql 的顺序，即线程 A 如果先修改了数据行 x，然后提交了事务，线程 B 后修改数据行 x，然后提交了事务，这样数据库的数据行 x 最终是线程 B 修改的数据。而事务提交后，由于线程 A 先提交，所以线程 B 的 binlog 生成会比线程 A 的 binlog 要晚，这样就保证能够覆盖线程 A 的数据，保证 binlog 和 数据库的一致性。
	因此我们可以开一个服务订阅数据库的 binlog，数据库执行写操作后将 binlog 推送出去，然后这个服务消费这个 binlog，异步刷新缓存，如果更新失败那么循环尝试，由于是异步的，所以不会跟前面的方案一样需要阻塞，效率来说是最高的，同时保证了数据的一致性
	使用该方法我们可以将缓存不设置过期时间，异步刷新即可
    （阿里有一个模块 canal，主要用来实现 binlog 订阅，应该是基于消息队列实现的）
```





## 7、redis 持久化方式 RDB 和 AOF

```java
redis 的持久化方式有 RDB 和 AOF 两种方式
AOF 持久化方式默认是关闭的

1、RDB：
RDB 是一个二进制数据文件，它存储的都是 redis 数据库内存中某个时间点的快照。
RDB 涉及两个命令：save 和 bgsave
    1）save 执行时会阻塞 redis 主进程，由主进程进行 RDB 备份，redis 服务器这段时间无法处理用户请求（慎用）
    2）bgsave 是会 fork 一个子进程，然后让子进程进行 RDB 备份，主进程继续执行用户请求，不过子进程处理的是快照，对于后续主进程处理的写命令它是无法感知的。

RDB 备份过程：
    1）执行 bgsave 命令，主进程调用 fork() 创建一个子进程
    2）主进程继续处理用户请求，子进程对 bgsave 命令执行时的数据库快照进行备份，将 key-value 数据存储到一个新的 RDB 文件中，此时主进程执行的些命令子进程无法感知
    3）当子进程 RDB 备份完毕后，发送 ”信号“（这里是进程通信的一种方式） 通知主进程进行 RDB 文件的替换，然后子进程退出。
    4）主进程收到通知后，进行 RDB 文件的替换，完成 RDB 备份

2、AOF：
AOF 功能是默认关闭的，需要用户手动开启
AOF 文件跟 RDB 文件不同，AOF 文件不会存储数据，而是存储用户的写命令，即是文本格式的。
AOF 文件是利用 append 的顺序写方式追加写命令的，为了避免执行完写命令就写到磁盘的文件上这种消耗性能的低效刷盘，它的设计思路跟数据库的 redo log 差不多，包含 AOF buffer + AOF file 两个部分
当执行完写命令时，先将写命令写入到 AOF buffer 中，然后再按照指定的策略进行刷盘，redis 总共存在 3 种刷盘策略：
    1）always：执行完写命令就直接刷盘
    2）every second：每隔 1s 就将 AOF buffer 中的数据刷盘
    3）no：redis 不会自动刷盘，而是依托于操作系统，由操作系统决定刷盘的时机，不可控制
我们可以看出，
（1）最多只会丢失一条写命令，但是 IO 开销大，并且根本用不上 AOF buffer；
（2）是 redis 默认的策略，从数据丢失量和效率上进行权衡，最多只会丢失 1s 内的写命令；
（3）效率最高，但是同时也是最不安全的策略

AOF 文件一直追加写命令，会导致整个文件变得非常大，在后续进行恢复的时候会占用很多的时间，因此需要进行瘦身，即 AOF 重写
AOF 文件能够进行瘦身的理由是：AOF 文件中执行的插入数据在后面可能经过修改或者删除，以及多条写命令可以直接糅合为一条写命令
比如 
    rpush list "A"
    rpush list "B"
    rpush list "C"
    rpush list "D"
像这种实际上可以糅合为一条写命令
	rpush list "A" "B" "C" "D"
同时，同时不只如此，AOF 重写实际上是根据 redis 数据库内存来进行重写的，它跟 RDB 备份时一样，执行 AOF 重写的时候参考的是 数据库内存的快照，它是将数据库内存中的数据全部转换为 insert 命令的形式重新写入到 AOF 文件中的，这样就直接忽略了 旧 AOF 文件中的 update、delete 命令

AOF 重写的过程：
    1）主进程调用 fork() 创建一个子进程，同时创建一个 AOF rewrite buffer（AOF 重写缓冲区）
    2）主进程继续处理用户的请求，而此时主进程对写命令会写入到 AOF buffer 和 AOF rewrite buffer 中。子进程创建 AOF 文件，根据数据库内存快照进程重写
    3）子进程 AOF 重写完毕，发送 ”信号“ 通知主进程，子进程关闭
    4）主进程收到通知，将 AOF rewrite buffer 中的数据追加到新的 AOF 文件中，替换掉旧的 AOF 文件，AOP 重写完成

为什么需要创建 AOF rewrite buffer？
    因为子进程在重写的过程中，使用的是数据库内存快照，同时无法感知到新执行的用户写命令，所以如果不存储新的写命令，那么就会导致新的 AOF 文件中丢失这些新的写命令

为什么写到 AOF rewrute buffer 后还需要写到 AOF buffer？
    因为 AOF 重写可能会是一个比较漫长的过程，这段时间如果出现 redis 宕机了，那么重启后还是会使用到旧的 AOF 文件，因此在这段时间需要将写命令存储到 AOF buffer 中然后进行刷盘
    
    
3、RDB 和 AOF 两种备份方式的区别：
    1）数据格式：RDB 文件存储的是二进制的数据；AOF 文件存储的是写命令，是文本格式。redis 重启恢复数据的时候 RDB 文件恢复的速度更快
    2）数据丢失量：RDB 文件由于是全量备份，每次备份都是整个 redis 数据库内存的数据，所以它不会经常进行备份，因此丢失的数据就是 redis 宕机时到上一次 RDB 备份期间的所有写操作数据；AOF 文件是 append 追加的增量更新的方式，默认情况下只会丢失 1s 内的写命令
    3）优先级：在 AOF 功能开启并且存在 AOF 文件的时候，默认使用 AOF 文件进行数据恢复


4、Linux 的 fork()
    在 RDB 备份 和 AOF 重写中，都使用到了 fork() 来创建子进程，并且子进程处理的都是数据库快照，那么它们是将数据库的数据全部拷贝一遍吗？
    其实不然，Linux 设计的 fork() 使用 写时复制（CopyOnWrite）的技术，并且它跟 Java 层面的 CopyOnWriteArrayList 不同，它不会复制整个数据库数据，而是在最开始 父进程（主进程） 和 子进程共用相同的虚拟地址页，只有在主进程执行写命令需要修改某一页的数据时，子进程才会在修改前将这一页的数据复制出来。
    这种做法大大节省了内存，因为在很多情况下，大部分的数据页是不需要修改的，里面的数据是可以进行复用的。
```





## 8、IO 多路复用

```java
1、IO 多路复用是什么？
	IO 多路复用是 IO 模型的一种
    在没有 IO 多路复用的情况下，我们只能使用 BIO 或者 NIO，它们都需要给每个 socket 分配一个线程，线程资源占用大。
    而 IO 多路复用 则是使用一个线程来管理多个 socket 的读写、连接等事件。

常见的 IO 多路复用模型有：select、poll、epoll

2、select：
select 使用的数据结构是 long 型数组 fd_set，实际上是当作 bitmap 来使用的
它维护了 3 个 fd_set，read_fd、write_fd、listen_fd 分别对应 读事件、写事件、accept 事件
每个 bit 位置的下标对应 fd，比如 read_fd[10] = 1 表示监听 fd = 10 的 socket 的读事件

select 执行流程：
    1）进程关心哪些 socket 以及对应的事件，就将对应 fd_set 上对应位置的 bit 置为 1
    2）调用 select()，将 fd_set 作为方法参数传入到内核中
    3）内核拷贝 3 个 fd_set，然后进行 O(n) 轮询，它只会去查看 fd_set 上 bit = 1 的 socket,对于 bit = 0 的 socket 进程并不关心，那么内核也不会去查看
    4）轮询过程中，内核将没有发生对应事件的 bit 置为 0，同时记录发生了事件的 socket 个数 n，当全部轮询完毕后，将 fd_set 拷贝回用户态，并且 n 返回给用户态进程
    5）用户态进程根据 n 对 fd_set 进行轮询，如果 bit = 1，那么进行处理

需要注意的是，select() 每次调用前都需要重置 fd_set 中的 bit，否则 fd_set 中的数据就是被内核修改过的数据

select 的缺点：
    1）每次调用 select() 都需要将 fd_set 拷贝到内核态中，同时内核态还需要 O(n) 去轮询这些 fd_set，轮询完毕后还需要将 fd_set 拷贝回内核态
    2）内核并没有准确告知用户进程哪些 socket 发生了事件，只是将发生事件的 socket 个数告知用户进程，因此用户进程同样也需要 O(n) 去轮询这些 fd_set
    3）select 的 fd_set 由于内核的原因，只支持 [0, 1023] 索引位置的 fd，即表示 select 只能处理 1024 个 socket，超过该范围的 socket 无法正常处理
即一次 select() 需要 两次 copy 和 两次 O(n) 轮询，效率低下

3、poll:
poll 舍弃了 select 的 fd_set，而使用了链表的形式，这样就不会限制只能处理 1024 个 socket。
其他的方式跟 select 一样


4、epoll：
epoll 开启了新的模式，不再是由用户进程来管理 socket， 而是由内核来管理 socket
epoll 定义了三个函数：
    1）int epoll_create()
    2）int epoll_ctl(int epfd, int op, int fd, epoll_event *event)
    3）int epoll_wait(int epfd, epoll_event *events, int maxevents, int timeout)

epoll 内部使用一个红黑树来管理所有的 fd，使用一个 rdlist(ready list) 就绪链表来存储存在事件的 fd：
    1）当用户进程调用 epoll_create() 那么会创建一个 epoll 对象
    2）当用户进程调用 epoll_ctl() 添加一个新的 fd 时，会同时根据监听的事件注册一个回调函数 ep_poll_callback() 到网卡设备上，当发生监听的事件时，会调用这个回调函数将 fd 加入到 rdlist 中
    3）当用户进程调用 epoll_wait() 的时候，如果 rdlist 中存在节点，那么将 rdlist 中的 fd 以及对应的事件 拷贝到用户进程，用户进程只需要轮询这些节点即可；如果 rdlist 为空，那么用户进程会进入等待队列中等待，如果在等待期间有 fd 发生事件，调用了回调函数，那么回调函数在将 fd 放入 rdlist 后会唤醒用户进程；如果等待超时，那么直接返回
    
关于 epoll_wait() 是否会发生拷贝：
	在 epoll_wait() 源码里面有个 put_user()，表示将 epoll_event 拷贝到用户态进程，因此是发生了拷贝的
    而且调用 epoll_wait() 时需要传入一个 epoll_event 指针，这是用户进程开辟的内存，这也表示了是需要发生拷贝的
	它并没有使用 mmap 共享内存来减少拷贝（很多文章都是说使用共享内存的方式来减少拷贝，这是错的，至少源码没体现）
	
epoll 相比 select 的优点：
    1）epoll 由内核来管理 socket，省去了 select 数据结构 fd_set 的用户态和内核态之间的拷贝
    2）epoll 通过回调函数的机制以及将发生事件的 fd 和 对应的事件直接拷贝到内核态，省去了内核和用户进程 O(n) 轮询的时间
    3）select 和 poll 只支持 LT，而 epoll 支持 LT 和 ET

epoll 的两种触发方式：
1）水平触发 LT： 如果按照电平来说，那么只要位于高电平就会触发
    可读事件：如果 socket 接收缓冲区存在数据，那么就会触发可读事件
    可写事件：如果 socket 发送缓冲区未满，那么就会触发可写事件

2）边缘触发 ET: 如果按照电平来说，那么只有从低电平变为高电平的时候才会触发
    可读事件：只有接收到新的数据才会触发可读事件
    可写事件：
            socket 发送缓冲区状态变化： 满-> 未满，触发一次可写事件
            epoll_ctl() 注册可写事件（无论是新添加 fd 还是 重新注册监听事件），触发一次可写事件
            同时监听读写事件，当可读事件发生时，如果发送缓冲区未满，那么会顺带一个可写事件
            
对于 ET，如果可读事件触发后没有一次性全部读取完毕，那么也不会再触发可读事件，因为在 epoll_wait() 中当拷贝到用户进程后会将该 fd 从 rdlist 中移除，而 LT 则是会继续存储到 rdlist 中。
所以 ET 在必要的情况下需要使用 while 读取完所有的数据，同时要设置 非阻塞，避免读取完数据后阻塞在 read() 处


LT 和 ET 之间的区别：
ET 是用来减少一些不必要事件的频繁触发，防止浪费 CPU 资源
    LT 的可读事件：不需要一次全部读取完成，因为下次还是会在 rdlist 中，可以留到下次读取
    ET 的可读事件：一般需要使用 while 循环读取，否则可能会导致数据堆积，而 while 读取需要将 fd 设置为非阻塞，防止数据读取完毕后阻塞在 read() 处
    LT 的可写事件：如果在不需要写数据的情况，那么需要将可写事件移除掉，否则会频繁触发
    ET 的可写事件：如果可写事件触发后，有的数据还没有处理完成，无法此时写入时，那么可以在数据处理完成后重新注册监听可写事件，以此来触发可写事件，然后将处理完的数据写入
```





## 9、redis 分布式锁

[细说分布式锁🔒](https://juejin.cn/post/6844904082860146695)

```java
1、单纯的 setnx：
最开始使用 setnx key value 指令进行加锁，此时无论 value 是什么都无所谓
问题在于此时的锁是无过期时间的，只有加锁的线程执行完成后释放锁，别的线程才能去获取锁
如果线程执行过程中宕机了，那么这把锁将得不到释放，只有程序员去手动释放



2、setnx + expire 组合
这里使用 setnx key value + expire key seconds 两条指令来解决宕机时锁的释放问题
在加锁后进行设置锁的过期时间，这样就算宕机了，那么同样也会因为过期了而得到释放

但是这个方案存在问题：setnx 和 expire 指令的执行不是原子性的，如果在执行完 setnx 后宕机了，那么同样还是会导致锁无法释放



3、使用 set 指令实现 setnx + expire 的原子性
redisTemplate 中有一个 api：Boolean setIfAbsent(K key, V value, long timeout, TimeUnit unit); 
它能够将 setnx 和 expire 两条指令原子性执行，而实际上它们并不是利用 setnx 和 expire 来实现的，而是利用 set 来实现的。
随着 redis 的发展，set 指令添加了很多的参数，其中 NX 参数可以实现 setnx 的功能，EX 参数可以实现 expire 的功能。
set 通过添加不同参数的方式来实现 setnx 和 expire 的功能组合以及原子性操作

set 命令参数如下：
	//SET key value [EX seconds|PX milliseconds] [NX|XX] [KEEPTTL]
比如我们执行：
	//set key value EX 30 NX
表示设置 如果 key 不存在，那么进行存储，同时设置 30 秒的过期时间

但是这个方案还是存在问题：线程 A 获取锁后，在过期时间内没有完成业务操作，那么锁就会释放了，这样的话假设线程 B 获取了锁，而在线程 A 执行完后，会在 finally 中将线程 B 获取的锁给释放掉，然后线程 C 获取锁，线程 B 执行完后又会将线程 C 的锁给释放掉，这样下来，这把分布式锁实际上没有起到任何的作用



4、value 参数的作用
我们上面的所有方案中，都是通过 key 来控制分布式锁的获取的，而 value 我们并没有特别的声明，而在这里，我们可以通过 value 来识别哪一个线程获取了锁。
线程在获取锁前，生成一个 uuid，作为自己的标识，然后在获取锁的时候，将 uuid 作为 value 设置进去：
	set key uuid EX 30 NX
这样在获取锁的时候，如果线程 A 获取了锁，而在过期时间内没有完成业务操作，那么自动释放锁后，线程 B 获取锁，将 value 设置为自己的 uuid，等到线程 A 执行完后，会执行 finally 中的代码块进行锁的释放：
	try{
		redisTemplate.setIfAbsent(key, uuid, 30, TimeUnit.SECOND);
	}finally{
		if(redisTemplate.get(key) == uuid){
			redisTemplate.delete(key);
		}
	}
在 finally 中它先执行 get(key)，如果 value 不是自己的 uuid，那么就不执行 delete
如果是自己的 uuid，那么再执行 delete 删除 key，这样就可以避免删除了别的线程的锁

但是这个方案还是存在问题：在 finally 中，get() 和 delete 不是原子性的，这样的话，当 get() 的时候发现 value 是自己的 uuid，但是在执行 delete 前 key 过期了，导致其他的线程先加锁了，这样就会导致删除了别的线程刚加的锁。
（这个问题是有可能发生的，因为 redis 是单线程执行用户指令，只要在线程 A get() 后别的线程在线程 A 提交 delete 指令前先一步提交 set 指令，那么就会导致这种情况）



5、lua 脚本
上面的问题的产生就是因为 get() 和 delete() 之间不存在原子性，即 get() 和 delete() 提交的时机不同，它们之间可能会插入别的线程的指令。
redis 支持 lua 脚本，它能够将多条指令作为一条指令提交给 redis 执行，我们可以通过 lua 脚本，将 get()、delete() 作为一条指令让 redis 去执行

lua 脚本如下：
    -- lua 脚本删除锁：
    -- KEYS 和 ARGV 分别是以集合方式传入的参数。
    -- 这个集合是索引下标是以 1 开头的，KEYS[1] 是我们传入的 key，ARGV[1] 是我们传入的 uuid
    -- 如果对应的 value 等于传入的 uuid。
    if redis.call('get', KEYS[1]) == ARGV[1] 
        then 
        -- 执行删除操作
            return redis.call('del', KEYS[1]) 
        else 
        -- 删除不成功，返回 0
            return 0 
    end

lua 脚本用起来很麻烦，所以出现了 redission，它是 JAVA 层面的 redis 客户端之一，可以直接用来分布式锁的加锁和解锁
redission 对外提供了 lock() 和 unlock() 两个接口，用于实现加锁和解锁，这个封装就很像 ReentrantLock
不同的是它是对 lua 脚本的封装，加锁和解锁都是使用的 lua 脚本。

这里可能有个疑问：加锁使用 set 指令不就能保证 原子性 setnx 和 expire 了吗？ 为什么还要使用 lua 脚本？
因为它内部不仅考虑到加锁，还考虑到了分布式锁的重入性，加锁的 lua 脚本大致如下：
    /*
    	KEYS[1] 是 key
    	ARGV[1] 是 过期时间
    	ARGV[2] 是 uuid
    	这里由于需要记录 key、uuid 和 重入度，所以仅仅使用一个 set 是不够的，所以这里使用 hash
    	hash 的结构为 [key field value]，在这里表示 [key, uuid, 重入度]
		
    */
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
                                          //exists 命令，判断 key 是否存在，如果不存在, 执行下面代码
                                          "if (redis.call('exists', KEYS[1]) == 0) then " +
                                          	//设置 [key, field, value] 为 [key, uuid, 1]
                                          "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                                          	//设置过期时间
                                          "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                                          	//返回 null
                                          "return nil; " +
                                          	//结束
                                          "end; " +
                                          //如果存在
                                          //那么执行 hexists 命令，判断 key 下的 field = uuid 是否存在
                                          "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                                          	//如果存在，那么调用 incr 将它的重入度 +1
                                          "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                                          	//设置过期时间
                                          "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                                          "return nil; " +
                                          "end; " +
                                          //已经有线程加锁，并且加锁线程不是自己，调用 pttl 返回锁的过期时间
                                          "return redis.call('pttl', KEYS[1]);",

redission 的加锁是一段 lua 脚本，由于需要记录重入度，所以简单的的一个 set 是不够的，所以它使用 hash 来存储
	[key filed value] 表示 [key, uuid, 重入度]
加锁过程：
    1）判断 key 是否存在
    2）如果 key 不存在，表示没有线程获取锁，那么将 uuid 和 重入度 1 设置进去
    3）如果 key 存在，判断 filed 是否是当前 uuid
    4）如果 field 是当前 uuid，那么将它的重入度 +1
    5）如果 field 不是当前 uuid，那么调用 pttl 给线程返回锁的过期时间
                                          

6、redLock 红锁
redLock 出现的目的是为了解决以下问题：
	redis 集群加锁情况下，主节点 set 后告知服务器加锁成功，然而还没有将数据同步给从节点就宕机了，这样选举了一个从节点作为主节点后，另一个线程也可以获取锁成功，导致同时两个线程自认为处于持有锁的状态

redLock 要求 5 个 redis 实例，它们之间不存在任何的主从关系，即是平级的，类似 redis cluster 中的多个主节点，每次服务器请求加锁的时候，只有 (N / 2) + 1 个 redis 实例都 set 成功了，该线程才会加锁成功。解锁时需要所有实例都进行解锁才成功。
需要注意的是，加锁花费的时候必须小于锁设置的过期时间，比如设置锁的有效时间为 30s，加锁花费了 31s，那么加锁也是失败的，同时加锁的花费时间也是算在有效时间里的，比如有效时间为 30s，但是加锁花费了 3s，那么实际上线程持有锁的时间为 27s。
```





## 10、redis 集群

```java
1、CAP 原理：
    C：一致性，这里指的是数据的强一致性，表示节点间始终都是数据一致的
    A：可用性，当一个节点宕机了，那么服务仍然可以使用，即使用从节点顶上去
    P：分区容忍性，主从节点分布在不同的机器上，这里存在网络隔离，因此节点间可能存在通信失败、通信延迟等问题，导致主从节点间数据不一致，分区容忍性就是允许短暂的数据不一致性，只要最终主从节点间能够数据一致即可

A 是必须要的，而 C 和 P 是互斥的，二者只能选一
    1）如果选择 C，那么就是不能容忍短暂的数据不一致，那么一旦通信失败就需要停止节点对外的服务，直到节点间通信正常以及数据同步为止
    2）如果选择 P，那么只要保证服务能够对外提供服务即可，只要求数据的最终一致性
一般情况下都是选择 A 和 P，这两个才能真正保证高可用

2、BASE 原理：
BA：基本可用，
S：软状态，


3、主从复制：
主从复制模式是一个主节点 master，一个或者多个从节点 slave
主从节点读写分离，master 负责写操作，slave 负责读操作
既然写操作都在 master 中，那么就必定需要将数据同步到 slave，redis 指定了两种同步方式：全量复制 和 增量复制

在讲解全量复制和增量复制前，需要提到 3 个东西：
1）复制偏移量 offset：
	master 和 slave 之间都会维护一个 offset，当 master 和 slave 的 offset 相同时，表示它们的数据一致；不相同时，表示 master 和 该 slave 数据不一致，master 需要根据相差的 offset 将 slave 欠缺的数据发送给 slave。
	比如 master 的 offset = 1000，slave 的 offset = 990，那么 slave 欠缺 offset = [991, 1000] 的这 10B 数据，那么 master 需要将这 10B 数据发送给 slave。

2）复制缓冲区 buffer：
	master 会维护一个 buffer，上面存储着每个字节对应的 offset，比如 slave 相差 [991, 1000] 的数据，那么 master 就将 buffer 中标记着 [991, 1000] 的数据发送给 slave。
	需要注意的是，buffer 的空间是有限的，如果 buffer 无法容纳新的写命令，那么会将旧的数据挤出。
	因此，一旦 slave 缺失的数据已经不在 buffer 上了，那么就必须执行全量复制，发送 RDB 文件。

	buffer 中存储的是整条写命令，将命令拆分为 char[] 进行存储：
	offset	0032	0033	0034	0035	0036	0037	0038	0039	0040	0041	0042
	value	$		3		\r		\n		d		e		l		\r		\n		$		4

3）runId：
	在 master 和 slave 在每次启动时都会随机分配一个 runId。
	master 和 slave 在第一次通信时， master 会将自己的 runId 发送给 slave，slave 会持久化保存 master 的 runId。
	当 slave 宕机重启时，会向 master 发送自己保存的 master runId 和 offset， 如果当前的 master 的 runId 和 收到的 runId 一样并且 buffer 的数据还在，那么就可以继续增量复制，如果 runId 不一致或者欠缺的数据已经不在 buffer 中了，那么就只能进行一次全量复制。


全量复制：
    如果是刚接入的 slave 节点，它没有数据，因此它会向主节点发起全量复制的命令，主节点收到后，调用 bgsave 命令，生成一份 RDB 文件。
    在执行 bgsave 命令的时候，master 会继续执行用户命令，而这些新的用户命令会存储到 复制缓冲区 buffer 中。
    当 bgsave 完成后，master 将 RDB 文件发送给 slave，然后再将 buffer 中的数据发送给 slave。
    slave 收到 RDB 文件后，清空自己的数据，然后将使用 RDB 文件同步数据，再执行收到的 buffer 中的写命令。

全量复制的问题：
	1）在 bgsave 生成 RDB 文件、传输 RDB 文件、slave 使用 RDB 文件同步数据这些过程中，slave 是无法对外提供服务的
	2）如果数据太多，bgsave 时间太长，期间写命令过多，导致 buffer 中的数据溢出，那么表示此次 bgsave 无效，需要重新进行 bgsave。


增量复制：
	增量复制需要的就是上面讲的 3 个东西，offset、buffer、runId，主从节点之间通过 offset 来判断缺失的数据以及数据同步是使用增量复制还是去全量复制
	当全量复制后，master 和 slave 之间会使用增量复制来同步数据，只要 slave 缺失的 offset 后面的数据还在 buffer 中，那么就可以执行增量复制，否则将执行全量复制


主从复制的缺点：
    1）一旦 master 宕机了，那么需要开发人员手动指定其中一个 slave 作为 master
    2）如果 slave 和 master 还没有数据同步完成，master 宕机了，那么会导致 offset 差值之间的数据丢失


4、哨兵模式：
现在也不用这个，就不讲了


5、redis cluster：
redis cluster 使用的是去中心化的设计思想，使用多个主从复制节点联合的方式，但是各个 master 之间地位平等
redis cluster 去除了哨兵节点，但是为每个 redis 节点增加了故障判断和故障转移的功能，即将 哨兵节点的功能加到 redis 节点上

//待定
```




