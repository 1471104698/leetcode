# Redis key 知识点

## 1、key 过期策略 + 内存淘汰

redis 所有数据都是存储在 内存中的，内存很宝贵且有限，磁盘廉价且大量

由于 redis 的内存是有限的，因此不可能一直往 redis 中添加 key 而不进行处理，这样的话迟早会堆满整个内存空间

因此，对 key 的处理就显得至关重要了



我们需要知道，在 redis 当中，key 过期了如果没有删除的话仍然还是会占用内存的，因为过期仅仅只是一个标识符标识这个 key 不能再进行返回了而已，实际数据还是存在内存中的

因此，删除过期的 key 以及 当 redis 内存不足以存储新的 key 时的 处理方式 就显得格外重要



在此之前，我们需要先知道 **redis 中的一些存储 key 的数据结构：**

- expires 字典：存储了所有设置了过期时间的 key 以及对应的过期时间
- 键空间：保存了所有的 key（无论是否存在过期时间），expires 字典可以算作 键空间的一部分



> ### key 过期处理策略

- 定时删除：每个设置过期时间的 key 都会绑定一个专属的定时器，这样到达过期时间了就会立马删除过期的缓存 key
  - 该方法对内存很友好，因为会立即删除，不会占据内存，但是对 CPU 不友好，因为有 key 过期就需要 CPU 去处理，如果同一段时间过期的 key 量大，那么占用的 CPU 资源将会是巨大的
- 惰性删除：当一个 key 被访问时，才会判断该 key 是否已经过期，如果是，则删除。
  - 该方法对 CPU 友好，但是对 内存不友好，因为当大量过期的 key 没有被访问时，会一直占据着内存空间
- 定期删除：redis 默认每隔 100ms 就扫描 expires 字典，并在其中随机抽取一些  key，检查是否过期，如果过期了，那么就直接删除
  - 该方法是定时删除 和 惰性删除的折中方案，一般情况下可以让 内存和 CPU 的性能达到平衡
  - 假设 redis 里面存放了 10W 个设置了过期时间的 key，每隔 100ms，就遍历 10W 个 key，这个是不现实的，因此只是随机选择一些 key 进行扫描
  - **定期删除的问题：**定期删除需要调整好 扫描和删除 的总体时间，如果太长，就浪费了 CPU，如果太短，过期的 key 一直没有被删除，那么就占据了内存

**redis 使用的过期策略是 定期删除 + 惰性删除**



当 redis 的这两个过期 key 处理策略的处理速度比不上 key 的添加速度时，就会出现内存不足的问题

这时候就需要 内存淘汰策略

> ### 内存淘汰策略

当用户要存储新的 key，而 redis 内存不足以存储这个 key 及 value 数据时，可以有以下的策略：

- 直接报错
- **allkeys-lru**：移除掉 键空间 中最近最少使用的 key（最常用）
- allkeys-random：随机移除掉 键空间 中的某个 key
- volatile-lru：移除掉 expires 字典 中最近最少使用的 key
- volatile-random：随机移除掉 expires 字典 字典中的某个 key
- volatile-ttl：在 expires 字典 中，优先移除掉过期时间距离现在最近的 key





## 2、key 三大问题：缓存雪崩、缓存穿透、缓存击穿



### 1、缓存雪崩

> ### 问题

缓存雪崩就是在**同一个时间段大量的 缓存 key 都失效了**，而这时大量的并发请求都打到 数据库上，导致数据库宕机



**举个简单的例子：**电商首页所有的 key 失效时间都是中午 12 点，即在 12 点会进行缓存的刷新，而在中午 12 点有个秒杀活动，并发量会非常高，假设每秒 1W 请求，本来 redis 能够命中 8000 个 请求的，但是由于所有的 key 都失效了，那么就会导致这 1W 个 key 全部打到数据库上，可能会导致数据库直接宕机，后续重启也会被新的流量直接打死，而其他所有依赖这个数据库的接口全部瘫痪，用户体验极差

![img](https://pic4.zhimg.com/80/v2-e6e23ac28b0915c0fae67b5d6da34277_720w.jpg)



> ### 解决

由于是同一时间大量 key 失效才会造成这个问题，那么我们只需要将 key 的失效时间错开就可以了

在设置失效时间时加上一个随机值，这样可以保证在同一段时间内大面积 key 失效，剩下的我感觉 redis 这点流量是顶得住的

```C
setRedis（Key，value，time + Math.random() * 10000）；
```



或者设置热点数据永不过期，这样只需要定期刷新缓存就可以了（刷新缓存的时候加锁）



### 2、缓存穿透

> ### 问题

缓存穿透就是 用户不断请求数据库中没有的数据，这样就必定不会走缓存，直到打到数据库上

比如 数据库表 id 是从 1 自增上去的，这样的话用户不断请求 id = -1 的数据，就可以直接绕过缓存，打到数据库

这样的用户很可能就是攻击者了，一旦并发量高，数据库可能直接宕机

![img](https://picb.zhimg.com/80/v2-e846d8c3371c5eef80cf4185bcec15c4_720w.jpg)

> ### 解决

- 对参数进行校验，上面的 id = -1 明显是不可能存在的参数，因此需要进行校验，而有的情况下需要接收分表查询的参数，类似这种的也需要校验，因为前端发过来的不一定都是合法参数，可能是攻击者之类发的，要是最大为 max = Integer.MAX_VALUE，那么数据库表数据量一大，每次查询都要几秒，这样问题就大了，这种的请求直接舍弃掉
- 限制每个 ip 每秒可以发送的请求数（不过对于攻击者来说没啥实际作用，攻击者可以用不同的 ip 发起攻击）
- 对于第一次查询不存在的数据，我们定期缓存空对象 null
  - 由于可能很多请求的数据会不存在，所以可能需要在 redis 大量缓存空对象，这样就会导致内存大量占用
- 最好的方法就是使用 布隆过滤器，它能够判断哪些数据必定是不存在的，哪些数据是可能存在的，对于必定不存在的数据我们就没必要去查询数据库
  - 布隆过滤器底层是 bitmap，经过多次 hash 得到一串二进制数，将每个数映射到这个 bitmap 上
  - 布隆过滤器的缺点就是只能增加不能删除，并且一旦数据量一大，误判的可能性也会提高



### 3、缓存击穿

> ### 问题

缓存击穿 有点像 缓存雪崩，但是缓存雪崩指的是不同的 key 大面积失效，而 缓存穿透 指 一个非常热点的 key 在失效的时候，高并发不断对这个 key 进行访问，导致全部打到数据库中

由于只是一个 key 失效导致的问题，就跟一颗子弹直接击穿然后出现一个洞一样

![img](https://pic2.zhimg.com/80/v2-102c103361db026414237c4be9de2ec9_720w.jpg)



> ### 解决

- 设置热点 key 永不过期
- 从 redis 读取如果为空，那么 lock() 加锁从 db 中获取，保证一次只有一个请求访问数据库，防止高并发都打到数据库上，读取完数据回来后将数据放回缓存，让其他的请求去访问缓存（redis 双重检查）





## 3、缓存数据库双写问题

一般情况下，如果**先修改数据库，再删除缓存**，那么如果缓存删除失败了，那么数据库中的是新值，缓存中的是旧值

这就出现了缓存不一致的问题，而读线程读取到的就是缓存中的旧值

如果**先删除缓存，再修改数据库**，如果缓存删除失败，那么也不会去修改数据库，保证了数据一致性，如果缓存删除成功，数据库修改失败，那么缓存为空，数据库为旧值，后续的读线程读不到缓存就会去查询数据库，保证了数据一致性



> ### 为什么是删除缓存，而不是更新缓存？



**原因一：**更新效率低

在复杂的缓存场景，有的缓存不是单单一个表的数据，而是多个表计算出来的数据

假设一个缓存是 3 个表联合计算出来的数据，如果我们更新了某个表的数据，这样如果要更新缓存就需要去读取另外两个表

如果频繁的修改某个表的数据，而某个 key 是由这个表和其他表的数据联合计算的，那么就同样的需要去频繁查询其他的两个表，这样效率太低了



**原因二：**读写比例不成正比

假设我们对某个数据行频繁的进行写，但是却少读，即 1 min 内 有 1000 次写，但是却只有 1 次读

如果这 1000 次写 都去更新缓存，那么实际上真正用到的只有其中的 1 次更新，其他的 999 次更新都是无意义的，浪费 CPU 资源

因此设计为需要用到的时候再去更新缓存

**删除缓存而不是更新缓存，是一种 lazy 的设计思想**