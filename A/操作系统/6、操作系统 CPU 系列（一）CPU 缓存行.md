# CPU 缓存行



[CPU 缓存行 和 问题详解](https://www.jianshu.com/p/e338b550850f )



最开始知道 CPU 缓存行应该是在 理解 volatile 实现原理的时候，volatile 变量写回内存会使得 CPU 所有核心 中存在该 volatile 变量的缓存行都失效，从而使得缓存中的值是最新值

后面在 GC 的 卡表中涉及到写屏障，而频繁的写屏障又涉及到 虚共享问题，这个虚共享问题就是缓存行造成的



## 1、CPU 缓存行是什么？

[看看自己在评论问中的问题以及楼主解答](https://zhuanlan.zhihu.com/p/135462276)



CPU 规定了它操作数据的基本单位就是 缓存行，一般的缓存是 64B

CPU 从主存读取数据同样是以 缓存行 作为基本单位



一个缓存行 64B，一个 long 型 8B，那么一个缓存行可以存储 8个 long 变量

当访问一个 long 数组中的任意一个索引位置的值时，CPU 会**额外免费加载**另外 7 个到缓存中（**随机缓存附近的变量，凑齐缓存行**），因为它是以缓存行作为基本存取单位的，所以一次会从内存中获取 64B 数据。因此，由于缓存行的存在，CPU 能够非常快的遍历 类似数组这种 连续内存空间 的数据结构，因为 CPU 一次访存就能够获取到要遍历的大部分数据。

但是如果是 链表 这种内存空间不连续的数据结构，那么一次访问可能只能获取到 1 个真正有用的数据，缓存行中的其他数据都于此次遍历来说没有任何意义。因此，数组 这种数据结构的访问速度 比 链表 快的原因在于此



所以，对于数组的访问，一般 访问每行的列 会比 访问每列的行 要更快

```java
public class Main{
	public static void main(String[] args){
		int N = (int)1e4;
		int[][] mat = new int[N][N];
        //先访问每行的列，速度更快，因为利用了 CPU 缓存行提前缓存附近的数据
        for(int i = 0; i < N; i++){
            for(int j = 0; j < N; j++){
                arr[i][j] = 1;
            }
        }
        //先访问每列的行
        for(int i = 0; i < N; i++){
            for(int j = 0; j < N; j++){
                arr[j][i] = 1;
            }
        }
	}
}
```



## 2、CPU 缓存行 的 虚共享 问题

CPU 会一次读取内存中 缓存行大小的数据，而这个缓存行的数据可能包含了很多的变量

CPU 缓存行有一个很明显的特点：当缓存行中的某个数据无效时，那么整个缓存行的数据都无效，需要再次访问主存，更新缓存行数据

**问题产生：**

假设 CPU 存在两个核心 CPU1 和 CPU2

当线程 A 修改完 head 变量，将它写回主存中，由于 volatile 的缘故，所以 CPU2 中存在 head 变量的缓存行也会失效，导致它需要重新访问主存（CPU2 不能只是把 head 标记为无效而只去主存中获取 head，因为它的处理单位是 缓存行）。

但实际上，对于 CPU2 中的 线程 B 来说，它明显是不需要使用到 head 变量的，但却要因为 head 失效的原因使得缓存行无效去重新访问主存，效率降低，这都是 缓存行 造成的结果



上述问题 就是 **缓存行造成的 虚共享 问题**，访问 head 会得到 tail，访问 tail 会得到 head，实际上这种无法通过代码看出来，同时也没有任何的编译警告，在不为人知的情况下，泄漏一个并发效率很低的代码

