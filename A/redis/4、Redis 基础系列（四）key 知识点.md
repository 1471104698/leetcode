# Redis key 知识点

## 1、key 过期策略 + 内存淘汰

redis 所有数据都是存储在 内存中的，内存很宝贵且有限，磁盘廉价且大量

由于 redis 的内存是有限的，因此不可能一直往 redis 中添加 key 而不进行处理，这样的话迟早会堆满整个内存空间

因此，对 key 的处理就显得至关重要了



我们需要知道，在 redis 当中，key 过期了如果没有删除的话仍然还是会占用内存的，因为过期仅仅只是一个标识符标识这个 key 不能再进行返回了而已，实际数据还是存在内存中的

因此，删除过期的 key 以及 当 redis 内存不足以存储新的 key 时的 处理方式 就显得格外重要



在此之前，我们需要先知道 **redis 中的一些存储 key 的数据结构：**

- expires 字典：存储了所有设置了过期时间的 key 以及对应的过期时间
- 键空间：保存了所有的 key（无论是否存在过期时间），expires 字典可以算作 键空间的一部分



> #### key 过期处理策略

- 定时删除：每个设置过期时间的 key 都会绑定一个专属的定时器，这样到达过期时间了就会立马删除过期的缓存 key
  - 该方法对内存很友好，因为会立即删除，不会占据内存，但是对 CPU 不友好，因为有 key 过期就需要 CPU 去处理，如果同一段时间过期的 key 量大，那么占用的 CPU 资源将会是巨大的
- 惰性删除：当一个 key 被访问时，才会判断该 key 是否已经过期，如果是，则删除。
  - 该方法对 CPU 友好，但是对 内存不友好，因为当大量过期的 key 没有被访问时，会一直占据着内存空间
- 定期删除：redis 默认每隔 100ms 就扫描 expires 字典，随机抽取一些  key，检查是否过期，如果过期了，那么删除
  - 该方法考虑 内存和 CPU 的权衡
  - 为什么不扫描整个 expires 字典？假设 redis 里面存放了 10W 个设置了过期时间的 key，每隔 100ms，就遍历 10W 个 key，这个是不现实的

**redis 使用的过期策略是 定期删除 + 惰性删除**



> #### 8 种 内存淘汰策略

 [彻底弄懂Redis的内存淘汰策略 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/105587132) 



redis 的内存空间是有限的，如果一直存储，那么总会挤满整个内存空间，单靠 key 过期处理策略是不行的

当要存储新的 key，而 redis 无法分配内存时，可以采取以下的策略：

1.  noeviction ：报错

2. **allkeys-lru**：移除掉 键空间 中最久没有使用的 key（LRU）

3. allkeys-random：随机移除掉 键空间 中的某个 key

4. volatile-lru：移除掉 expires 字典 中最久没有使用的 key（LRU）

5. volatile-random：随机移除掉 expires 字典 字典中的某个 key

6. volatile-ttl：在 expires 字典 中，优先移除掉过期时间距离现在最近的 key
7. volatile-lfu：从 expires 字典中删除使用频率最少的键（LFU）
8. allkeys-lfu：从键空间中删除使用频率最少的键（LFU）





## 2、key 三大问题：缓存雪崩、缓存穿透、缓存击穿



### 1、缓存雪崩

> #### 问题

缓存雪崩就是在**同一个时间段大量的 缓存 key 都失效了**，而这时大量的并发请求都打到 数据库上，导致数据库宕机



**举个简单的例子：**电商首页所有的 key 失效时间都是中午 12 点，即在 12 点会进行缓存的刷新，而在中午 12 点有个秒杀活动，并发量会非常高，假设每秒 1W 请求，本来 redis 能够命中 8000 个 请求的，但是由于所有的 key 都失效了，那么就会导致这 1W 个 key 全部打到数据库上，可能会导致数据库直接宕机，后续重启也会被新的流量直接打死，而其他所有依赖这个数据库的接口全部瘫痪，用户体验极差

![img](https://pic4.zhimg.com/80/v2-e6e23ac28b0915c0fae67b5d6da34277_720w.jpg)



> #### 解决

由于是同一时间大量 key 失效才会造成这个问题，那么我们只需要将 key 的失效时间错开就可以了

在设置失效时间时加上一个随机值，这样可以保证在同一段时间内大面积 key 失效，剩下的我感觉 redis 这点流量是顶得住的

```C
setRedis（Key，value，time + Math.random() * 10000）；
```



或者设置热点数据永不过期，这样只需要定期刷新缓存就可以了（刷新缓存的时候加锁）



### 2、缓存穿透

> #### 问题

缓存穿透就是 用户不断请求数据库中没有的数据，这样就必定不会走缓存，直到打到数据库上

比如 数据库表 id 是从 1 自增上去的，这样的话用户不断请求 id = -1 的数据，就可以直接绕过缓存，打到数据库

这样的用户很可能就是攻击者了，一旦并发量高，数据库可能直接宕机

![img](https://picb.zhimg.com/80/v2-e846d8c3371c5eef80cf4185bcec15c4_720w.jpg)

> #### 解决

- **对参数进行校验**，上面的 id = -1 明显是不可能存在的参数，因此需要进行校验，而有的情况下需要接收分表查询的参数，类似这种的也需要校验，因为前端发过来的不一定都是合法参数，可能是攻击者之类发的，要是最大为 max = Integer.MAX_VALUE，那么数据库表数据量一大，每次查询都要几秒，这样问题就大了，这种的请求直接舍弃掉
- **限制每个 ip 每秒可以发送的请求数**（不过对于攻击者来说没啥实际作用，攻击者可以用不同的 ip 发起攻击）
- 对于第一次查询不存在的数据，我们定期**缓存空对象 null**
  - 由于可能很多请求的数据会不存在，所以可能需要在 redis 大量缓存空对象，这样就会导致内存大量占用
- 最好的方法就是**使用 布隆过滤器**，它能够判断哪些数据必定是不存在的，哪些数据是可能存在的，对于必定不存在的数据我们就没必要去查询数据库
  - 布隆过滤器底层是 bitmap，经过多次 hash 得到一串二进制数，将每个数映射到这个 bitmap 上
  - 布隆过滤器的缺点就是只能增加不能删除，并且一旦数据量一大，误判的可能性也会提高





### 3、缓存击穿

> #### 问题

缓存击穿 有点像 缓存雪崩，但是缓存雪崩指的是不同的 key 大面积失效，而 缓存穿透 指 一个非常热点的 key 在失效的时候，高并发不断对这个 key 进行访问，导致全部打到数据库中

由于只是一个 key 失效导致的问题，就跟一颗子弹直接击穿然后出现一个洞一样

<img src="https://pic2.zhimg.com/80/v2-102c103361db026414237c4be9de2ec9_720w.jpg" style="zoom:50%;" />



> #### 解决

- 设置热点 key 永不过期
- 从 redis 读取如果为空，那么 lock() 加锁，然后再访问 db，保证一次只有一个请求访问数据库，防止高并发都打到数据库上，读取完数据回来后将数据放回缓存，让其他的请求去访问缓存（redis 双重检查）





## 3、缓存数据库一致性问题（双写问题）

使用缓存就必定会存在数据不一致的问题，**我们不要求数据强一致，只要求数据最终一致性**

因此，我们下面探讨的数据一致性问题，是防止由于某些操作导致的 长时间性 的数据库和缓存的不一致，而不是短暂的不一致



### 1、先更新数据库，再删除缓存

更新完数据库，删缓存这段时间出现数据不一致，线程获取到的是缓存中的旧数据

可能会出现缓存删除失败，所以我们需要捕获异常，然后进行重试



### 2、先删除缓存，再更新数据库

删除完缓存，更新数据库失败，那么这时候数据库的是旧数据，缓存为 null，还是保证了数据一致性

但是如果是多线程的情况下：

- 线程 A 删除了缓存
- 线程 B 获取缓存发现为 null，那么就查询数据库，然后将数据库旧值存储到缓存中
- 线程 A 更新数据库

这样的话就导致数据库缓存 **长时间** 数据不一致，数据库的是新值，缓存的是旧值



### 3、延时双删

删除完缓存，更新完数据库，睡眠一段时间，再删除缓存

这样的话即使上述的线程 B 将旧数据存储到缓存中了，也会被删除掉

只是在睡眠的这段时间内 数据库缓存存在不一致

```java
redis.del()
db.update()
Thread.sleep(500);
redis.del()
```

睡眠的时间根据实际情况来判断，缺点是难以估计睡眠时间

不过如果第二次删除失败的话，需要不断进行重试直到成功



### 4、基于 binlog 的异步更新（最优）

数据库对每条写操作都会生成对应的 binlog，并且它是确保了一定的顺序的，即谁先执行那么谁就先生成 binlog

这样的话，线程 A 先修改了 数据行 x，然后线程 B 再修改 数据行 x，那么线程 A 会比 线程 B 先生成 binlog

这样执行 binlog 的话，线程 B 的 binlog 会覆盖掉 线程 A 的 binlog，保证了最终 redis 数据必定跟数据库的一致

因此，可以开一个程序订阅数据库的 binlog ，异步更新缓存



MySQL binlog 增量订阅消费 + 消息队列 + 增量数据更新到redis

**1）读Redis**：热数据基本都在Redis

**2）写MySQL**:增删改都是操作MySQL

**3）更新Redis数据**：MySQ的数据操作binlog，来更新到Redis



**1）数据操作主要分为两大块：**

- 一个是全量(将全部数据一次写入到redis)
- 一个是增量（实时更新）

这里说的是增量, 指的是 mysql 的 update、insert、delate 变更数据。



简单讲就是 mysql 不用来读，读全在 redis 中，因此我们 redis 不删除缓存，而是 mysql 写完后就发布 binlog 异步更新缓存

这样只是存在短暂的一段时间的数据不一致性，而不会存在长时间的数据不一致性