# TCP 的 time_wait

## 1、为什么需要 TIME_WAIT  状态？

原因有二：

- 防止旧的数据包被 相同的 【四元组】 接收
- 确保 被动关闭的一方 能够接收 ACK，正确关闭连接



> ### 原因一：防止旧连接的数据包

如果在客户但未发起 FIN 的时候，服务端发送一个数据包 x，由于网络拥堵等原因， x 一直未到达客户端

而客户端觉得自己数据传输完了，那么发送 FIN 请求关闭连接，然后一直来来回回，客户端 2MSL 过后都关闭了连接，而这时，又有一个新的客户端，使用了原本相同的四元组，那么当建立起连接后，这个旧的数据包 x 发送给了 这个新的客户端，那么客户端是有可能正常接收的（即当序列号巧合的一致时），那么就会导致数据错乱

因此，等待这个 2MSL，可以让旧的数据全部无效，保证新的连接接收到的必定是新的数据

![image.png](https://pic.leetcode-cn.com/1597979904-bDiuAM-image.png)



> ### 原因二：保证连接正常关闭

如果 TIME_WAIT 过短或者没有的话，有什么问题呢？

假设客户端取消了 TIME_WAIT 

当客户端发送 ACK 后，立马关闭了，那么如果 ACK 在 MSL 内没有到达 服务端

那么服务端会重新发送 FIN 给客户端，但是由于客户端关闭连接了，那么就会导致服务端无法正常关闭，

**一直处于 LAST_ACK 状态，持续几分钟**，那么对于后续的相同 【四元组】的连接，服务端会发送 RST 表示中止连接，影响了后续的正常连接





![1597980047007](C:\Users\蒜头王八\AppData\Roaming\Typora\typora-user-images\1597980047007.png)





## 2、为什么 TIME_WAIT 等待的时间是 2MSL？

假设 客户端为主动关闭端，服务端为被动端，这里我们需要先知道：

1、**MSL：报文的最大生TIME_WAIT存时间，如果超过这个时间，那么报文就无效了，会被丢弃**

2、服务端在 收不到 ACK 时，会一直重新发送 FIN ，尝试几分钟后才自动关闭

3、客户端重新收到 FIN 报文后，会重新开始计时

4、服务端在收到 ACK 报文后，不会再发送任何报文，直接进入 CLOSED 状态



客户端给服务端发送 ACK 报文后，假设经过 t 时间后被服务端接收，存在 0 < t <= MSL

因为客户端不知道服务端多久才会收到 ACK，假设服务端在收到 ACK 前的一瞬间，发送了 FIN 报文，

那么这个报文 那么临界时间内最多需要一个 MSL 的时间才会无效或被接收，那么客户端就需要再等待一个 MSL 的时间，确保接收这个 FIN，因为如果只等待 1MSL 之类的，客户端关闭了，那么 FIN 到达时客户端无法接收，会回发一个 RST 包，让服务端以为出现了错误，但实际上是正常关闭



## 3、服务端出现大量 TIME_WAIT  的原因，以及解决方法

> ### 服务端出现大量 TIME_WAIT  的原因

在高并发的服务器上，如果使用的是短连接，那么基本每个请求都是处理完就正常关闭了，而服务端发起的关闭的情况下，由于并发量高，因此会出现大量 socket 停留在  2MSL 的 TIME_WAIT



> ### 大量 TIME_WAIT 的解决方法

1、使用长连接

2、缩减 TIME_WAIT 的时间





## 4、TIME_WAIT 过多的问题？

很多人都说端口被占用，一旦端口被占用后，就会导致新的连接无法建立，**这个说法是有问题的**



对于普通的连接，是【五元组】，即 协议，客户端 IP，客户端 端口，服务端 IP，服务端 端口

而单单说 TCP 连接，因为已经指定了协议，所以只剩下 【四元组】



我们需要先知道，服务端固定监听的是某个端口，比如我们自己写的服务，就是监听的 8080，运行起来它是不会变的



因此，服务端是不存在 端口被占用，然后无法建立新连接这个问题的，问题是出在客户端

对于同个服务，【四元组】中，服务端 IP 和 服务端 端口 不会发生改变

改变的是客户端的 IP 和 客户端的 端口



> ### 客户端 TIME_WAILT 过多

对于某个客户端来说，它的 IP 不变，如果它向服务发起多个连接，然后自己主动关闭，进入 TIME_WAIT 状态

那么就会导致这些端口这段时间内无法使用，那么当端口全部被占用时，这个客户端就无法再建立新的连接了





> ### 服务端 TIME_WAILT 过多

- 内存资源占用，一个 TIME_WAIT  占用 4KB 和 一个文件描述符 fd
- 线程资源占用，服务端监听端口，获取 socket 后交给后台线程处理，如果使用线程池，那么 TIME_WAILT 这段时间会导致线程无法执行其他任务
- 服务端的文件描述符 fd 数量是有限的，当全部被占用后将无法建立新的连接



需要注意的是，服务端的端口是不会被占用的，比如我的一个服务监听的是 8080 端口

客户端要发起连接，它自己肯定是找一个未被使用的端口，作为源端口建立进程通信

服务端收到请求，连接完后是交给后台线程处理，如果这个 8080 端口会被占用的话，那么之后的连接不都连接不上吗？很显然，并不会出现这种情况，因此不存在 8080 端口被占用的情况

不过，有个疑问，8080 端口没被占用，不一定表示其他端口没被占用，要是服务端针对每个连接，都找一个未被使用的端口来给这个连接进行使用，建立进程通信，那么不就不会占用 8080 端口了么？

这其实是有问题的，可用端口才 65535 个，tm 除去计算机内部自己运行的程序，还剩下多少个？就只能支撑几万并发量？那 阿里那个上亿并发量怎么整出来的？

很显然也不是，其实是因为 【四元组】确定一个 TCP 连接，对于的连接， 服务端 IP 和 服务端端口 都是一样的，那是怎么确定数据传输是给哪个 socket 的呢？当同个客户端建立两个连接，客户端肯定使用的是两个不一样的端口，那么对于服务端来说，就只需要通过 源 IP + 源端口 来确定 socket，即可以确定数据是发往哪个 socket 的



综上，我们可以看出，服务端能够建立的客户端的连接理论上是无限的，跟文件描述符 fd 是数量有关

而客户端自己能够建立的连接就跟自己内部的 端口数量有关系了



> ### 文件描述符 fd

Linux 中一切皆文件，对于每个文件，都有一个文件描述符 fd，这相当于是它的索引

内部维护了一张文件描述符表，可以在这张表上查找某个文件描述符 fd 对应的文件位置



当 Linux 系统启动的时候，存在 3 个默认的文件 和 对应的文件描述符：0 标准启动 ，1 标准输入，2 标准错误

而当我们此时 调用 open() 打开一个新的文件的时候，这个函数会返回一个 文件描述符 fd = 3，表示打开的这个文件的文件描述符 （索引）为 3

```java
fd = open(pathname, flags, mode)
// 返回了该文件的fd
rlen = read(fd, buf, count)
// IO操作均需要传入该文件的fd值
wlen = write(fd, buf, count)
status = close(fd)
```

往后我们的 IO 操作都需要传入文件描述符 fd，即都是操作系统深入内部帮我们修改的，即我们使用 fd 是告诉操作系统我们的 IO 操作是对哪个文件的，具体的操作是操作系统来修改的，防止用户瞎搞



每个进程具有的文件描述符数量是有限的，因此上面的服务端，它是一个进程，它的文件描述符的数量是有限的，当被 TIME_WAIT 都占用后，就无法建立新的连接